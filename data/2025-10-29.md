<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 58]
- [cs.AI](#cs.AI) [Total: 34]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices](https://arxiv.org/abs/2510.23775)
*Aryan Mathur,Asaduddin Ahmed,Pushti Amit Vasoya,Simeon Kandan Sonar,Yasir Z,Madesh Kuppusamy*

Main category: cs.CV

TL;DR: 本文提出一种结合视觉与语言模型的可解释图像真伪检测系统，兼顾高精度、快速推理和良好可解释性，可应用于司法、工业检测和社交媒体审查等领域。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成图像的真实性不断提高，验证图像真伪成为挑战。研究旨在开发一个高效、可解释、可部署于本地设备的检测系统，以应对视觉真实性验证需求。

Method: 论文提出了一个可解释的图像真实性检测系统，由轻量级卷积分类器（Faster-Than-Lies）与视觉-语言模型（Qwen2-VL-7B）结合，实现图像伪造分类、伪造特征定位与原因解释。系统还采用基于自编码器的重建误差图生成伪造特征热力图，以增强可解释性。

Result: 模型在扩展的CiFAKE数据集上达到96.5%的准确率，在8核CPU上推理时间为175毫秒，可满足边缘计算环境需求。研究还将70种视觉伪造特征归纳为8个语义类别，并实现了可解释的文本生成说明。

Conclusion: 研究验证了视觉与语言联合推理在低分辨率图像真实性检测中的可行性，展示了可解释AI在视觉取证领域的应用潜力，并为跨领域可信图像分析提供了新的研究方向。

Abstract: The increasing realism of AI-generated imagery poses challenges for verifying
visual authenticity. We present an explainable image authenticity detection
system that combines a lightweight convolutional classifier
("Faster-Than-Lies") with a Vision-Language Model (Qwen2-VL-7B) to classify,
localize, and explain artifacts in 32x32 images. Our model achieves 96.5%
accuracy on the extended CiFAKE dataset augmented with adversarial
perturbations and maintains an inference time of 175ms on 8-core CPUs, enabling
deployment on local or edge devices. Using autoencoder-based reconstruction
error maps, we generate artifact localization heatmaps, which enhance
interpretability for both humans and the VLM. We further categorize 70 visual
artifact types into eight semantic groups and demonstrate explainable text
generation for each detected anomaly. This work highlights the feasibility of
combining visual and linguistic reasoning for interpretable authenticity
detection in low-resolution imagery and outlines potential cross-domain
applications in forensics, industrial inspection, and social media moderation.

</details>


### [2] [CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting](https://arxiv.org/abs/2510.23785)
*Md Tanvir Hossain,Akif Islam,Mohd Ruhul Ameen*

Main category: cs.CV

TL;DR: 本文提出一种类无关的物体计数方法CountFormer，利用DINOv2特征增强结构感知能力，在复杂场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有计数模型缺乏模拟人类通过结构关系进行计数的能力，在面对复杂、重叠或对称物体时易出错。

Method: 采用Transformer架构，使用DINOv2作为自监督视觉编码器，通过位置嵌入融合保持几何关系，并以轻量级卷积解码器生成密度图。

Result: 在FSC-147数据集上表现与当前最优方法相当，并在结构复杂或密集的场景中取得更高准确度。

Conclusion: CountFormer能有效捕捉视觉重复与结构一致性，在复杂形状和密集场景下实现接近人类的计数准确度，并证明基础视觉模型可显著提升通用计数性能。

Abstract: Humans can effortlessly count diverse objects by perceiving visual repetition
and structural relationships rather than relying on class identity. However,
most existing counting models fail to replicate this ability; they often
miscount when objects exhibit complex shapes, internal symmetry, or overlapping
components. In this work, we introduce CountFormer, a transformer-based
framework that learns to recognize repetition and structural coherence for
class-agnostic object counting. Built upon the CounTR architecture, our model
replaces its visual encoder with the self-supervised foundation model DINOv2,
which produces richer and spatially consistent feature representations. We
further incorporate positional embedding fusion to preserve geometric
relationships before decoding these features into density maps through a
lightweight convolutional decoder. Evaluated on the FSC-147 dataset, our model
achieves performance comparable to current state-of-the-art methods while
demonstrating superior accuracy on structurally intricate or densely packed
scenes. Our findings indicate that integrating foundation models such as DINOv2
enables counting systems to approach human-like structural perception,
advancing toward a truly general and exemplar-free counting paradigm.

</details>


### [3] [A geometric and deep learning reproducible pipeline for monitoring floating anthropogenic debris in urban rivers using in situ cameras](https://arxiv.org/abs/2510.23798)
*Gauthier Grimmer,Romain Wenger,Clément Flint,Germain Forestier,Gilles Rixhon,Valentin Chardon*

Main category: cs.CV

TL;DR: 利用深度学习与摄像头几何模型监测与估算河流漂浮废弃物的大小与数量。


<details>
  <summary>Details</summary>
Motivation: 河流中漂浮的人为垃圾污染生态与人类活动，缺乏经济高效的实时监测方法，促使作者研发基于深度学习和几何分析的自动化监测系统。

Method: 使用固定现场摄像头获取图像数据，通过不同配置的深度学习模型进行实时检测与分类，并引入考虑相机内在与外在参数的几何模型，用于从二维图像估计物体的真实尺寸。

Result: 该论文研究了利用固定现场摄像头监测河流中漂浮的人为废弃物的问题，提出了一套创新的方法框架。通过深度学习实现连续监测与定量分析，评估不同模型在复杂环境中的准确性与推理速度，并采用几何模型从二维图像中估算物体实际尺寸。

Conclusion: 证明了结合投影几何与回归校正可以实现对漂浮废弃物的度量估算，并为城市水域建立低成本自动监测系统提供了可行路径。

Abstract: The proliferation of floating anthropogenic debris in rivers has emerged as a
pressing environmental concern, exerting a detrimental influence on
biodiversity, water quality, and human activities such as navigation and
recreation. The present study proposes a novel methodological framework for the
monitoring the aforementioned waste, utilising fixed, in-situ cameras. This
study provides two key contributions: (i) the continuous quantification and
monitoring of floating debris using deep learning and (ii) the identification
of the most suitable deep learning model in terms of accuracy and inference
speed under complex environmental conditions. These models are tested in a
range of environmental conditions and learning configurations, including
experiments on biases related to data leakage. Furthermore, a geometric model
is implemented to estimate the actual size of detected objects from a 2D image.
This model takes advantage of both intrinsic and extrinsic characteristics of
the camera. The findings of this study underscore the significance of the
dataset constitution protocol, particularly with respect to the integration of
negative images and the consideration of temporal leakage. In conclusion, the
feasibility of metric object estimation using projective geometry coupled with
regression corrections is demonstrated. This approach paves the way for the
development of robust, low-cost, automated monitoring systems for urban aquatic
environments.

</details>


### [4] [RareFlow: Physics-Aware Flow-Matching for Cross-Sensor Super-Resolution of Rare-Earth Features](https://arxiv.org/abs/2510.23816)
*Forouzan Fallah,Wenwen Li,Chia-Yu Hsu,Hyunho Lee,Yezhou Yang*

Main category: cs.CV

TL;DR: RareFlow是一种物理感知的遥感图像超分辨率方法，在分布外场景下保持高保真与物理一致性，通过双重条件架构和不确定性量化取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 针对遥感图像超分辨率在分布外（OOD）条件下表现不佳的问题，例如由不同传感器捕获的罕见地貌特征会导致视觉上合理但物理上不准确的结果，作者希望提升模型在这些复杂场景下的鲁棒性和物理一致性。

Method: 采用双重条件架构：Gated ControlNet保持低分辨率输入的几何精度，文本提示引导复杂特征的语义合成；设计多维损失函数保障光谱与辐射一致性；通过随机前向传播量化输出不确定性，以识别不熟悉输入并减少幻觉特征。

Result: 提出的RareFlow框架在多传感器卫星影像测试中表现出显著优于现有方法的效果，专家评估其生成结果接近真实影像，量化指标上FID降低约40%。

Conclusion: RareFlow验证了其在数据稀缺和分布漂移严重的科学领域中具有稳健的高保真生成能力，为物理一致的图像合成提供了新范式。

Abstract: Super-resolution (SR) for remote sensing imagery often fails under
out-of-distribution (OOD) conditions, such as rare geomorphic features captured
by diverse sensors, producing visually plausible but physically inaccurate
results. We present RareFlow, a physics-aware SR framework designed for OOD
robustness. RareFlow's core is a dual-conditioning architecture. A Gated
ControlNet preserves fine-grained geometric fidelity from the low-resolution
input, while textual prompts provide semantic guidance for synthesizing complex
features. To ensure physically sound outputs, we introduce a multifaceted loss
function that enforces both spectral and radiometric consistency with sensor
properties. Furthermore, the framework quantifies its own predictive
uncertainty by employing a stochastic forward pass approach; the resulting
output variance directly identifies unfamiliar inputs, mitigating feature
hallucination. We validate RareFlow on a new, curated benchmark of multi-sensor
satellite imagery. In blind evaluations, geophysical experts rated our model's
outputs as approaching the fidelity of ground truth imagery, significantly
outperforming state-of-the-art baselines. This qualitative superiority is
corroborated by quantitative gains in perceptual metrics, including a nearly
40\% reduction in FID. RareFlow provides a robust framework for high-fidelity
synthesis in data-scarce scientific domains and offers a new paradigm for
controlled generation under severe domain shift.

</details>


### [5] [TRELLISWorld: Training-Free World Generation from Object Generators](https://arxiv.org/abs/2510.23880)
*Hanke Chen,Yuan Liu,Minchen Li*

Main category: cs.CV

TL;DR: 提出一种无训练的文本驱动3D场景生成新方法，通过瓦片式生成和融合实现高效、灵活的场景构建。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法受限于单对象生成、需要特定领域训练或缺乏全景支持，因此作者希望构建一种可扩展、训练自由、具备全方位可视能力的文本驱动3D场景生成方案。

Method: 将文本到3D对象的扩散模型改造成模块化瓦片生成器，并以多瓦片去噪和加权融合的方式实现场景整体合成。

Result: 本文提出了一种无需训练的文本驱动3D场景生成方法，通过将通用文本到3D对象的扩散模型改造成模块化瓦片生成器，重新构造场景生成问题为多瓦片去噪过程。重叠的3D区域独立生成后，通过加权平均实现无缝融合。该方法消除了对场景级数据集和再训练的需求，保留对象层次的通用能力，可高效生成布局多样、语义一致的3D场景。

Conclusion: 该方法能够在不依赖场景数据集或额外训练的情况下，实现灵活的3D场景生成，并为通用语言驱动的场景构建提供了基础。

Abstract: Text-driven 3D scene generation holds promise for a wide range of
applications, from virtual prototyping to AR/VR and simulation. However,
existing methods are often constrained to single-object generation, require
domain-specific training, or lack support for full 360-degree viewability. In
this work, we present a training-free approach to 3D scene synthesis by
repurposing general-purpose text-to-3D object diffusion models as modular tile
generators. We reformulate scene generation as a multi-tile denoising problem,
where overlapping 3D regions are independently generated and seamlessly blended
via weighted averaging. This enables scalable synthesis of large, coherent
scenes while preserving local semantic control. Our method eliminates the need
for scene-level datasets or retraining, relies on minimal heuristics, and
inherits the generalization capabilities of object-level priors. We demonstrate
that our approach supports diverse scene layouts, efficient generation, and
flexible editing, establishing a simple yet powerful foundation for
general-purpose, language-driven 3D scene construction.

</details>


### [6] [DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning](https://arxiv.org/abs/2510.23907)
*Eddison Pham,Prisha Priyadarshini,Adrian Maliackel,Kanishk Bandi,Cristian Meo,Kevin Zhu*

Main category: cs.CV

TL;DR: 论文提出了一个名为DynaStride的系统，用于自动生成教学视频的场景级字幕，提升字幕的连贯性与教学效果。


<details>
  <summary>Details</summary>
Motivation: 现有教学视频字幕常缺乏场景结构理解，导致字幕不连贯、信息质量低，无法支持有效学习。论文旨在解决字幕生成中的时间和语义一致性问题。

Method: 该方法利用YouCookII数据集的场景标注进行自适应帧采样和多模态窗口处理，通过多模态链式推理生成动作-对象对，再以动态步进选择算法平衡时间上下文与冗余，最终生成整合视觉语义和时间推理的场景级字幕。

Result: 在BLEU、METEOR、BERTScore和CLIPScore等指标上，DynaStride优于VLLaMA3和GPT-4o，并在定性分析中表现出更好的时间一致性与信息丰富度。

Conclusion: DynaStride在教学视频场景级字幕生成中可以有效提升字幕的时间连贯性和语义丰富度，在多个自动评估指标上均超越现有强基线模型。

Abstract: Scene-level captioning in instructional videos can enhance learning by
requiring an understanding of both visual cues and temporal structure. By
aligning visual cues with textual guidance, this understanding supports
procedural learning and multimodal reasoning, providing a richer context for
skill acquisition. However, captions that fail to capture this structure may
lack coherence and quality, which can create confusion and undermine the
video's educational intent. To address this gap, we introduce DynaStride, a
pipeline to generate coherent, scene-level captions without requiring manual
scene segmentation. Using the YouCookII dataset's scene annotations, DynaStride
performs adaptive frame sampling and multimodal windowing to capture key
transitions within each scene. It then employs a multimodal chain-of-thought
process to produce multiple action-object pairs, which are refined and fused
using a dynamic stride window selection algorithm that adaptively balances
temporal context and redundancy. The final scene-level caption integrates
visual semantics and temporal reasoning in a single instructional caption.
Empirical evaluations against strong baselines, including VLLaMA3 and GPT-4o,
demonstrate consistent gains on both N-gram-based metrics (BLEU, METEOR) and
semantic similarity measures (BERTScore, CLIPScore). Qualitative analyses
further show that DynaStride produces captions that are more temporally
coherent and informative, suggesting a promising direction for improving
AI-powered instructional content generation.

</details>


### [7] [TurboPortrait3D: Single-step diffusion-based fast portrait novel-view synthesis](https://arxiv.org/abs/2510.23929)
*Emily Kim,Julieta Martinez,Timur Bagautdinov,Jessica Hodgins*

Main category: cs.CV

TL;DR: 利用单步扩散模型提升图像到3D头像生成质量，实现低延迟高保真新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有图像到3D人像模型存在细节缺失与身份保持问题，而扩散模型虽画质好却不具备3D一致性且计算昂贵，因此需要开发一种同时兼顾画质、3D一致性与效率的方案。

Method: 采用两个阶段：首先通过前向图像到头像生成获得初始3D表示及噪声渲染；随后使用单步扩散模型，在输入图像条件下对渲染结果进行多视角一致性优化。训练策略包括大型合成多视角数据的预训练以及高质量真实图像的微调。

Result: 论文提出了一种名为TurboPortrait3D的低延迟人像新视角合成方法，通过结合图像到3D模型与扩散模型的优势，实现高质量且身份保持的三维人像渲染。

Conclusion: 该方法在定性与定量性能上均优于现有技术，在效率方面也更优，证明其在真实应用中具有显著潜力。

Abstract: We introduce TurboPortrait3D: a method for low-latency novel-view synthesis
of human portraits. Our approach builds on the observation that existing
image-to-3D models for portrait generation, while capable of producing
renderable 3D representations, are prone to visual artifacts, often lack of
detail, and tend to fail at fully preserving the identity of the subject. On
the other hand, image diffusion models excel at generating high-quality images,
but besides being computationally expensive, are not grounded in 3D and thus
are not directly capable of producing multi-view consistent outputs. In this
work, we demonstrate that image-space diffusion models can be used to
significantly enhance the quality of existing image-to-avatar methods, while
maintaining 3D-awareness and running with low-latency. Our method takes a
single frontal image of a subject as input, and applies a feedforward
image-to-avatar generation pipeline to obtain an initial 3D representation and
corresponding noisy renders. These noisy renders are then fed to a single-step
diffusion model which is conditioned on input image(s), and is specifically
trained to refine the renders in a multi-view consistent way. Moreover, we
introduce a novel effective training strategy that includes pre-training on a
large corpus of synthetic multi-view data, followed by fine-tuning on
high-quality real images. We demonstrate that our approach both qualitatively
and quantitatively outperforms current state-of-the-art for portrait novel-view
synthesis, while being efficient in time.

</details>


### [8] [PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors](https://arxiv.org/abs/2510.23930)
*Xirui Jin,Renbiao Jin,Boying Li,Danping Zou,Wenxian Yu*

Main category: cs.CV

TL;DR: PlanarGS利用语言提示的平面与几何先验改进3DGS，在室内场景重建上优于所有现有方法，提升了几何精度与表面细节。


<details>
  <summary>Details</summary>
Motivation: 现有的三维高斯散射（3DGS）方法在生成新的视角合成时效果出色，但在室内场景中，由于存在大面积低纹理区域，基于光度损失的优化会导致几何模糊，难以恢复高保真表面。作者希望解决该方法在低纹理、平面丰富场景中的重建问题。

Method: 方法包括：1）通过语言提示生成平面区域候选；2）跨视角融合与几何先验校准；3）在3D高斯优化中加入平面一致性和几何先验监督项，以增强深度和法线一致性。

Result: 提出的PlanarGS框架引入语言提示的平面先验（LP3）管线，结合预训练视觉语言分割模型、跨视角融合和几何先验检查，并在优化中加入平面一致性和几何先验监督项。实验表明，PlanarGS在标准室内重建数据集上显著优于现有方法，能生成更准确、细节更丰富的三维表面。

Conclusion: PlanarGS有效缓解了传统3DGS在低纹理室内场景中的几何模糊问题，通过引入计划性平面与几何约束，使三维重建结果更加真实可靠。

Abstract: Three-dimensional Gaussian Splatting (3DGS) has recently emerged as an
efficient representation for novel-view synthesis, achieving impressive visual
quality. However, in scenes dominated by large and low-texture regions, common
in indoor environments, the photometric loss used to optimize 3DGS yields
ambiguous geometry and fails to recover high-fidelity 3D surfaces. To overcome
this limitation, we introduce PlanarGS, a 3DGS-based framework tailored for
indoor scene reconstruction. Specifically, we design a pipeline for
Language-Prompted Planar Priors (LP3) that employs a pretrained vision-language
segmentation model and refines its region proposals via cross-view fusion and
inspection with geometric priors. 3D Gaussians in our framework are optimized
with two additional terms: a planar prior supervision term that enforces planar
consistency, and a geometric prior supervision term that steers the Gaussians
toward the depth and normal cues. We have conducted extensive experiments on
standard indoor benchmarks. The results show that PlanarGS reconstructs
accurate and detailed 3D surfaces, consistently outperforming state-of-the-art
methods by a large margin. Project page: https://planargs.github.io

</details>


### [9] [Neural USD: An object-centric framework for iterative editing and control](https://arxiv.org/abs/2510.23956)
*Alejandro Escontrela,Shrinu Kushagra,Sjoerd van Steenkiste,Yulia Rubanova,Aleksander Holynski,Kelsey Allen,Kevin Murphy,Thomas Kipf*

Main category: cs.CV

TL;DR: 本文提出Neural USD框架，以结构化方式实现生成模型中对象的精确可控编辑，解决了现有方法常伴的全局干扰问题。


<details>
  <summary>Details</summary>
Motivation: 当前生成式模型虽然在可控生成上取得了显著进展，但对于精确且可多次迭代的对象编辑仍存在困难，尤其是在不影响其他场景元素的情况下修改特定对象。

Method: 作者受计算机图形学中的Universal Scene Descriptor (USD)标准启发，提出神经通用场景描述符（Neural USD）框架，用结构化和层次化的方式表示场景与对象，并通过微调方法实现控制信号间的解耦。

Result: Neural USD实现了对场景中各个对象在外观、几何与姿态上的独立控制，并支持逐步迭代的编辑流程，实验展示了其在灵活性与可控性方面的优势。

Conclusion: Neural USD为生成式模型的精确对象编辑提供了新的思路，克服了传统方法中全局变化难以控制的不足，展示了在可拓展与模块化场景生成中的潜力。

Abstract: Amazing progress has been made in controllable generative modeling,
especially over the last few years. However, some challenges remain. One of
them is precise and iterative object editing. In many of the current methods,
trying to edit the generated image (for example, changing the color of a
particular object in the scene or changing the background while keeping other
elements unchanged) by changing the conditioning signals often leads to
unintended global changes in the scene. In this work, we take the first steps
to address the above challenges. Taking inspiration from the Universal Scene
Descriptor (USD) standard developed in the computer graphics community, we
introduce the "Neural Universal Scene Descriptor" or Neural USD. In this
framework, we represent scenes and objects in a structured, hierarchical
manner. This accommodates diverse signals, minimizes model-specific
constraints, and enables per-object control over appearance, geometry, and
pose. We further apply a fine-tuning approach which ensures that the above
control signals are disentangled from one another. We evaluate several design
considerations for our framework, demonstrating how Neural USD enables
iterative and incremental workflows. More information at:
https://escontrela.me/neural_usd .

</details>


### [10] [SafeVision: Efficient Image Guardrail with Robust Policy Adherence and Explainability](https://arxiv.org/abs/2510.23960)
*Peiyang Xu,Minzhou Pan,Zhaorun Chen,Shuang Yang,Chaowei Xiao,Bo Li*

Main category: cs.CV

TL;DR: SafeVision通过结合推理和策略遵循机制，实现了高效、透明且具备动态适应能力的图像安全防护，性能与速度均优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 传统图像安全防护模型依赖预先定义的类别，缺乏语义推理能力，导致误分类和对新型威胁适应性差，更新成本高。

Method: 提出SafeVision框架，结合人类式推理机制，通过数据收集与生成框架、策略遵循式训练流程、自定义损失函数和多样化问答生成策略，提升模型的透明性与适应性。

Result: SafeVision在多个基准测试中取得了最先进的性能，相比GPT-4o在VisionHarm-T和VisionHarm-C数据集上的表现分别提升8.6%和15.5%，并且推理速度提高16倍以上。

Conclusion: SafeVision是一个可解释、可动态适应的图像安全防护系统，能够实时与安全策略对齐，无需重新训练即可应对新兴威胁。

Abstract: With the rapid proliferation of digital media, the need for efficient and
transparent safeguards against unsafe content is more critical than ever.
Traditional image guardrail models, constrained by predefined categories, often
misclassify content due to their pure feature-based learning without semantic
reasoning. Moreover, these models struggle to adapt to emerging threats,
requiring costly retraining for new threats. To address these limitations, we
introduce SafeVision, a novel image guardrail that integrates human-like
reasoning to enhance adaptability and transparency. Our approach incorporates
an effective data collection and generation framework, a policy-following
training pipeline, and a customized loss function. We also propose a diverse QA
generation and training strategy to enhance learning effectiveness. SafeVision
dynamically aligns with evolving safety policies at inference time, eliminating
the need for retraining while ensuring precise risk assessments and
explanations. Recognizing the limitations of existing unsafe image benchmarks,
which either lack granularity or cover limited risks, we introduce VisionHarm,
a high-quality dataset comprising two subsets: VisionHarm Third-party
(VisionHarm-T) and VisionHarm Comprehensive(VisionHarm-C), spanning diverse
harmful categories. Through extensive experiments, we show that SafeVision
achieves state-of-the-art performance on different benchmarks. SafeVision
outperforms GPT-4o by 8.6% on VisionHarm-T and by 15.5% on VisionHarm-C, while
being over 16x faster. SafeVision sets a comprehensive, policy-following, and
explainable image guardrail with dynamic adaptation to emerging threats.

</details>


### [11] [Reasoning Visual Language Model for Chest X-Ray Analysis](https://arxiv.org/abs/2510.23968)
*Andriy Myronenko,Dong Yang,Baris Turkbey,Mariam Aboian,Sena Azamat,Esra Akcicek,Hongxu Yin,Pavlo Molchanov,Marc Edgar,Yufan He,Pengfei Guo,Yucheng Tang,Daguang Xu*

Main category: cs.CV

TL;DR: 该研究开发了一个具备显式推理能力的胸片视觉语言模型，兼顾诊断准确性与临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统医学视觉语言模型缺乏透明的推理过程，不符合临床需求。研究者希望通过引入链式推理学习专家思维过程，提升AI系统的可靠性与可解释性。

Method: 模型采用两阶段训练：首先进行推理风格的有监督微调（SFT），然后通过基于可验证奖励的强化学习（RL）进一步优化；同时结合高保真视觉编码与放射科工作流程对齐。

Result: 本文提出了一种将链式思维（CoT）推理引入胸部X光片解读的视觉语言模型框架，旨在提升模型的可解释性和临床可审计性。模型不仅能生成准确诊断，还能展示推理路径和不确定性。实验表明，该方法在分类精度上具有竞争力，同时显著改善了解释能力。

Conclusion: 该方法通过显式推理提升了视觉语言模型在医疗影像中的可信度和透明度，有助于人机协作与错误审计。

Abstract: Vision-language models (VLMs) have shown strong promise for medical image
analysis, but most remain opaque, offering predictions without the transparent,
stepwise reasoning clinicians rely on. We present a framework that brings
chain-of-thought (CoT) reasoning to chest X-ray interpretation. Inspired by
reasoning-first training paradigms, our approach is designed to learn how
experts reason, not just what they conclude, by aligning intermediate steps
with observable image evidence and radiology workflow. Beyond accuracy, the
explicit reasoning traces support clinical auditability: they reveal why a
conclusion was reached, which alternatives were considered, and where
uncertainty remains, enabling quality assurance, error analysis, and safer
human-AI collaboration.
  Our model couples high-fidelity visual encoding with a two-stage training
recipe: a reasoning-style supervised fine-tuning (SFT) followed by
reinforcement learning (RL) that uses verifiable rewards over a list of X-ray
abnormalities. The model outputs reasoning that mirrors radiologists systematic
thought process, uncertainty, and differential diagnosis. In
out-of-distribution evaluation, the approach achieves competitive multi-label
classification while improving interpretability. In a reader study with expert
radiologists, full reasoning traces increased confidence, supported error
auditing, and reduced time to finalize reports. We release code and the model
NV-Reason-CXR-3B to support community progress toward trustworthy, explainable
AI in chest radiography and other medical imaging tasks where reasoning quality
is as critical as prediction quality.

</details>


### [12] [TeleEgo: Benchmarking Egocentric AI Assistants in the Wild](https://arxiv.org/abs/2510.23981)
*Jiaqi Yan,Ruilong Ren,Jingren Liu,Shuning Xu,Ling Wang,Yiheng Wang,Yun Wang,Long Zhang,Xiangyu Chen,Changzhi Sun,Jixiang Luo,Dell Zhang,Hao Sun,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleEgo基准实现对多模态、自中心AI助手在现实任务下的长时流式评估，补足了现有基准的短期和单维度不足。


<details>
  <summary>Details</summary>
Motivation: 现有的自中心AI助手评估基准往往分离评估多模态输入处理、实时响应或长期记忆等能力，缺乏在真实流式场景和长期任务中的整体性评测。

Method: 作者构建了名为TeleEgo的长期、多模态流式基准，涵盖视频、音频、文本三种输入，提供了现实生活中的14小时/人数据，数据按统一时间线对齐并经过人工精修。定义了12个子任务，覆盖记忆、理解、跨记忆推理三种核心能力，并以实时准确率和记忆持久时间为核心评估指标。

Result: TeleEgo包含3291条经人工验证的问题项，题型多样，并在严格的流式场景下测试模型表现。该基准能全面评估AI助手的正确性、时间响应性和长期记忆表现。

Conclusion: TeleEgo为评估和提升实际可用的自中心AI助手提供了更真实且系统的测评框架，可推动多模态AI的发展。

Abstract: Egocentric AI assistants in real-world settings must process multi-modal
inputs (video, audio, text), respond in real time, and retain evolving
long-term memory. However, existing benchmarks typically evaluate these
abilities in isolation, lack realistic streaming scenarios, or support only
short-term tasks. We introduce \textbf{TeleEgo}, a long-duration, streaming,
omni-modal benchmark for evaluating egocentric AI assistants in realistic daily
contexts. The dataset features over 14 hours per participant of synchronized
egocentric video, audio, and text across four domains: work \& study, lifestyle
\& routines, social activities, and outings \& culture. All data is aligned on
a unified global timeline and includes high-quality visual narrations and
speech transcripts, curated through human refinement.TeleEgo defines 12
diagnostic subtasks across three core capabilities: Memory (recalling past
events), Understanding (interpreting the current moment), and Cross-Memory
Reasoning (linking distant events). It contains 3,291 human-verified QA items
spanning multiple question formats (single-choice, binary, multi-choice, and
open-ended), evaluated strictly in a streaming setting. We propose two key
metrics -- Real-Time Accuracy and Memory Persistence Time -- to jointly assess
correctness, temporal responsiveness, and long-term retention. TeleEgo provides
a realistic and comprehensive evaluation to advance the development of
practical AI assistants.

</details>


### [13] [AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization](https://arxiv.org/abs/2510.24000)
*Heethanjan Kanagalingam,Thenukan Pathmanathan,Mokeeshan Vathanakumar,Tharmakulasingam Mukunthan*

Main category: cs.CV

TL;DR: 该研究提出AdvBlur，通过引入对抗模糊图像与双损失函数增强糖尿病视网膜病变检测模型的跨域泛化能力，在多源数据测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有DR检测模型在不同拍摄设备、人口群体及成像条件下表现不稳定，缺乏有效的域泛化能力。为解决由于数据分布变化导致模型鲁棒性下降的问题，亟需设计一种可抵御分布差异的方法。

Method: 提出一种结合对抗模糊图像与双损失函数框架的深度学习方法，通过在训练集中加入对抗模糊图像并设计双损失机制来提升模型的域泛化能力。

Result: 实验显示AdvBlur在多个数据集上显著缓解了分布差异带来的性能退化，特别是在低质量图像及不同摄像机类型的情况下仍保持较高准确率与稳健性。

Conclusion: AdvBlur显著提升了糖尿病视网膜病变（DR）分类模型在跨域数据集上的鲁棒性和泛化能力，并在外部未见数据上取得与现有先进域泛化模型相当的性能。

Abstract: Diabetic retinopathy (DR) is a leading cause of vision loss worldwide, yet
early and accurate detection can significantly improve treatment outcomes.
While numerous Deep learning (DL) models have been developed to predict DR from
fundus images, many face challenges in maintaining robustness due to
distributional variations caused by differences in acquisition devices,
demographic disparities, and imaging conditions. This paper addresses this
critical limitation by proposing a novel DR classification approach, a method
called AdvBlur. Our method integrates adversarial blurred images into the
dataset and employs a dual-loss function framework to address domain
generalization. This approach effectively mitigates the impact of unseen
distributional variations, as evidenced by comprehensive evaluations across
multiple datasets. Additionally, we conduct extensive experiments to explore
the effects of factors such as camera type, low-quality images, and dataset
size. Furthermore, we perform ablation studies on blurred images and the loss
function to ensure the validity of our choices. The experimental results
demonstrate the effectiveness of our proposed method, achieving competitive
performance compared to state-of-the-art domain generalization DR models on
unseen external datasets.

</details>


### [14] [Towards the Automatic Segmentation, Modeling and Meshing of the Aortic Vessel Tree from Multicenter Acquisitions: An Overview of the SEG.A. 2023 Segmentation of the Aorta Challenge](https://arxiv.org/abs/2510.24009)
*Yuan Jin,Antonio Pepe,Gian Marco Melito,Yuxuan Chen,Yunsu Byeon,Hyeseong Kim,Kyungwon Kim,Doohyun Park,Euijoon Choi,Dosik Hwang,Andriy Myronenko,Dong Yang,Yufan He,Daguang Xu,Ayman El-Ghotni,Mohamed Nabil,Hossam El-Kady,Ahmed Ayyad,Amr Nasr,Marek Wodzinski,Henning Müller,Hyeongyu Kim,Yejee Shin,Abbas Khan,Muhammad Asad,Alexander Zolotarev,Caroline Roney,Anthony Mathur,Martin Benning,Gregory Slabaugh,Theodoros Panagiotis Vagenas,Konstantinos Georgas,George K. Matsopoulos,Jihan Zhang,Zhen Zhang,Liqin Huang,Christian Mayer,Heinrich Mächler,Jan Egger*

Main category: cs.CV

TL;DR: 该研究通过SEG.A挑战提供AVT分割公开数据集，推动算法评测；3D U-Net主导表现，模型集成效果最佳，为后续自动分析研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏共享的高质量数据，主动脉血管树（AVT）在CTA影像中的自动分析发展受限，因此研究者希望通过建立公开数据集促进该领域进展。

Method: 发起SEG.A挑战赛，提供大型多机构AVT分割数据集，并在隐藏测试集上评估自动算法，同时设置可选的表面网格任务；汇总并分析参赛算法表现。

Result: 深度学习方法尤其是3D U-Net架构在分割任务中表现最佳；顶尖模型集成优于单一模型，算法设计和训练数据特征显著影响性能。

Conclusion: SEG.A挑战赛建立了新的性能基准和重要的开放资源，为未来临床可转化的AVT自动分析工具开发提供了推动力。

Abstract: The automated analysis of the aortic vessel tree (AVT) from computed
tomography angiography (CTA) holds immense clinical potential, but its
development has been impeded by a lack of shared, high-quality data. We
launched the SEG.A. challenge to catalyze progress in this field by introducing
a large, publicly available, multi-institutional dataset for AVT segmentation.
The challenge benchmarked automated algorithms on a hidden test set, with
subsequent optional tasks in surface meshing for computational simulations. Our
findings reveal a clear convergence on deep learning methodologies, with 3D
U-Net architectures dominating the top submissions. A key result was that an
ensemble of the highest-ranking algorithms significantly outperformed
individual models, highlighting the benefits of model fusion. Performance was
strongly linked to algorithmic design, particularly the use of customized
post-processing steps, and the characteristics of the training data. This
initiative not only establishes a new performance benchmark but also provides a
lasting resource to drive future innovation toward robust, clinically
translatable tools.

</details>


### [15] [Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks](https://arxiv.org/abs/2510.24010)
*Mirali Purohit,Bimal Gajera,Vatsal Malaviya,Irish Mehta,Kunal Kasodekar,Jacob Adler,Steven Lu,Umaa Rebbapragada,Hannah Kerner*

Main category: cs.CV

TL;DR: 本文提出Mars-Bench——首个火星任务的标准化评测基准，涵盖20个多任务数据集，为火星专用基础模型研究提供统一平台并显示其潜在优势。


<details>
  <summary>Details</summary>
Motivation: 火星科学领域在利用大规模预训练模型方面进展缓慢，主要原因在于缺乏标准化的评测基准和统一的评估框架，这限制了火星任务中基础模型的发展。

Method: 作者提出了Mars-Bench，这是第一个面向火星任务的系统化评测基准，整合了包含轨道与地表影像的20个数据集，覆盖分类、分割与目标检测任务。作者提供了标准化数据集和基线评测，模型包括自然影像、地球卫星影像以及视觉-语言模型的预训练版本。

Result: 分析结果表明，与通用领域的模型相比，基于火星特定任务进行预训练的基础模型在性能上可能具有优势。

Conclusion: Mars-Bench为火星科学中的机器学习模型发展与比较建立了标准化基础，推动火星领域专用基础模型的进一步探索与发展。

Abstract: Foundation models have enabled rapid progress across many specialized domains
by leveraging large-scale pre-training on unlabeled data, demonstrating strong
generalization to a variety of downstream tasks. While such models have gained
significant attention in fields like Earth Observation, their application to
Mars science remains limited. A key enabler of progress in other domains has
been the availability of standardized benchmarks that support systematic
evaluation. In contrast, Mars science lacks such benchmarks and standardized
evaluation frameworks, which have limited progress toward developing foundation
models for Martian tasks. To address this gap, we introduce Mars-Bench, the
first benchmark designed to systematically evaluate models across a broad range
of Mars-related tasks using both orbital and surface imagery. Mars-Bench
comprises 20 datasets spanning classification, segmentation, and object
detection, focused on key geologic features such as craters, cones, boulders,
and frost. We provide standardized, ready-to-use datasets and baseline
evaluations using models pre-trained on natural images, Earth satellite data,
and state-of-the-art vision-language models. Results from all analyses suggest
that Mars-specific foundation models may offer advantages over general-domain
counterparts, motivating further exploration of domain-adapted pre-training.
Mars-Bench aims to establish a standardized foundation for developing and
comparing machine learning models for Mars science. Our data, models, and code
are available at: https://mars-bench.github.io/.

</details>


### [16] [AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts](https://arxiv.org/abs/2510.24034)
*Yufan Liu,Wanqian Zhang,Huashan Chen,Lin Wang,Xiaojun Jia,Zheng Lin,Weiping Wang*

Main category: cs.CV

TL;DR: 本论文提出了一种用于生成文本到图像模型(T2I)对抗性提示的新框架，以自动评估安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有T2I模型安全评估方法需白盒访问且效率低下，并往往产生无意义的提示词，论文旨在提出无需白盒访问且能生成可读对抗性提示的自动化方案。

Method: 使用大语言模型(LLM)生成对抗性后缀，并采用交替优化与微调流程，通过辅助LLM的困惑度评分保证提示的可读性，同时引入禁止词惩罚机制以防止生成被过滤的词汇。

Result: 实验结果显示AutoPrompT生成的提示具备高效的红队测试能力、强抗过滤性和良好的零样本迁移性能，能够快速发现商用API中的潜在安全漏洞。

Conclusion: 论文表明所提出的AutoPrompT框架能够在黑盒环境中自动生成既易读又能绕过过滤器的对抗性提示，从而显著提升了红队测试效率和广度。

Abstract: Despite rapid advancements in text-to-image (T2I) models, their safety
mechanisms are vulnerable to adversarial prompts, which maliciously generate
unsafe images. Current red-teaming methods for proactively assessing such
vulnerabilities usually require white-box access to T2I models, and rely on
inefficient per-prompt optimization, as well as inevitably generate
semantically meaningless prompts easily blocked by filters. In this paper, we
propose APT (AutoPrompT), a black-box framework that leverages large language
models (LLMs) to automatically generate human-readable adversarial suffixes for
benign prompts. We first introduce an alternating optimization-finetuning
pipeline between adversarial suffix optimization and fine-tuning the LLM
utilizing the optimized suffix. Furthermore, we integrates a dual-evasion
strategy in optimization phase, enabling the bypass of both perplexity-based
filter and blacklist word filter: (1) we constrain the LLM generating
human-readable prompts through an auxiliary LLM perplexity scoring, which
starkly contrasts with prior token-level gibberish, and (2) we also introduce
banned-token penalties to suppress the explicit generation of banned-tokens in
blacklist. Extensive experiments demonstrate the excellent red-teaming
performance of our human-readable, filter-resistant adversarial prompts, as
well as superior zero-shot transferability which enables instant adaptation to
unseen prompts and exposes critical vulnerabilities even in commercial APIs
(e.g., Leonardo.Ai.).

</details>


### [17] [Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for Vision Models](https://arxiv.org/abs/2510.24037)
*Shufan Shen,Junshu Sun,Shuhui Wang,Qingming Huang*

Main category: cs.CV

TL;DR: SNELLA是一种高效的一阶段稀疏微调方法，结合低秩非线性分解和自适应稀疏机制，实现视觉任务性能提升与内存占用显著降低。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调（PEFT）方法在适应下游视觉任务时存在两方面问题：一是基于梯度信息定位任务相关参数，忽视了微调过程中的参数变化，限制了性能；二是稀疏调整导致优化器需存储完整权重矩阵，占用高内存。

Method: 本文提出一种一阶段方法SNELLA，通过引入两个低秩可学习矩阵构成稀疏矩阵并加入原权重，实现内存高效的更新。同时，结合非线性核函数提升合成矩阵的秩，减少权重更新间的依赖。提出自适应双层稀疏分配机制，使权重在层间和层内基于重要性评分进行竞争，实现端到端的任务相关权重选择。

Result: SNELLA在分类、分割和生成任务上表现优异，不仅达到最新SOTA性能，还显著减少内存消耗。在FGVC基准上比SPT-LoRA提高1.8%的Top-1准确率，并在86M至632M参数规模模型中实现31.1%-39.9%的内存减少。

Conclusion: SNELLA为视觉模型提供了一种高效、一阶段的参数微调方案，通过低秩非线性分解和双层稀疏分配，在提升性能的同时有效降低了存储成本。

Abstract: Parameter-efficient fine-tuning (PEFT) aims to adapt pre-trained vision
models to downstream tasks. Among PEFT paradigms, sparse tuning achieves
remarkable performance by adjusting only the weights most relevant to
downstream tasks, rather than densely tuning the entire weight matrix. Current
methods follow a two-stage paradigm. First, it locates task-relevant weights by
gradient information, which overlooks the parameter adjustments during
fine-tuning and limits the performance. Second, it updates only the located
weights by applying a sparse mask to the gradient of the weight matrix, which
results in high memory usage due to the storage of all weight matrices in the
optimizer. In this paper, we propose a one-stage method named SNELLA to
overcome the above limitations. For memory usage, SNELLA selectively updates
the weight matrix by adding it to another sparse matrix that is merged by two
low-rank learnable matrices. We extend the low-rank decomposition by
introducing nonlinear kernel functions, thereby increasing the rank of the
resulting merged matrix to prevent the interdependency among weight updates,
enabling better adaptation to downstream tasks. For locating task-relevant
weights, we propose an adaptive bi-level sparsity allocation mechanism that
encourages weights to compete across and inside layers based on their
importance scores in an end-to-end manner. Extensive experiments are conducted
on classification, segmentation, and generation tasks using different
pre-trained vision models. The results show that SNELLA achieves SOTA
performance with low memory usage. Notably, SNELLA obtains 1.8% (91.9% v.s.
90.1%) higher Top-1 accuracy on the FGVC benchmark compared to SPT-LoRA.
Compared to previous methods, SNELLA achieves a memory reduction of 31.1%-39.9%
across models with parameter scales from 86M to 632M. Our source codes are
available at https://github.com/ssfgunner/SNELL.

</details>


### [18] [Enhancing CLIP Robustness via Cross-Modality Alignment](https://arxiv.org/abs/2510.24038)
*Xingyu Zhu,Beier Zhu,Shuo Wang,Kesen Zhao,Hanwang Zhang*

Main category: cs.CV

TL;DR: 本研究提出COLA框架，通过最优传输实现图文特征对齐，在多项零样本任务中显著提升模型对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）如CLIP虽然在零样本分类中泛化能力强，但在对抗扰动下表现脆弱，主要原因是图像与文本特征间存在显著的不对齐。

Method: 提出了一种基于最优传输的跨模态对齐框架COLA，通过在特征空间恢复图文对齐与结构一致性来缓解对抗失配。具体包括：（1）将对抗图像嵌入投影到由类别文本特征张成的子空间中过滤非语义失真；（2）将图像和文本建模为多视图下的离散分布，通过OT优化其对齐。

Result: 在14个零样本分类基准上验证，COLA在ImageNet及其变体下对抗攻击条件中平均提升6.7%，同时在干净样本上保持高准确率。

Conclusion: COLA有效增强了CLIP等模型在对抗场景下的鲁棒性，且无需训练、可与已有微调模型结合。

Abstract: Vision-language models (VLMs) such as CLIP demonstrate strong generalization
in zero-shot classification but remain highly vulnerable to adversarial
perturbations. Existing methods primarily focus on adversarial fine-tuning or
prompt optimization; they often overlook the gaps in CLIP's encoded features,
which is shown as the text and image features lie far apart from each other.
This misalignment is significantly amplified under adversarial perturbations,
leading to severe degradation in classification performance. To address this
problem, we propose Cross-modality Alignment, dubbed COLA, an optimal
transport-based framework that explicitly addresses adversarial misalignment by
restoring both global image-text alignment and local structural consistency in
the feature space. (1) COLA first projects adversarial image embeddings onto a
subspace spanned by class text features, effectively filtering out non-semantic
distortions while preserving discriminative information. (2) It then models
images and texts as discrete distributions over multiple augmented views and
refines their alignment via OT, with the subspace projection seamlessly
integrated into the cost computation. This design ensures stable cross-modal
alignment even under adversarial conditions. COLA is training-free and
compatible with existing fine-tuned models. Extensive evaluations across 14
zero-shot classification benchmarks demonstrate the effectiveness of COLA,
especially with an average improvement of 6.7% on ImageNet and its variants
under PGD adversarial attacks, while maintaining high accuracy on clean
samples.

</details>


### [19] [Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification](https://arxiv.org/abs/2510.24078)
*William Yang,Xindi Wu,Zhiwei Deng,Esin Tureci,Olga Russakovsky*

Main category: cs.CV

TL;DR: BOB通过类无关属性条件化微调T2I模型，有效提升少样本分类性能并减少过拟合。


<details>
  <summary>Details</summary>
Motivation: 当前通过T2I模型生成用于分类的合成数据仍面临效果有限和过拟合的问题，尤其是在少样本情况下，因此需要一种方法在提升数据质量的同时保持多样性。

Method: 利用类无关属性（背景、姿态等）对T2I模型进行条件化微调，并在生成时对这些属性进行边缘化，从而在保持生成多样性的同时降低过拟合。

Result: 论文提出了一种名为BOB（BeyondOBjects）的微调策略，用于改进文本到图像（T2I）模型生成的合成训练数据，以提升少样本细粒度分类的性能。该方法通过提取类无关属性（如场景背景、物体姿态），在微调时显式条件化并在生成时边缘化，从而减少过拟合并保持生成多样性。实验证明，BOB在多个基准测试中实现了最先进的性能。

Conclusion: BOB方法显著提升了少样本细粒度分类的表现，优于现有方法，在多数实验中取得更高准确率。

Abstract: Text-to-image (T2I) models are increasingly used for synthetic dataset
generation, but generating effective synthetic training data for classification
remains challenging. Fine-tuning a T2I model with a few real examples can help
improve the quality of synthetic training data; however, it may also cause
overfitting and reduce diversity in the generated samples. We propose a
fine-tuning strategy BOB (BeyondOBjects) to mitigate these concerns for
fine-grained classification. Given a small set of real examples, we first
extract class-agnostic attributes such as scene background and object pose. We
then explicitly condition on these attributes during fine-tuning of the T2I
model and marginalize them out during generation. This design mitigates
overfitting, preserves the T2I model's generative prior, reduces estimation
errors, and further minimizes unintended inter-class associations. Extensive
experiments across multiple T2I models, backbones, and datasets show that our
method achieves state-of-the-art performance in low-shot fine-grained
classification when augmented with synthetic data. Concretely, BOB outperforms
DataDream by 7.4% on the Aircraft dataset (from 50.0% to 57.4% when fine-tuning
a CLIP classifier with five real images augmented with 100 synthetic images).
In three of the four benchmarks, fine-tuning downstream models with 5 real
images augmented with BOB achieves better performance than fine-tuning with 10
real images. Collectively, BOB outperforms prior art in 18 of 24 experimental
settings, with 2+% accuracy improvements in 14 of these settings.

</details>


### [20] [OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation](https://arxiv.org/abs/2510.24093)
*Agus Gunawan,Samuel Teodoro,Yun Chen,Soo Ye Kim,Jihyong Oh,Munchurl Kim*

Main category: cs.CV

TL;DR: OmniText实现了多任务文本图像操作，解决了传统方法在文本删除和风格控制上的不足，性能领先且无需训练。


<details>
  <summary>Details</summary>
Motivation: 现有扩散式文本修复方法无法有效处理文本删除、风格控制和重复字问题，限制了文本图像操作任务的广泛应用。

Method: 提出了一个无需训练的通用文本图像操作框架OmniText，通过研究交叉注意力和自注意力机制的特性，实现文本删除、风格控制和内容编辑；在潜变量优化框架中设计了新的损失函数，包括交叉注意力内容损失和自注意力风格损失。

Result: OmniText不仅能完成文本删除、重定位、缩放、插入与编辑等多种任务，还在多个基准中达到最先进性能，并构建了新的评测数据集OmniText-Bench。

Conclusion: OmniText作为首个通用文本图像操作框架，通过注意力机制调控与优化损失设计，实现了多样化TIM任务的高性能与可控编辑，为后续研究提供了统一基准与方向。

Abstract: Recent advancements in diffusion-based text synthesis have demonstrated
significant performance in inserting and editing text within images via
inpainting. However, despite the potential of text inpainting methods, three
key limitations hinder their applicability to broader Text Image Manipulation
(TIM) tasks: (i) the inability to remove text, (ii) the lack of control over
the style of rendered text, and (iii) a tendency to generate duplicated
letters. To address these challenges, we propose OmniText, a training-free
generalist capable of performing a wide range of TIM tasks. Specifically, we
investigate two key properties of cross- and self-attention mechanisms to
enable text removal and to provide control over both text styles and content.
Our findings reveal that text removal can be achieved by applying
self-attention inversion, which mitigates the model's tendency to focus on
surrounding text, thus reducing text hallucinations. Additionally, we
redistribute cross-attention, as increasing the probability of certain text
tokens reduces text hallucination. For controllable inpainting, we introduce
novel loss functions in a latent optimization framework: a cross-attention
content loss to improve text rendering accuracy and a self-attention style loss
to facilitate style customization. Furthermore, we present OmniText-Bench, a
benchmark dataset for evaluating diverse TIM tasks. It includes input images,
target text with masks, and style references, covering diverse applications
such as text removal, rescaling, repositioning, and insertion and editing with
various styles. Our OmniText framework is the first generalist method capable
of performing diverse TIM tasks. It achieves state-of-the-art performance
across multiple tasks and metrics compared to other text inpainting methods and
is comparable with specialist methods.

</details>


### [21] [Enhancing Pre-trained Representation Classifiability can Boost its Interpretability](https://arxiv.org/abs/2510.24105)
*Shufan Shen,Zhaobo Qi,Junshu Sun,Qingming Huang,Qi Tian,Shuhui Wang*

Main category: cs.CV

TL;DR: 本文提出IIS指标量化预训练视觉模型的表示可解释性，发现可解释性与可分类性正相关，可同时优化。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉模型主要关注在下游任务中的可分类性，但实际应用中对表示的可解释性也提出了新的需求。目前尚不清楚预训练表示是否能同时具备高可解释性和高可分类性。

Method: 作者通过量化表示中可解释语义的比例来评估可解释性，提出了一个新的指标——固有可解释性分数（Inherent Interpretability Score，IIS），用于测量信息损失并评估表示的可解释性。

Result: 实验发现可解释性与可分类性之间存在正相关关系，即更易分类的表示能提供更多可被解释语义。

Conclusion: 这项研究证明了可解释性和可分类性能够统一提升，意味着通过优化可解释性可以同时提高模型的分类性能，并在保持高预测准确度的同时实现更好的模型解释。

Abstract: The visual representation of a pre-trained model prioritizes the
classifiability on downstream tasks, while the widespread applications for
pre-trained visual models have posed new requirements for representation
interpretability. However, it remains unclear whether the pre-trained
representations can achieve high interpretability and classifiability
simultaneously. To answer this question, we quantify the representation
interpretability by leveraging its correlation with the ratio of interpretable
semantics within the representations. Given the pre-trained representations,
only the interpretable semantics can be captured by interpretations, whereas
the uninterpretable part leads to information loss. Based on this fact, we
propose the Inherent Interpretability Score (IIS) that evaluates the
information loss, measures the ratio of interpretable semantics, and quantifies
the representation interpretability. In the evaluation of the representation
interpretability with different classifiability, we surprisingly discover that
the interpretability and classifiability are positively correlated, i.e.,
representations with higher classifiability provide more interpretable
semantics that can be captured in the interpretations. This observation further
supports two benefits to the pre-trained representations. First, the
classifiability of representations can be further improved by fine-tuning with
interpretability maximization. Second, with the classifiability improvement for
the representations, we obtain predictions based on their interpretations with
less accuracy degradation. The discovered positive correlation and
corresponding applications show that practitioners can unify the improvements
in interpretability and classifiability for pre-trained vision models. Codes
are available at https://github.com/ssfgunner/IIS.

</details>


### [22] [UHKD: A Unified Framework for Heterogeneous Knowledge Distillation via Frequency-Domain Representations](https://arxiv.org/abs/2510.24116)
*Fengming Yu,Haiwei Pan,Kejia Zhang,Jian Guan,Haiying Jiang*

Main category: cs.CV

TL;DR: 本文提出UHKD框架，通过频域特征对齐解决异构模型蒸馏中间表征不一致问题，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法多针对同构模型设计，对异构模型尤其是涉及中间特征的场景表现不佳。作者希望解决教师与学生模型架构差异带来的语义不一致问题，充分利用中间层的语义信息以提升蒸馏效果。

Method: 提出一种统一异构知识蒸馏框架（UHKD），利用傅里叶变换在频域中处理中间特征。通过特征变换模块（FTM）生成教师特征的紧凑频域表示，并使用可学习的特征对齐模块（FAM）实现学生特征的多层匹配。训练目标结合中间特征的均方误差与logits上的KL散度。

Result: 在CIFAR-100和ImageNet-1K数据集上，UHKD相较最新方法分别提升5.59%和0.83%的准确率，证明其在异构模型间的特征统一和知识迁移方面效果显著。

Conclusion: UHKD有效缓解了异构架构之间的表示差异，实现了跨结构的知识传递，为视觉模型的高效部署提供了新思路。

Abstract: Knowledge distillation (KD) is an effective model compression technique that
transfers knowledge from a high-performance teacher to a lightweight student,
reducing cost while maintaining accuracy. In visual applications, where
large-scale image models are widely used, KD enables efficient deployment.
However, architectural diversity introduces semantic discrepancies that hinder
the use of intermediate representations. Most existing KD methods are designed
for homogeneous models and degrade in heterogeneous scenarios, especially when
intermediate features are involved. Prior studies mainly focus on the logits
space, making limited use of the semantic information in intermediate layers.
To address this limitation, Unified Heterogeneous Knowledge Distillation (UHKD)
is proposed as a framework that leverages intermediate features in the
frequency domain for cross-architecture transfer. Fourier transform is applied
to capture global feature information, alleviating representational
discrepancies between heterogeneous teacher-student pairs. A Feature
Transformation Module (FTM) produces compact frequency-domain representations
of teacher features, while a learnable Feature Alignment Module (FAM) projects
student features and aligns them via multi-level matching. Training is guided
by a joint objective combining mean squared error on intermediate features with
Kullback-Leibler divergence on logits. Experiments on CIFAR-100 and ImageNet-1K
demonstrate gains of 5.59% and 0.83% over the latest method, highlighting UHKD
as an effective approach for unifying heterogeneous representations and
enabling efficient utilization of visual knowledge

</details>


### [23] [ETC: training-free diffusion models acceleration with Error-aware Trend Consistency](https://arxiv.org/abs/2510.24129)
*Jiajian Xie,Hubery Yin,Chen Li,Zhou Zhao,Shengyu Zhang*

Main category: cs.CV

TL;DR: ETC框架通过趋势预测与误差容忍机制加速扩散模型采样，保持生成一致性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型加速方法忽略了去噪趋势与误差控制，导致多步复用时轨迹偏移与生成结果不一致，亟需一种兼顾加速与稳定性的解决方案。

Method: 1）利用扩散轨迹的平滑连续性设计一致趋势预测器，以稳定的方式预测未来去噪方向；2）通过模型特定的误差容忍搜索机制确定纠正阈值，实现语义到质量的平稳过渡。

Result: 本文提出了Error-aware Trend Consistency（ETC）框架，用于在不降低生成质量的前提下加速扩散模型采样。该方法利用历史去噪趋势预测未来方向，并通过误差控制机制使多步近似采样保持一致，从而减少生成结果的偏差。实验表明，ETC在相对较低的质量损失下实现了2.65倍的加速效果。

Conclusion: ETC能够有效加速扩散模型采样过程，同时保持生成结果的稳定性与一致性，明显优于现有训练自由加速方法。

Abstract: Diffusion models have achieved remarkable generative quality but remain
bottlenecked by costly iterative sampling. Recent training-free methods
accelerate diffusion process by reusing model outputs. However, these methods
ignore denoising trends and lack error control for model-specific tolerance,
leading to trajectory deviations under multi-step reuse and exacerbating
inconsistencies in the generated results. To address these issues, we introduce
Error-aware Trend Consistency (ETC), a framework that (1) introduces a
consistent trend predictor that leverages the smooth continuity of diffusion
trajectories, projecting historical denoising patterns into stable future
directions and progressively distributing them across multiple approximation
steps to achieve acceleration without deviating; (2) proposes a model-specific
error tolerance search mechanism that derives corrective thresholds by
identifying transition points from volatile semantic planning to stable quality
refinement. Experiments show that ETC achieves a 2.65x acceleration over FLUX
with negligible (-0.074 SSIM score) degradation of consistency.

</details>


### [24] [Compositional Image Synthesis with Inference-Time Scaling](https://arxiv.org/abs/2510.24133)
*Minsuk Ji,Sanghyeok Lee,Namhyuk Ahn*

Main category: cs.CV

TL;DR: 本文提出一种无训练框架，通过对象中心与自我修正机制提升文本到图像模型的布局一致性和美感。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型难以准确表示对象数量、属性和空间关系，缺乏构图一致性，因此需要改进生成对齐度的方法。

Method: 利用大型语言模型(LLMs)从文本生成显式布局，并在图像生成过程中注入这些布局；再通过对象中心视觉语言模型(VLM)对生成图像进行多轮筛选与重排序，从而实现自我修正。

Result: 实验结果表明，所提出的框架能够在保持图像美感的同时，使生成场景与输入提示在布局上更为一致，超越了近期主流模型。

Conclusion: 该方法在不重新训练模型的情况下显著提升了生成图像与文本提示的一致性，优于现有模型。

Abstract: Despite their impressive realism, modern text-to-image models still struggle
with compositionality, often failing to render accurate object counts,
attributes, and spatial relations. To address this challenge, we present a
training-free framework that combines an object-centric approach with
self-refinement to improve layout faithfulness while preserving aesthetic
quality. Specifically, we leverage large language models (LLMs) to synthesize
explicit layouts from input prompts, and we inject these layouts into the image
generation process, where a object-centric vision-language model (VLM) judge
reranks multiple candidates to select the most prompt-aligned outcome
iteratively. By unifying explicit layout-grounding with self-refine-based
inference-time scaling, our framework achieves stronger scene alignment with
prompts compared to recent text-to-image models. The code are available at
https://github.com/gcl-inha/ReFocus.

</details>


### [25] [VC4VG: Optimizing Video Captions for Text-to-Video Generation](https://arxiv.org/abs/2510.24134)
*Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin*

Main category: cs.CV

TL;DR: 本文提出VC4VG字幕优化框架及VC4VG-Bench评测基准，通过多维度优化视频字幕，显著提升文本生成视频模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现有T2V训练中视频文本配对质量关键，但缺乏针对视频生成需求的字幕优化方法，因此亟需系统性研究和评测框架。

Method: 从文本生成视频（T2V）视角出发，分析视频字幕的关键构成要素，提出多维度字幕设计方法；并构建名为VC4VG-Bench的基准，包含细粒度、多维度、必要性分级的指标体系用于评估。

Result: 通过大规模T2V微调实验，证实优化后的字幕质量与生成视频效果高度相关，显著提升模型生成的连贯性与对指令的响应效果。

Conclusion: 高质量视频字幕的优化对提升文本生成视频模型的表现具有显著影响。VC4VG框架和新的评测基准有效验证了改进字幕设计能增强视频生成的连贯性和指令对齐度。

Abstract: Recent advances in text-to-video (T2V) generation highlight the critical role
of high-quality video-text pairs in training models capable of producing
coherent and instruction-aligned videos. However, strategies for optimizing
video captions specifically for T2V training remain underexplored. In this
paper, we introduce VC4VG (Video Captioning for Video Generation), a
comprehensive caption optimization framework tailored to the needs of T2V
models.We begin by analyzing caption content from a T2V perspective,
decomposing the essential elements required for video reconstruction into
multiple dimensions, and proposing a principled caption design methodology. To
support evaluation, we construct VC4VG-Bench, a new benchmark featuring
fine-grained, multi-dimensional, and necessity-graded metrics aligned with
T2V-specific requirements.Extensive T2V fine-tuning experiments demonstrate a
strong correlation between improved caption quality and video generation
performance, validating the effectiveness of our approach. We release all
benchmark tools and code at https://github.com/qyr0403/VC4VG to support further
research.

</details>


### [26] [Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning](https://arxiv.org/abs/2510.24152)
*Aodi Wu,Xubo Luo*

Main category: cs.CV

TL;DR: 论文通过混合提示路由与空间结构化推理，提高视觉语言模型在自动驾驶任务中对不同场景的理解和容错能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提高视觉语言模型在自动驾驶场景理解中的表现，针对感知、预测、规划和数据损坏检测等安全关键任务的准确性和鲁棒性问题。

Method: 论文提出一个系统化框架，包含四个核心组件：1）混合提示路由器对问题进行分类并分派至特定任务提示；2）任务特定提示嵌入坐标系统、空间推理规则、角色扮演和少样本示例；3）视觉组合模块根据任务需求整合多视角图像及历史帧；4）根据任务调整模型推理参数（如temperature、top-p等）以提高输出质量。

Result: 该方法基于Qwen2.5-VL-72B模型，在Phase-1（干净数据）上取得平均准确率70.87%，在Phase-2（损坏数据）上取得72.85%，显示结构化提示和空间约束能显著提升模型表现。

Conclusion: 研究验证了系统化提示设计与空间推理结合的有效性，为视觉语言模型在安全关键的自动驾驶领域应用提供了新的解决方案。

Abstract: This technical report presents our solution for the RoboSense Challenge at
IROS 2025, which evaluates Vision-Language Models (VLMs) on autonomous driving
scene understanding across perception, prediction, planning, and corruption
detection tasks. We propose a systematic framework built on four core
components. First, a Mixture-of-Prompts router classifies questions and
dispatches them to task-specific expert prompts, eliminating interference
across diverse question types. Second, task-specific prompts embed explicit
coordinate systems, spatial reasoning rules, role-playing,
Chain-of-Thought/Tree-of-Thought reasoning, and few-shot examples tailored to
each task. Third, a visual assembly module composes multi-view images with
object crops, magenta markers, and adaptive historical frames based on question
requirements. Fourth, we configure model inference parameters (temperature,
top-p, message roles) per task to optimize output quality. Implemented on
Qwen2.5-VL-72B, our approach achieves 70.87% average accuracy on Phase-1 (clean
data) and 72.85% on Phase-2 (corrupted data), demonstrating that structured
prompting and spatial grounding substantially enhance VLM performance on
safety-critical autonomous driving tasks. Code and prompt are available at
https://github.com/wuaodi/UCAS-CSU-phase2.

</details>


### [27] [Vanish into Thin Air: Cross-prompt Universal Adversarial Attacks for SAM2](https://arxiv.org/abs/2510.24195)
*Ziqi Zhou,Yifan Hu,Yufei Song,Zijing Li,Shengshan Hu,Leo Yu Zhang,Dezhong Yao,Long Zheng,Hai Jin*

Main category: cs.CV

TL;DR: 本文研究视频分割模型SAM2在对抗样本攻击下的脆弱性，并提出一种新型跨提示通用对抗攻击方法UAP-SAM2。


<details>
  <summary>Details</summary>
Motivation: 由于SAM2在视频分割中的高泛化能力，其鲁棒性尚未得到研究，且现有针对SAM的攻击无法直接迁移至SAM2，因此需要新的攻击方法。

Method: 设计了跨提示目标扫描策略以降低提示依赖，并构建双语义偏差框架来同时扰乱单帧语义和跨帧语义一致性，从而生成通用对抗扰动。

Result: 实验结果显示UAP-SAM2在六个数据集上的两种分割任务中均显著优于当前最先进攻击，验证了其跨提示迁移性和有效性。

Conclusion: UAP-SAM2在多个数据集和两种分割任务上显著优于现有攻击方法，表明该方法有效提升了对SAM2的攻击性能。

Abstract: Recent studies reveal the vulnerability of the image segmentation foundation
model SAM to adversarial examples. Its successor, SAM2, has attracted
significant attention due to its strong generalization capability in video
segmentation. However, its robustness remains unexplored, and it is unclear
whether existing attacks on SAM can be directly transferred to SAM2. In this
paper, we first analyze the performance gap of existing attacks between SAM and
SAM2 and highlight two key challenges arising from their architectural
differences: directional guidance from the prompt and semantic entanglement
across consecutive frames. To address these issues, we propose UAP-SAM2, the
first cross-prompt universal adversarial attack against SAM2 driven by dual
semantic deviation. For cross-prompt transferability, we begin by designing a
target-scanning strategy that divides each frame into k regions, each randomly
assigned a prompt, to reduce prompt dependency during optimization. For
effectiveness, we design a dual semantic deviation framework that optimizes a
UAP by distorting the semantics within the current frame and disrupting the
semantic consistency across consecutive frames. Extensive experiments on six
datasets across two segmentation tasks demonstrate the effectiveness of the
proposed method for SAM2. The comparative results show that UAP-SAM2
significantly outperforms state-of-the-art (SOTA) attacks by a large margin.

</details>


### [28] [MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive Visual Generation Acceleration](https://arxiv.org/abs/2510.24211)
*Junhyuk So,Hyunho Kook,Chaeyeon Jang,Eunhyeok Park*

Main category: cs.CV

TL;DR: 本文提出了一个用于加速自回归视觉生成的无训练、无损并行解码框架MC-SJD。


<details>
  <summary>Details</summary>
Motivation: 现有自回归视觉生成方法推理速度极慢，每个样本需生成成千上万次token，严重阻碍了实际应用。

Method: 作者基于信息论耦合思想扩展了Speculative Jacobi Decoding (SJD)，通过最大化相邻迭代间草稿token相同的概率提高接受率，并保持无损特性。

Result: 实验验证MC-SJD在图像与视频生成任务中显著提升了解码速度，同时保持输出质量。

Conclusion: MC-SJD在不降低生成质量的前提下，实现了图像生成约4.2倍、视频生成约13.3倍的加速。

Abstract: While autoregressive (AR) modeling has recently emerged as a new paradigm in
visual generation, its practical adoption is severely constrained by the slow
inference speed of per-token generation, which often requires thousands of
steps to produce a single sample. To address this challenge, we propose MC-SJD,
a training-free, lossless parallel decoding framework designed to accelerate AR
visual generation by extending the recently introduced Speculative Jacobi
Decoding (SJD). Although SJD shows strong potential for accelerating AR
generation, we demonstrate that token instability across iterations
significantly reduces the acceptance rate, a limitation that primarily arises
from the independent sampling process used during draft token generation. To
overcome this, we introduce MC-SJD, an information-theoretic approach based on
coupling, which substantially accelerates standard SJD by maximizing the
probability of sampling identical draft tokens across consecutive iterations,
all while preserving its lossless property. Remarkably, this method requires
only a single-line modification to the existing algorithm, yet achieves
substantial performance gains, delivering up to a ~4.2x acceleration in image
generation and ~13.3x acceleration in video generation compared to standard AR
decoding, without any degradation in output quality.

</details>


### [29] [Beyond Inference Intervention: Identity-Decoupled Diffusion for Face Anonymization](https://arxiv.org/abs/2510.24213)
*Haoxin Yang,Yihong Lin,Jingdan Kang,Xuemiao Xu,Yue Li,Cheng Xu,Shengfeng He*

Main category: cs.CV

TL;DR: ID²Face 通过训练阶段的身份-非身份解耦实现高质量、无推理优化的人脸匿名化。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的人脸匿名化方法依赖推理阶段干预，会引入分布偏移并破坏图像真实性。作者希望通过在训练阶段实现身份与非身份的结构性解耦，从根本上改进匿名化效果和可控性。

Method: 作者设计了一个条件扩散模型，结合身份掩码学习、身份变分自编码器（VAE）建模身份特征、双向潜空间对齐以及软门控融合机制。同时提出基于重组的重建损失和正交身份映射策略，以确保身份与非身份特征的显式解耦。

Result: 本文提出了一种名为 ID²Face 的人脸匿名化框架，旨在在保持非身份特征的同时有效去除身份信息。现有扩散模型需要在推理阶段进行干预，如负引导或基于能量的优化，这会导致分布偏移和特征纠缠。ID²Face 则通过训练阶段的结构设计解决该问题，消除了推理时的优化需求。

Conclusion: 实验结果显示，ID²Face 在视觉质量、身份信息抑制及数据可用性方面优于现有方法。

Abstract: Face anonymization aims to conceal identity information while preserving
non-identity attributes. Mainstream diffusion models rely on inference-time
interventions such as negative guidance or energy-based optimization, which are
applied post-training to suppress identity features. These interventions often
introduce distribution shifts and entangle identity with non-identity
attributes, degrading visual fidelity and data utility. To address this, we
propose \textbf{ID\textsuperscript{2}Face}, a training-centric anonymization
framework that removes the need for inference-time optimization. The rationale
of our method is to learn a structured latent space where identity and
non-identity information are explicitly disentangled, enabling direct and
controllable anonymization at inference. To this end, we design a conditional
diffusion model with an identity-masked learning scheme. An Identity-Decoupled
Latent Recomposer uses an Identity Variational Autoencoder to model identity
features, while non-identity attributes are extracted from same-identity pairs
and aligned through bidirectional latent alignment. An Identity-Guided Latent
Harmonizer then fuses these representations via soft-gating conditioned on
noisy feature prediction. The model is trained with a recomposition-based
reconstruction loss to enforce disentanglement. At inference, anonymization is
achieved by sampling a random identity vector from the learned identity space.
To further suppress identity leakage, we introduce an Orthogonal Identity
Mapping strategy that enforces orthogonality between sampled and source
identity vectors. Experiments demonstrate that ID\textsuperscript{2}Face
outperforms existing methods in visual quality, identity suppression, and
utility preservation.

</details>


### [30] [SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs](https://arxiv.org/abs/2510.24214)
*Jinhong Deng,Wen Li,Joey Tianyi Zhou,Yang He*

Main category: cs.CV

TL;DR: SCOPE方法结合显著性与覆盖性，更高效地剪枝视觉token，减少计算量并保持语义完整。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅基于显著性选择视觉token，导致语义不完整；因此需要一种能兼顾显著性与语义覆盖的剪枝策略以提升模型性能与计算效率。

Method: 通过定义token之间关系的集合覆盖度和token覆盖增益，并结合显著性得分，迭代选取最高SCOPE得分的token，实现高效的视觉token剪枝。

Result: 本文针对多模态大模型（MLLMs）中视觉token数量庞大、计算开销高以及冗余问题，提出了一种新的视觉token剪枝策略——SCOPE（基于显著性与覆盖性的高效剪枝方法）。该方法综合考虑token的显著性与语义覆盖性，定义了集合覆盖和token覆盖增益，并依此迭代选择最具综合价值的token，从而在降低计算成本的同时保持语义完整性。

Conclusion: SCOPE在多个视觉语言理解任务上超越现有方法，有效提升了多模态大模型的效率与性能。

Abstract: Multimodal Large Language Models (MLLMs) typically process a large number of
visual tokens, leading to considerable computational overhead, even though many
of these tokens are redundant. Existing visual token pruning methods primarily
focus on selecting the most salient tokens based on attention scores, resulting
in the semantic incompleteness of the selected tokens. In this paper, we
propose a novel visual token pruning strategy, called
\textbf{S}aliency-\textbf{C}overage \textbf{O}riented token \textbf{P}runing
for \textbf{E}fficient MLLMs (SCOPE), to jointly model both the saliency and
coverage of the selected visual tokens to better preserve semantic
completeness. Specifically, we introduce a set-coverage for a given set of
selected tokens, computed based on the token relationships. We then define a
token-coverage gain for each unselected token, quantifying how much additional
coverage would be obtained by including it. By integrating the saliency score
into the token-coverage gain, we propose our SCOPE score and iteratively select
the token with the highest SCOPE score. We conduct extensive experiments on
multiple vision-language understanding benchmarks using the LLaVA-1.5 and
LLaVA-Next models. Experimental results demonstrate that our method
consistently outperforms prior approaches. Our code is available at
\href{https://github.com/kinredon/SCOPE}{https://github.com/kinredon/SCOPE}.

</details>


### [31] [DeshadowMamba: Deshadowing as 1D Sequential Similarity](https://arxiv.org/abs/2510.24260)
*Zhaotong Yang,Yi Chen,Yanying Li,Shengfeng He,Yangyang Xu,Junyu Dong,Jian Yang,Yong Du*

Main category: cs.CV

TL;DR: 该论文提出了基于序列建模方法的图像阴影去除新模型DeshadowMamba。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力机制的阴影去除方法容易混淆光照信息，产生结构扭曲和颜色不一致问题。作者希望改进模型以更好地捕捉全局上下文并保持色彩一致性。

Method: 作者将Mamba选择性状态空间模型应用于阴影去除任务，并设计了CrossGate方向调制机制以注入阴影感知相似性，同时引入ColorShift正则化，通过对比学习稳定颜色恢复。

Result: 该模型在多个公开数据集上取得了最新的视觉质量和良好的量化性能。

Conclusion: 该工作通过将序列建模方式与阴影特征相结合，改善了阴影去除的结构完整性和色彩一致性，验证了DeshadowMamba在性能上的显著优势。

Abstract: Recent deep models for image shadow removal often rely on attention-based
architectures to capture long-range dependencies. However, their fixed
attention patterns tend to mix illumination cues from irrelevant regions,
leading to distorted structures and inconsistent colors. In this work, we
revisit shadow removal from a sequence modeling perspective and explore the use
of Mamba, a selective state space model that propagates global context through
directional state transitions. These transitions yield an efficient global
receptive field while preserving positional continuity. Despite its potential,
directly applying Mamba to image data is suboptimal, since it lacks awareness
of shadow-non-shadow semantics and remains susceptible to color interference
from nearby regions. To address these limitations, we propose CrossGate, a
directional modulation mechanism that injects shadow-aware similarity into
Mamba's input gate, allowing selective integration of relevant context along
transition axes. To further ensure appearance fidelity, we introduce ColorShift
regularization, a contrastive learning objective driven by global color
statistics. By synthesizing structured informative negatives, it guides the
model to suppress color contamination and achieve robust color restoration.
Together, these components adapt sequence modeling to the structural integrity
and chromatic consistency required for shadow removal. Extensive experiments on
public benchmarks demonstrate that DeshadowMamba achieves state-of-the-art
visual quality and strong quantitative performance.

</details>


### [32] [Training-free Source Attribution of AI-generated Images via Resynthesis](https://arxiv.org/abs/2510.24278)
*Pietro Bongini,Valentina Molinari,Andrea Costanzo,Benedetta Tondi,Mauro Barni*

Main category: cs.CV

TL;DR: 本文提出基于再合成的单样本图像归属方法与新数据集，在样本稀缺场景下优于现有少样本方法。


<details>
  <summary>Details</summary>
Motivation: 在合成图像来源归属任务中，特别是在样本稀缺或需要少样本、零样本分类的情况下，现有方法表现不佳，因此研究者希望提出一种新的无需训练的归属方法。

Method: 提出一种基于图像再合成的训练自由单样本归属方法。首先生成描述待分析图像的文本提示，再用该提示通过候选生成源模型重新合成图像，然后在特征空间中比较原图与再合成图的相似度，将图像归属于最接近的生成模型。

Result: 提出的新数据集包含来自商业与开源文本生成图像模型的人脸图像，可用于测试各种原型归属方法。实验结果显示该基于再合成的方法在少样本场景中优于当前最先进的少样本归属方法。

Conclusion: 该研究表明，在数据有限条件下，利用图像再合成进行归属是有效的。新提出的数据集具有挑战性且为后续研究提供了有价值的基准。

Abstract: Synthetic image source attribution is a challenging task, especially in data
scarcity conditions requiring few-shot or zero-shot classification
capabilities. We present a new training-free one-shot attribution method based
on image resynthesis. A prompt describing the image under analysis is
generated, then it is used to resynthesize the image with all the candidate
sources. The image is attributed to the model which produced the resynthesis
closest to the original image in a proper feature space. We also introduce a
new dataset for synthetic image attribution consisting of face images from
commercial and open-source text-to-image generators. The dataset provides a
challenging attribution framework, useful for developing new attribution models
and testing their capabilities on different generative architectures. The
dataset structure allows to test approaches based on resynthesis and to compare
them to few-shot methods. Results from state-of-the-art few-shot approaches and
other baselines show that the proposed resynthesis method outperforms existing
techniques when only a few samples are available for training or fine-tuning.
The experiments also demonstrate that the new dataset is a challenging one and
represents a valuable benchmark for developing and evaluating future few-shot
and zero-shot methods.

</details>


### [33] [ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model](https://arxiv.org/abs/2510.24285)
*Juntian Zhang,Song Jin,Chuanqi Cheng,Yuhan Liu,Yankai Lin,Xun Zhang,Yufei Zhang,Fei Jiang,Guojun Yin,Wei Lin,Rui Yan*

Main category: cs.CV

TL;DR: ViPER通过自举闭环强化学习机制提升VLM的细粒度视觉感知能力，实现Qwen系列显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在细粒度视觉感知方面受限，监督微调会削弱模型通用性，而强化微调更偏向文本推理，缺乏对视觉感知的强化。

Method: 提出ViPER框架，一种自举式的视觉感知强化方案，采用从粗到细的两阶段任务设计，结合图像级与实例级重建，并通过双阶段强化学习实现自我批评与自我预测的闭环训练。

Result: 在Qwen2.5-VL上应用ViPER后，形成Qwen-Viper模型系列，在七个综合基准上的平均性能提升1.7%，在细粒度视觉感知任务上提升最高达6.0%，表现超过多种场景的基线模型。

Conclusion: ViPER不仅验证了生成与理解之间的互促关系，还为开发更自治、更强感知的视觉语言模型提供了新范式。

Abstract: The limited capacity for fine-grained visual perception presents a critical
bottleneck for Vision-Language Models (VLMs) in real-world applications.
Addressing this is challenging due to the scarcity of high-quality data and the
limitations of existing methods: supervised fine-tuning (SFT) often compromises
general capabilities, while reinforcement fine-tuning (RFT) prioritizes textual
reasoning over visual perception. To bridge this gap, we propose a novel
two-stage task that structures visual perception learning as a coarse-to-fine
progressive process. Based on this task formulation, we develop ViPER, a
self-bootstrapping framework specifically designed to enable iterative
evolution through self-critiquing and self-prediction. By synergistically
integrating image-level and instance-level reconstruction with a two-stage
reinforcement learning strategy, ViPER establishes a closed-loop training
paradigm, where internally synthesized data directly fuel the enhancement of
perceptual ability. Applied to the Qwen2.5-VL family, ViPER produces the
Qwen-Viper series. With an average gain of 1.7% on seven comprehensive
benchmarks spanning various tasks and up to 6.0% on fine-grained perception,
Qwen-Viper consistently demonstrates superior performance across different
vision-language scenarios while maintaining generalizability. Beyond enabling
self-improvement in perceptual capabilities, ViPER provides concrete evidence
for the reciprocal relationship between generation and understanding, a
breakthrough to developing more autonomous and capable VLMs.

</details>


### [34] [Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning](https://arxiv.org/abs/2510.24321)
*Ivica Dimitrovski,Vlatko Spasev,Ivan Kitanovski*

Main category: cs.CV

TL;DR: 本文探讨了利用提示学习策略提升CLIP在遥感场景分类中的表现，验证了其在少样本与跨域任务中的优越性。


<details>
  <summary>Details</summary>
Motivation: 由于遥感影像标注成本高、数据稀缺，且CLIP等模型存在显著领域差异，直接应用于遥感场景分类效果不佳，因此需要一种高效、可迁移的适配方法。

Method: 本文采用提示学习（prompt learning）策略对大规模视觉语言模型（如CLIP）进行轻量化适配，用于遥感影像场景分类。研究系统比较了不同提示学习方法，包括Context Optimization、Conditional Context Optimization、Multi-modal Prompt Learning 和 Prompting with Self-Regulating Constraints，并与零样本CLIP和线性探针基线进行对比。

Result: 实验结果表明，提示学习方法在少样本遥感场景分类任务中普遍优于零样本CLIP和线性探针，尤其是带自调节约束的提示方法在跨域任务上表现最为稳健。

Conclusion: 研究表明，提示学习是一种高效、可扩展的解决方案，可有效缩小遥感影像与通用视觉语言模型之间的领域差距，为今后遥感智能分析研究提供了新方向。

Abstract: Remote sensing applications increasingly rely on deep learning for scene
classification. However, their performance is often constrained by the scarcity
of labeled data and the high cost of annotation across diverse geographic and
sensor domains. While recent vision-language models like CLIP have shown
promise by learning transferable representations at scale by aligning visual
and textual modalities, their direct application to remote sensing remains
suboptimal due to significant domain gaps and the need for task-specific
semantic adaptation. To address this critical challenge, we systematically
explore prompt learning as a lightweight and efficient adaptation strategy for
few-shot remote sensing image scene classification. We evaluate several
representative methods, including Context Optimization, Conditional Context
Optimization, Multi-modal Prompt Learning, and Prompting with Self-Regulating
Constraints. These approaches reflect complementary design philosophies: from
static context optimization to conditional prompts for enhanced generalization,
multi-modal prompts for joint vision-language adaptation, and semantically
regularized prompts for stable learning without forgetting. We benchmark these
prompt-learning methods against two standard baselines: zero-shot CLIP with
hand-crafted prompts and a linear probe trained on frozen CLIP features.
Through extensive experiments on multiple benchmark remote sensing datasets,
including cross-dataset generalization tests, we demonstrate that prompt
learning consistently outperforms both baselines in few-shot scenarios.
Notably, Prompting with Self-Regulating Constraints achieves the most robust
cross-domain performance. Our findings underscore prompt learning as a scalable
and efficient solution for bridging the domain gap in satellite and aerial
imagery, providing a strong foundation for future research in this field.

</details>


### [35] [Adaptive Knowledge Transferring with Switching Dual-Student Framework for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2510.24366)
*Thanh-Huy Nguyen,Hoang-Thien Nguyen,Ba-Thinh Lam,Vi Vu,Bach X. Nguyen,Jianhua Xing,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: 文章提出可切换双学生和损失感知指数移动平均机制，从而提升教师-学生框架的稳定性与分割精度，在医学图像半监督任务中表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有的教师-学生框架在半监督医学图像分割中表现优异，但存在教师与学生之间知识传递不可靠的问题，导致学习效果受限。

Method: 采用可切换的双学生架构，在每次迭代中选择最可靠的学生模型；同时引入损失感知指数移动平均法，使教师模型动态吸收学生的有效信息。

Result: 在多个3D医学图像分割数据集上，该方法超越当前的最新半监督分割方法，在有限监督条件下取得更高的分割准确率。

Conclusion: 新提出的可切换双学生架构与损失感知指数移动平均策略能显著提升半监督医学图像分割的性能。

Abstract: Teacher-student frameworks have emerged as a leading approach in
semi-supervised medical image segmentation, demonstrating strong performance
across various tasks. However, the learning effects are still limited by the
strong correlation and unreliable knowledge transfer process between teacher
and student networks. To overcome this limitation, we introduce a novel
switching Dual-Student architecture that strategically selects the most
reliable student at each iteration to enhance dual-student collaboration and
prevent error reinforcement. We also introduce a strategy of Loss-Aware
Exponential Moving Average to dynamically ensure that the teacher absorbs
meaningful information from students, improving the quality of pseudo-labels.
Our plug-and-play framework is extensively evaluated on 3D medical image
segmentation datasets, where it outperforms state-of-the-art semi-supervised
methods, demonstrating its effectiveness in improving segmentation accuracy
under limited supervision.

</details>


### [36] [Stroke Lesion Segmentation in Clinical Workflows: A Modular, Lightweight, and Deployment-Ready Tool](https://arxiv.org/abs/2510.24378)
*Yann Kerverdo,Florent Leray,Youwan Mahé,Stéphanie Leplaideur,Francesca Galassi*

Main category: cs.CV

TL;DR: StrokeSeg将复杂的研究级中风分割模型转化为轻量级、可部署的临床工具，并保持原始性能。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习框架（如nnU-Net）在脑损伤分割任务中表现优异，但由于依赖复杂和设计单一，临床部署困难。

Method: 提出了StrokeSeg框架，将研究级的中风病灶分割模型转化为可部署的应用。框架采用模块化设计，将预处理、推理和后处理解耦：预处理使用Anima工具箱并生成BIDS格式输出，推理采用ONNX Runtime与Float16量化以减小模型体积约50%。

Result: 在包含300例亚急性及慢性中风受试者的测试集上，StrokeSeg的分割性能与原PyTorch管线几乎一致（Dice差异小于10^-3）。

Conclusion: StrokeSeg能在保持高性能的同时，显著提升研究管线的便携性与临床可用性。

Abstract: Deep learning frameworks such as nnU-Net achieve state-of-the-art performance
in brain lesion segmentation but remain difficult to deploy clinically due to
heavy dependencies and monolithic design. We introduce \textit{StrokeSeg}, a
modular and lightweight framework that translates research-grade stroke lesion
segmentation models into deployable applications. Preprocessing, inference, and
postprocessing are decoupled: preprocessing relies on the Anima toolbox with
BIDS-compliant outputs, and inference uses ONNX Runtime with \texttt{Float16}
quantisation, reducing model size by about 50\%. \textit{StrokeSeg} provides
both graphical and command-line interfaces and is distributed as Python scripts
and as a standalone Windows executable. On a held-out set of 300 sub-acute and
chronic stroke subjects, segmentation performance was equivalent to the
original PyTorch pipeline (Dice difference $<10^{-3}$), demonstrating that
high-performing research pipelines can be transformed into portable, clinically
usable tools.

</details>


### [37] [When are radiology reports useful for training medical image classifiers?](https://arxiv.org/abs/2510.24385)
*Herman Bergström,Zhongqi Yue,Fredrik D. Johansson*

Main category: cs.CV

TL;DR: 该研究系统评估了如何在医学影像分类中合理利用放射科报告。结果表明，文本辅助预训练和微调效果取决于标签与报告的相关性，微调阶段加入报告常带来更大收益。


<details>
  <summary>Details</summary>
Motivation: 医学影像常伴随放射科报告，报告中包含丰富的专家注释，但依赖人工阅读报告进行临床预测耗时且需专业人员，因此作者希望探讨如何在训练阶段利用报告信息提升仅基于图像的分类模型性能。

Method: 作者系统研究了在不同任务（诊断与预后，如12个月再入院预测）及不同训练集规模下，将放射科报告用于预训练和微调的不同策略，并比较了基于图文对齐的预训练方法与单纯使用文本辅助的方式。

Result: 研究发现：在标签与文本高度相关时，使用报告进行预训练有助于下游分类；但若标签与文本关联弱，显式图文对齐反而可能有害。微调阶段引入报告往往能显著提高性能，有时影响甚至超过预训练方法本身。

Conclusion: 论文得出明确结论：应根据任务特性与标签-文本相关性，有选择地在预训练或微调阶段使用放射科报告，以最大化医学影像分类性能，并指出该领域仍存在研究空白。

Abstract: Medical images used to train machine learning models are often accompanied by
radiology reports containing rich expert annotations. However, relying on these
reports as inputs for clinical prediction requires the timely manual work of a
trained radiologist. This raises a natural question: when can radiology reports
be leveraged during training to improve image-only classification? Prior works
are limited to evaluating pre-trained image representations by fine-tuning them
to predict diagnostic labels, often extracted from reports, ignoring tasks with
labels that are weakly associated with the text. To address this gap, we
conduct a systematic study of how radiology reports can be used during both
pre-training and fine-tuning, across diagnostic and prognostic tasks (e.g.,
12-month readmission), and under varying training set sizes. Our findings
reveal that: (1) Leveraging reports during pre-training is beneficial for
downstream classification tasks where the label is well-represented in the
text; however, pre-training through explicit image-text alignment can be
detrimental in settings where it's not; (2) Fine-tuning with reports can lead
to significant improvements and even have a larger impact than the pre-training
method in certain settings. These results provide actionable insights into when
and how to leverage privileged text data to train medical image classifiers
while highlighting gaps in current research.

</details>


### [38] [Unsupervised Detection of Post-Stroke Brain Abnormalities](https://arxiv.org/abs/2510.24398)
*Youwan Mahé,Elise Bannier,Stéphanie Leplaideur,Elisa Fromont,Francesca Galassi*

Main category: cs.CV

TL;DR: 使用健康对照数据训练的无监督生成模型REFLECT，可更可靠地检测卒中后MRI中的各种结构异常。


<details>
  <summary>Details</summary>
Motivation: 现有的监督式分割方法难以全面捕捉卒中后MRI图像中的局灶性与非局灶性结构异常，因此需要探索无监督的异常检测模型以提高结构异常识别的全面性。

Method: 本文使用一种基于流模型的生成式无监督算法REFLECT，分别在两种数据上训练：卒中患者的无病灶切片（ATLAS数据集）与健康对照数据（IXI数据集）。通过双专家注释的中心切片评估，并采用自由响应ROC（FROC）分析进行性能对比。

Result: 在ATLAS测试集中，使用IXI（健康对照数据）训练的模型在病灶分割方面的Dice系数从0.27提升到0.37，对非病灶异常的敏感性（FROC）从0.43提升到0.62。

Conclusion: 在完全健康解剖数据上训练的REFLECT模型更能准确建模正常结构变异性，从而提升了对卒中后局灶性与非局灶性结构异常的检测能力。

Abstract: Post-stroke MRI not only delineates focal lesions but also reveals secondary
structural changes, such as atrophy and ventricular enlargement. These
abnormalities, increasingly recognised as imaging biomarkers of recovery and
outcome, remain poorly captured by supervised segmentation methods. We evaluate
REFLECT, a flow-based generative model, for unsupervised detection of both
focal and non-lesional abnormalities in post-stroke patients. Using dual-expert
central-slice annotations on ATLAS data, performance was assessed at the object
level with Free-Response ROC analysis for anomaly maps. Two models were trained
on lesion-free slices from stroke patients (ATLAS) and on healthy controls
(IXI) to test the effect of training data. On ATLAS test subjects, the
IXI-trained model achieved higher lesion segmentation (Dice = 0.37 vs 0.27) and
improved sensitivity to non-lesional abnormalities (FROC = 0.62 vs 0.43).
Training on fully healthy anatomy improves the modelling of normal variability,
enabling broader and more reliable detection of structural abnormalities.

</details>


### [39] [GenTrack: A New Generation of Multi-Object Tracking](https://arxiv.org/abs/2510.24399)
*Toan Van Nguyen,Rasmus G. K. Christiansen,Dirk Kraft,Leon Bodenhagen*

Main category: cs.CV

TL;DR: 本文提出GenTrack，一种结合PSO与社会交互的混合多目标跟踪算法，实验证明其在复杂场景下性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多目标跟踪（MOT）方法在处理目标数量变化、遮挡以及检测噪声时容易出现身份（ID）切换和跟踪丢失，亟需一种更稳健的跟踪方案。

Method: 提出了一种名为GenTrack的混合跟踪方法，结合随机（PSO粒子群优化）与确定性策略，通过设计新的适应度函数引导粒子逼近目标分布模式，并整合目标间社会交互信息来增强状态更新和弱检测的利用。

Result: GenTrack在标准基准和真实场景中均优于当前先进跟踪器，显著降低了ID切换率和跟踪丢失率，并提供了公开源码三种可扩展版本（Basic、PSO、PSO-Social）。

Conclusion: 该研究验证了混合随机-确定性框架及社会交互融合机制能有效提升多目标跟踪的稳健性和精度，为后续MOT研究提供了新方向。

Abstract: This paper introduces a novel multi-object tracking (MOT) method, dubbed
GenTrack, whose main contributions include: a hybrid tracking approach
employing both stochastic and deterministic manners to robustly handle unknown
and time-varying numbers of targets, particularly in maintaining target
identity (ID) consistency and managing nonlinear dynamics, leveraging particle
swarm optimization (PSO) with some proposed fitness measures to guide
stochastic particles toward their target distribution modes, enabling effective
tracking even with weak and noisy object detectors, integration of social
interactions among targets to enhance PSO-guided particles as well as improve
continuous updates of both strong (matched) and weak (unmatched) tracks,
thereby reducing ID switches and track loss, especially during occlusions, a
GenTrack-based redefined visual MOT baseline incorporating a comprehensive
state and observation model based on space consistency, appearance, detection
confidence, track penalties, and social scores for systematic and efficient
target updates, and the first-ever publicly available source-code reference
implementation with minimal dependencies, featuring three variants, including
GenTrack Basic, PSO, and PSO-Social, facilitating flexible reimplementation.
Experimental results have shown that GenTrack provides superior performance on
standard benchmarks and real-world scenarios compared to state-of-the-art
trackers, with integrated implementations of baselines for fair comparison.
Potential directions for future work are also discussed. The source-code
reference implementations of both the proposed method and compared-trackers are
provided on GitHub: https://github.com/SDU-VelKoTek/GenTrack

</details>


### [40] [A Hybrid Approach for Visual Multi-Object Tracking](https://arxiv.org/abs/2510.24410)
*Toan Van Nguyen,Rasmus G. K. Christiansen,Dirk Kraft,Leon Bodenhagen*

Main category: cs.CV

TL;DR: 本文提出結合粒子濾波與確定性關聯的多目標追蹤方法，透過PSO與平滑更新機制提升身份一致性與準確率，實驗顯示性能超越現有方法。


<details>
  <summary>Details</summary>
Motivation: 針對多目標追蹤中因目標數未知、非線性運動及遮擋導致的識別錯誤與追蹤漂移問題，作者希望提升識別一致性與追蹤穩定性。

Method: 結合隨機與確定性機制：利用粒子濾波處理非線性與非高斯噪聲，並以粒子群優化(PSO)引導粒子分佈，同時計算運動一致性、外觀相似度及社交互動特徵；再以確定性關聯方法基於代價矩陣保持身份一致，並提出平滑更新與速度回歸策略用於遮擋及弱追蹤情形。

Result: 在多個數據集與實時視頻上表現優於現有先進方法，顯示模型在追蹤準確率與身份保持方面具有顯著提升。

Conclusion: 所提方法能有效應對非線性、多目標、動態變化場景下的追蹤問題，實現穩定、準確且實用的多目標追蹤。

Abstract: This paper proposes a visual multi-object tracking method that jointly
employs stochastic and deterministic mechanisms to ensure identifier
consistency for unknown and time-varying target numbers under nonlinear
dynamics. A stochastic particle filter addresses nonlinear dynamics and
non-Gaussian noise, with support from particle swarm optimization (PSO) to
guide particles toward state distribution modes and mitigate divergence through
proposed fitness measures incorporating motion consistency, appearance
similarity, and social-interaction cues with neighboring targets. Deterministic
association further enforces identifier consistency via a proposed cost matrix
incorporating spatial consistency between particles and current detections,
detection confidences, and track penalties. Subsequently, a novel scheme is
proposed for the smooth updating of target states while preserving their
identities, particularly for weak tracks during interactions with other targets
and prolonged occlusions. Moreover, velocity regression over past states
provides trend-seed velocities, enhancing particle sampling and state updates.
The proposed tracker is designed to operate flexibly for both pre-recorded
videos and camera live streams, where future frames are unavailable.
Experimental results confirm superior performance compared to state-of-the-art
trackers. The source-code reference implementations of both the proposed method
and compared-trackers are provided on GitHub:
https://github.com/SDU-VelKoTek/GenTrack2

</details>


### [41] [50 Years of Water Body Monitoring: The Case of Qaraaoun Reservoir, Lebanon](https://arxiv.org/abs/2510.24413)
*Ali Ahmad Faour,Nabil Amacha,Ali J. Ghandour*

Main category: cs.CV

TL;DR: 通过卫星影像和SVR模型实现卡拉昂水库的无传感器库容实时估算，精度高、成本低，可推广至其他水体监测。


<details>
  <summary>Details</summary>
Motivation: 卡拉昂水库是黎巴嫩最大的地表水体，但监测传感器经常故障且维护能力有限，因此需要一种无需依赖地面传感器的储水量监测方法。

Method: 研究利用开源卫星影像（Sentinel-2和Landsat），结合新提出的水体分割指数以及支持向量回归（SVR）机器学习模型，通过水面面积推算库容。采用GridSearchCV进行超参数调优以优化模型性能。

Result: 新水体分割指数的岸线识别精度超过95%；优化后的SVR模型估算误差低于总库容的1.5%，决定系数超过0.98。方法能够仅依靠卫星数据准确估算库容。

Conclusion: 该研究提出了一种稳健、低成本、无需传感器的水库储水量监测方案，可持续应用于卡拉昂水库及其他水体，为气候变化和环境研究提供长期数据支持。

Abstract: The sustainable management of the Qaraaoun Reservoir, the largest surface
water body in Lebanon located in the Bekaa Plain, depends on reliable
monitoring of its storage volume despite frequent sensor malfunctions and
limited maintenance capacity. This study introduces a sensor-free approach that
integrates open-source satellite imagery, advanced water-extent segmentation,
and machine learning to estimate the reservoir surface area and volume in near
real time. Sentinel-2 and Landsat images are processed, where surface water is
delineated using a newly proposed water segmentation index. A machine learning
model based on Support Vector Regression (SVR) is trained on a curated dataset
that includes water surface area, water level, and water volume calculations
using a reservoir bathymetry survey. The model is then able to estimate
reservoir volume relying solely on surface area extracted from satellite
imagery, without the need for ground measurements. Water segmentation using the
proposed index aligns with ground truth for more than 95 percent of the
shoreline. Hyperparameter tuning with GridSearchCV yields an optimized SVR
performance with error under 1.5 percent of full reservoir capacity and
coefficients of determination exceeding 0.98. These results demonstrate the
robustness and cost-effectiveness of the method, offering a practical solution
for continuous, sensor-independent monitoring of reservoir storage. The
proposed methodology can be replicated for other water bodies, and the
resulting 50 years of time-series data is valuable for research on climate
change and environmental patterns.

</details>


### [42] [XAI Evaluation Framework for Semantic Segmentation](https://arxiv.org/abs/2510.24414)
*Reem Hammoud,Abdul karim Gizzini,Ali J. Ghandour*

Main category: cs.CV

TL;DR: 本文建立了一个专为语义分割设计的XAI评估框架，通过像素级指标验证了其在解释性与可靠性上的显著优势。


<details>
  <summary>Details</summary>
Motivation: 现有XAI评估方法多集中于分类任务，缺乏针对语义分割的评价体系，因此亟需开发一个能够同时考虑空间与上下文复杂度的系统评估方法。

Method: 研究设计了一个综合系统的评估框架，结合像素级评估策略与专门的度量指标，对语义分割模型的可解释性进行细粒度分析。

Result: 实验中采用基于类激活映射（CAM）的XAI方法进行仿真，结果显示该框架在可解释性评估上表现出优良的性能与稳定性。

Conclusion: 本文提出了一种针对语义分割任务的可解释人工智能（XAI）评估框架，并通过实验验证了其高效性、健壮性与可靠性。

Abstract: Ensuring transparency and trust in artificial intelligence (AI) models is
essential, particularly as they are increasingly applied in safety-critical and
high-stakes domains. Explainable AI (XAI) has emerged as a promising approach
to address this challenge, yet the rigorous evaluation of XAI methods remains
crucial for optimizing the trade-offs between model complexity, predictive
performance, and interpretability. While extensive progress has been achieved
in evaluating XAI techniques for classification tasks, evaluation strategies
tailored to semantic segmentation remain relatively underexplored. This work
introduces a comprehensive and systematic evaluation framework specifically
designed for assessing XAI in semantic segmentation, explicitly accounting for
both spatial and contextual task complexities. The framework employs
pixel-level evaluation strategies and carefully designed metrics to provide
fine-grained interpretability insights. Simulation results using recently
adapted class activation mapping (CAM)-based XAI schemes demonstrate the
efficiency, robustness, and reliability of the proposed methodology. These
findings contribute to advancing transparent, trustworthy, and accountable
semantic segmentation models.

</details>


### [43] [Deeply-Conditioned Image Compression via Self-Generated Priors](https://arxiv.org/abs/2510.24437)
*Zhineng Zhao,Zhihai He,Zikun Zhou,Siwei Ma,Yaowei Wang*

Main category: cs.CV

TL;DR: 本文提出DCIC-sgp框架，通过自生成结构先验深度调制压缩过程，有效减少低码率几何畸变并提升压缩性能。


<details>
  <summary>Details</summary>
Motivation: 现有的学习式图像压缩方法难以有效建模自然图像中的复杂相关结构，尤其是在单一表示下同时处理全局结构与局部纹理时会出现几何变形问题。

Method: 提出一种基于功能分解的深度条件图像压缩框架DCIC-sgp，首先生成自适应的结构先验表示图像骨架，然后以该先验作为整体调制信号深度嵌入压缩流程中，使分析变换专注于高熵残差信息，从而实现信息流的层次化解耦。

Result: 该方法显著减少低码率下的几何畸变，并在Kodak、CLIC和Tecnick数据集上相较于VVC测试模型VTM-12.1分别取得14.4%、15.7%、15.1%的BD-rate下降。

Conclusion: DCIC-sgp通过自生成先验实现信息分层与结构-纹理解耦，在保持高压缩性能的同时改善了低码率视觉质量。

Abstract: Learned image compression (LIC) has shown great promise for achieving high
rate-distortion performance. However, current LIC methods are often limited in
their capability to model the complex correlation structures inherent in
natural images, particularly the entanglement of invariant global structures
with transient local textures within a single monolithic representation. This
limitation precipitates severe geometric deformation at low bitrates. To
address this, we introduce a framework predicated on functional decomposition,
which we term Deeply-Conditioned Image Compression via self-generated priors
(DCIC-sgp). Our central idea is to first encode a potent, self-generated prior
to encapsulate the image's structural backbone. This prior is subsequently
utilized not as mere side-information, but to holistically modulate the entire
compression pipeline. This deep conditioning, most critically of the analysis
transform, liberates it to dedicate its representational capacity to the
residual, high-entropy details. This hierarchical, dependency-driven approach
achieves an effective disentanglement of information streams. Our extensive
experiments validate this assertion; visual analysis demonstrates that our
method substantially mitigates the geometric deformation artifacts that plague
conventional codecs at low bitrates. Quantitatively, our framework establishes
highly competitive performance, achieving significant BD-rate reductions of
14.4%, 15.7%, and 15.1% against the VVC test model VTM-12.1 on the Kodak, CLIC,
and Tecnick datasets.

</details>


### [44] [Rethinking Visual Intelligence: Insights from Video Pretraining](https://arxiv.org/abs/2510.24448)
*Pablo Acuaviva,Aram Davtyan,Mariam Hassan,Sebastian Stapf,Ahmad Rahimi,Alexandre Alahi,Paolo Favaro*

Main category: cs.CV

TL;DR: 视频扩散模型在视觉任务中优于语言模型，视频预训练可作为构建视觉基础模型的有效方向。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型在语言领域表现出快速适应新任务的能力，但在视觉领域效果有限，特别是在组合理解、样本效率和通用问题求解方面。研究者希望寻找一种方法来弥合这一差距。

Method: 本文探索了视频扩散模型（VDM）的潜力，通过在时空数据上的预训练，使模型具备强结构和动态的归纳偏置。研究设计了一个受控实验，将预训练的LLM和VDM分别添加轻量适配器，并在各自的自然模态任务中进行对比评估。

Result: 在多个基准测试上（包括ARC-AGI、ConceptARC、视觉游戏、路径规划和元胞自动机），VDM显示出比LLM更高的数据效率。

Conclusion: 视频预训练能够提供有助于视觉基础模型发展的归纳偏置，VDM在视觉任务中比语言模型具有更强的适应性和样本利用能力。

Abstract: Large language models (LLMs) have demonstrated that large-scale pretraining
enables systems to adapt rapidly to new problems with little supervision in the
language domain. This success, however, has not translated as effectively to
the visual domain, where models, including LLMs, continue to struggle with
compositional understanding, sample efficiency, and general-purpose
problem-solving. We investigate Video Diffusion Models (VDMs) as a promising
direction for bridging this gap. Pretraining on spatiotemporal data endows
these models with strong inductive biases for structure and dynamics, which we
hypothesize can support broad task adaptability. To test this, we design a
controlled evaluation in which both a pretrained LLM and a pretrained VDM are
equipped with lightweight adapters and presented with tasks in their natural
modalities. Across benchmarks including ARC-AGI, ConceptARC, visual games,
route planning, and cellular automata, VDMs demonstrate higher data efficiency
than their language counterparts. Taken together, our results indicate that
video pretraining offers inductive biases that support progress toward visual
foundation models.

</details>


### [45] [A Critical Study towards the Detection of Parkinsons Disease using ML Technologies](https://arxiv.org/abs/2510.24456)
*Vivek Chetia,Abdul Taher Khan,Rahish Gogoi,David Kapsian Khual,Purnendu Bikash,Sajal Saha*

Main category: cs.CV

TL;DR: 论文利用SSD、Faster R-CNN和Mask R-CNN等深度学习模型检测三种茶叶病害，Faster R-CNN表现最佳。


<details>
  <summary>Details</summary>
Motivation: 茶叶种植中常见病害影响产量与品质，需要使用自动化方法进行早期检测与分类，以减少人工误差和劳动力成本。

Method: 采用深度学习的目标检测与实例分割技术，对茶叶病害进行识别与受损区域分割。比较了SSD MobileNet V2和Faster R-CNN ResNet50 V1两种模型的检测性能，并使用Mask R-CNN进行病斑区域面积计算。

Result: Faster R-CNN ResNet50 V1模型在mAP、精度和召回率上均优于SSD MobileNet V2，其中mAP达到25%。实现了病叶区域的自动检测与损伤面积估算。

Conclusion: 深度学习方法可有效识别和分割茶叶病害，并能辅助评估受损程度，有助于实现智能化茶叶病害监测。

Abstract: The proposed solution is Deep Learning Technique that will be able classify
three types of tea leaves diseases from which two diseases are caused by the
pests and one due to pathogens (infectious organisms) and environmental
conditions and also show the area damaged by a disease in leaves. Namely Red
Rust, Helopeltis and Red spider mite respectively. In this paper we have
evaluated two models namely SSD MobileNet V2 and Faster R-CNN ResNet50 V1 for
the object detection. The SSD MobileNet V2 gave precision of 0.209 for IOU
range of 0.50:0.95 with recall of 0.02 on IOU 0.50:0.95 and final mAP of 20.9%.
While Faster R-CNN ResNet50 V1 has precision of 0.252 on IOU range of 0.50:0.95
and recall of 0.044 on IOU of 0.50:0.95 with a mAP of 25%, which is better than
SSD. Also used Mask R-CNN for Object Instance Segmentation where we have
implemented our custom method to calculate the damaged diseased portion of
leaves. Keywords: Tea Leaf Disease, Deep Learning, Red Rust, Helopeltis and Red
Spider Mite, SSD MobileNet V2, Faster R-CNN ResNet50 V1 and Mask RCNN.

</details>


### [46] [Kineo: Calibration-Free Metric Motion Capture From Sparse RGB Cameras](https://arxiv.org/abs/2510.24464)
*Charles Javerliat,Pierre Raimbaud,Guillaume Lavoué*

Main category: cs.CV

TL;DR: 本文提出Kineo，一个无需校准、可自动从非同步消费级摄像机视频中进行高精度动作捕捉的系统，精度与效率均显著领先现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有非标记多视角动作捕捉通常需精确校准，相机同步困难，且缺乏非专家易用性。作者希望突破这一限制，构建完全自动、无校准的捕捉系统。

Method: 采用基于现成2D关键点的自动相机校准与3D关键点、稠密场景点重建流程，通过置信度驱动的时空关键点采样以及基于图的全局优化，实现稳定的校准与重建；并提出成对重投影一致性得分评估三维重建可靠性。

Result: 在EgoHumans与Human3.6M数据集上，相机平移误差降低约83–85%，角度误差降低86–92%，W-MPJPE降低83–91%；处理速度可快于拍摄时长，实现高效实用的性能。

Conclusion: 本文提出的Kineo系统能够在无需相机校准的情况下高效、准确地进行多视角、非标记人体动作捕捉，显著提升了重建精度并降低计算成本。

Abstract: Markerless multiview motion capture is often constrained by the need for
precise camera calibration, limiting accessibility for non-experts and
in-the-wild captures. Existing calibration-free approaches mitigate this
requirement but suffer from high computational cost and reduced reconstruction
accuracy.
  We present Kineo, a fully automatic, calibration-free pipeline for markerless
motion capture from videos captured by unsynchronized, uncalibrated,
consumer-grade RGB cameras. Kineo leverages 2D keypoints from off-the-shelf
detectors to simultaneously calibrate cameras, including Brown-Conrady
distortion coefficients, and reconstruct 3D keypoints and dense scene point
maps at metric scale. A confidence-driven spatio-temporal keypoint sampling
strategy, combined with graph-based global optimization, ensures robust
calibration at a fixed computational cost independent of sequence length. We
further introduce a pairwise reprojection consensus score to quantify 3D
reconstruction reliability for downstream tasks.
  Evaluations on EgoHumans and Human3.6M demonstrate substantial improvements
over prior calibration-free methods. Compared to previous state-of-the-art
approaches, Kineo reduces camera translation error by approximately 83-85%,
camera angular error by 86-92%, and world mean-per-joint error (W-MPJPE) by
83-91%.
  Kineo is also efficient in real-world scenarios, processing multi-view
sequences faster than their duration in specific configuration (e.g., 36min to
process 1h20min of footage). The full pipeline and evaluation code are openly
released to promote reproducibility and practical adoption at
https://liris-xr.github.io/kineo/.

</details>


### [47] [Decoupled MeanFlow: Turning Flow Models into Flow Maps for Accelerated Sampling](https://arxiv.org/abs/2510.24474)
*Kyungmin Lee,Sihyun Yu,Jinwoo Shin*

Main category: cs.CV

TL;DR: 提出Decoupled MeanFlow方法，用最少1至4步生成高质量图像，无需调整架构，推理速度比传统流模型快百倍。


<details>
  <summary>Details</summary>
Motivation: 扩散与流模型在高质量图像生成上表现出色，但由于离散化误差，推理需多步去噪，导致采样速度慢。现有的流映射(flow map)方法可减少误差加快生成，但通常要求架构改动，不兼容已有预训练模型。

Method: 提出Decoupled MeanFlow，一种无需架构修改即可将预训练流模型转化为flow map模型的解码策略。该方法通过在扩散Transformer的最后层引入对下一时间步的条件，并结合改进的训练技巧，实现高效少步生成。

Result: 在ImageNet 256x256与512x512上，该方法实现1步FID分别为2.16和2.12，显著优于现有方法；4步时FID为1.51和1.68，几乎与完整流模型匹敌，同时推理速度提升100倍以上。

Conclusion: Decoupled MeanFlow能在保持高生成质量的同时大幅减少采样步数，并最大化利用预训练流模型，是一种兼顾速度与性能的高效生成策略。

Abstract: Denoising generative models, such as diffusion and flow-based models, produce
high-quality samples but require many denoising steps due to discretization
error. Flow maps, which estimate the average velocity between timesteps,
mitigate this error and enable faster sampling. However, their training
typically demands architectural changes that limit compatibility with
pretrained flow models. We introduce Decoupled MeanFlow, a simple decoding
strategy that converts flow models into flow map models without architectural
modifications. Our method conditions the final blocks of diffusion transformers
on the subsequent timestep, allowing pretrained flow models to be directly
repurposed as flow maps. Combined with enhanced training techniques, this
design enables high-quality generation in as few as 1 to 4 steps. Notably, we
find that training flow models and subsequently converting them is more
efficient and effective than training flow maps from scratch. On ImageNet
256x256 and 512x512, our models attain 1-step FID of 2.16 and 2.12,
respectively, surpassing prior art by a large margin. Furthermore, we achieve
FID of 1.51 and 1.68 when increasing the steps to 4, which nearly matches the
performance of flow models while delivering over 100x faster inference.

</details>


### [48] [Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs](https://arxiv.org/abs/2510.24514)
*Huanyu Zhang,Wenshan Wu,Chengzu Li,Ning Shang,Yan Xia,Yangyu Huang,Yifan Zhang,Li Dong,Zhang Zhang,Liang Wang,Tieniu Tan,Furu Wei*

Main category: cs.CV

TL;DR: 作者提出Latent Sketchpad框架，为MLLM加入视觉“草图板”，让模型在推理过程中生成视觉潜变量，用草图辅助视觉思考，在复杂视觉推理任务上取得更佳表现。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型主要擅长视觉理解，但缺乏视觉规划与想象能力；受到人类利用草图进行思维的启发，作者希望赋予模型类似的“视觉思考”能力。

Method: 提出Latent Sketchpad框架，通过在模型的自回归推理过程中直接整合视觉生成模块，使文本推理与视觉潜变量的生成交替进行；框架包含Context-Aware Vision Head用于生成视觉潜变量，以及预训练的Sketch Decoder将其转化为可解释的草图。

Result: 在MazePlanning数据集上的实验显示，Latent Sketchpad在多种前沿MLLM上均能达到或超过原模型的推理表现；同时保持良好泛化性与可解释性。

Conclusion: Latent Sketchpad显著提升了多模态大语言模型在需要视觉规划和想象的复杂任务中的推理与表现能力，并可广泛迁移到不同前沿MLLM架构。

Abstract: While Multimodal Large Language Models (MLLMs) excel at visual understanding,
they often struggle in complex scenarios that require visual planning and
imagination. Inspired by how humans use sketching as a form of visual thinking
to develop and communicate ideas, we introduce Latent Sketchpad, a framework
that equips MLLMs with an internal visual scratchpad. The internal visual
representations of MLLMs have traditionally been confined to perceptual
understanding. We repurpose them to support generative visual thought without
compromising reasoning ability. Building on frontier MLLMs, our approach
integrates visual generation directly into their native autoregressive
reasoning process. It allows the model to interleave textual reasoning with the
generation of visual latents. These latents guide the internal thought process
and can be translated into sketch images for interpretability. To realize this,
we introduce two components: a Context-Aware Vision Head autoregressively
produces visual representations, and a pretrained Sketch Decoder renders these
into human-interpretable images. We evaluate the framework on our new dataset
MazePlanning. Experiments across various MLLMs show that Latent Sketchpad
delivers comparable or even superior reasoning performance to their backbone.
It further generalizes across distinct frontier MLLMs, including Gemma3 and
Qwen2.5-VL. By extending model's textual reasoning to visual thinking, our
framework opens new opportunities for richer human-computer interaction and
broader applications. More details and resources are available on our project
page: https://latent-sketchpad.github.io/.

</details>


### [49] [OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents](https://arxiv.org/abs/2510.24563)
*Hongrui Jia,Jitong Liao,Xi Zhang,Haiyang Xu,Tianbao Xie,Chaoya Jiang,Ming Yan,Si Liu,Wei Ye,Fei Huang*

Main category: cs.CV

TL;DR: 该论文提出OSWorld-MCP基准，公平评估多模态智能体的工具调用与GUI操作能力，实验结果显示工具集成显著提高任务成功率，但调用率仍偏低，具备较强研究与改进价值。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要集中在GUI交互，而忽视了模型工具调用能力，使得带有工具集成的智能体评估存在公平性问题。作者希望建立一个全面而公平的基准来准确衡量智能体在复杂计算机使用场景中的真实能力。

Method: 作者设计了一个自动化代码生成管道，结合人工验证过程，生成并筛选了158个高质量工具（涵盖7类常见应用），并构建了OSWorld-MCP评测环境，对多模态智能体进行了系统性能测试。

Result: 在OSWorld-MCP上的实验显示，集成MCP工具后模型任务成功率显著提升（例如OpenAI o3从8.3%增至20.4%，Claude 4 Sonnet从40.1%增至43.3%），但工具调用率仅36.3%，显示挑战性与改进潜力并存。

Conclusion: OSWorld-MCP提供了一个综合且公平的基准，用于评估多模态智能体在真实环境下的工具调用、GUI操作与决策能力。实验结果表明，集成MCP工具能明显提升任务成功率，但当前模型的工具调用率仍较低，显示出改进空间。

Abstract: With advances in decision-making and reasoning capabilities, multimodal
agents show strong potential in computer application scenarios. Past
evaluations have mainly assessed GUI interaction skills, while tool invocation
abilities, such as those enabled by the Model Context Protocol (MCP), have been
largely overlooked. Comparing agents with integrated tool invocation to those
evaluated only on GUI interaction is inherently unfair. We present OSWorld-MCP,
the first comprehensive and fair benchmark for assessing computer-use agents'
tool invocation, GUI operation, and decision-making abilities in a real-world
environment. We design a novel automated code-generation pipeline to create
tools and combine them with a curated selection from existing tools. Rigorous
manual validation yields 158 high-quality tools (covering 7 common
applications), each verified for correct functionality, practical
applicability, and versatility. Extensive evaluations of state-of-the-art
multimodal agents on OSWorld-MCP show that MCP tools generally improve task
success rates (e.g., from 8.3% to 20.4% for OpenAI o3 at 15 steps, from 40.1%
to 43.3% for Claude 4 Sonnet at 50 steps), underscoring the importance of
assessing tool invocation capabilities. However, even the strongest models have
relatively low tool invocation rates, Only 36.3%, indicating room for
improvement and highlighting the benchmark's challenge. By explicitly measuring
MCP tool usage skills, OSWorld-MCP deepens understanding of multimodal agents
and sets a new standard for evaluating performance in complex, tool-assisted
environments. Our code, environment, and data are publicly available at
https://osworld-mcp.github.io.

</details>


### [50] [Physics-Inspired Gaussian Kolmogorov-Arnold Networks for X-ray Scatter Correction in Cone-Beam CT](https://arxiv.org/abs/2510.24579)
*Xu Jiang,Huiying Pan,Ligen Shi,Jianing Sun,Wenfeng Xu,Xing Zhao*

Main category: cs.CV

TL;DR: 本文提出利用物理先验结合KAN的CBCT散射校正模型,通过高斯RBF嵌入实现高维散射特征学习,在实验中较现有方法显著提高图像质量。


<details>
  <summary>Details</summary>
Motivation: 针对CBCT在数据采集过程中易受到散射影响,导致CT值偏差和组织对比度降低、诊断准确性下降的问题,亟需一种有效的散射校正方法。

Method: 方法基于物理先验知识,利用高斯径向基函数(Gaussian RBF)建模点散射函数,并将其嵌入Kolmogorov-Arnold Networks (KAN)层中,通过高维非线性映射实现散射特征的学习与校正。

Result: 通过合成数据和真实扫描实验验证,该模型能显著减少散射伪影,提升图像清晰度和对比度,定量性能超越现有校正算法。

Conclusion: 本文提出的基于深度学习的散射伪影校正方法能够有效改善CBCT重建图像质量,在定量指标上优于现有方法。

Abstract: Cone-beam CT (CBCT) employs a flat-panel detector to achieve
three-dimensional imaging with high spatial resolution. However, CBCT is
susceptible to scatter during data acquisition, which introduces CT value bias
and reduced tissue contrast in the reconstructed images, ultimately degrading
diagnostic accuracy. To address this issue, we propose a deep learning-based
scatter artifact correction method inspired by physical prior knowledge.
Leveraging the fact that the observed point scatter probability density
distribution exhibits rotational symmetry in the projection domain. The method
uses Gaussian Radial Basis Functions (RBF) to model the point scatter function
and embeds it into the Kolmogorov-Arnold Networks (KAN) layer, which provides
efficient nonlinear mapping capabilities for learning high-dimensional scatter
features. By incorporating the physical characteristics of the scattered photon
distribution together with the complex function mapping capacity of KAN, the
model improves its ability to accurately represent scatter. The effectiveness
of the method is validated through both synthetic and real-scan experiments.
Experimental results show that the model can effectively correct the scatter
artifacts in the reconstructed images and is superior to the current methods in
terms of quantitative metrics.

</details>


### [51] [Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology](https://arxiv.org/abs/2510.24653)
*Veronica Thai,Rui Li,Meng Ling,Shuning Jiang,Jeremy Wolfe,Raghu Machiraju,Yan Hu,Zaibo Li,Anil Parwani,Jian Chen*

Main category: cs.CV

TL;DR: 论文构建并公开了PathoGaze1.0病理诊断行为数据集，通过眼动与交互等多维记录揭示医生查看WSI的行为特征，为改进诊断与AI训练提供基础。


<details>
  <summary>Details</summary>
Motivation: 为了解释病理诊断中的错误与不一致性，填补行为数据的研究空白，并辅助改进医生和AI的诊断支持。

Method: 作者通过眼动追踪、鼠标交互记录、视口导航及决策过程监测，在名为PTAH的应用场景测试系统中采集行为数据。

Result: 共收集397张WSI的18.69小时行为数据，包括17万多个凝视点、26万余次扫视及近190万个鼠标事件，构成了高生态有效性的数据集并公开发布。

Conclusion: 论文推出了PathoGaze1.0，这是一个包含病理诊断全过程中视觉搜索与决策行为数据的综合性数据集，可用于研究诊断错误机制并提升病理学家与AI系统的训练效果。

Abstract: Interpretation of giga-pixel whole-slide images (WSIs) is an important but
difficult task for pathologists. Their diagnostic accuracy is estimated to
average around 70%. Adding a second pathologist does not substantially improve
decision consistency. The field lacks adequate behavioral data to explain
diagnostic errors and inconsistencies. To fill in this gap, we present
PathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual
search and decision-making processes of the full diagnostic workflow during
cancer diagnosis. The dataset comprises 18.69 hours of eye-tracking, mouse
interaction, stimulus tracking, viewport navigation, and diagnostic decision
data (EMSVD) collected from 19 pathologists interpreting 397 WSIs. The data
collection process emphasizes ecological validity through an
application-grounded testbed, called PTAH. In total, we recorded 171,909
fixations, 263,320 saccades, and 1,867,362 mouse interaction events. In
addition, such data could also be used to improve the training of both
pathologists and AI systems that might support human experts. All experiments
were preregistered at https://osf.io/hj9a7, and the complete dataset along with
analysis code is available at https://go.osu.edu/pathogaze.

</details>


### [52] [Group Relative Attention Guidance for Image Editing](https://arxiv.org/abs/2510.24657)
*Xuanpu Zhang,Xuesong Niu,Ruidong Chen,Dan Song,Jianhao Zeng,Penghui Du,Haoxiang Cao,Kai Wu,An-an Liu*

Main category: cs.CV

TL;DR: 提出GRAG方法，通过重新加权注意力delta，实现DiT图像编辑的无调参精确强度控制，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的DiT图像编辑方法缺乏对编辑程度的有效控制，无法满足对结果定制化的需求。

Method: 研究了DiT模型中的MM-Attention机制，发现Query与Key共享层相关偏置向量。基于此，利用偏置和token差值，重新加权不同token的delta值，从而控制模型对输入图像和编辑指令的关注比例。

Result: 实验显示GRAG可用极少的代码集成到现有图像编辑框架中，显著提升编辑质量，并较Classifier-Free Guidance实现更平滑且精确的控制。

Conclusion: 本文提出了一种名为Group Relative Attention Guidance (GRAG) 的方法，可在Diffusion-in-Transformer (DiT) 模型中实现连续且精细的图像编辑强度控制。

Abstract: Recently, image editing based on Diffusion-in-Transformer models has
undergone rapid development. However, existing editing methods often lack
effective control over the degree of editing, limiting their ability to achieve
more customized results. To address this limitation, we investigate the
MM-Attention mechanism within the DiT model and observe that the Query and Key
tokens share a bias vector that is only layer-dependent. We interpret this bias
as representing the model's inherent editing behavior, while the delta between
each token and its corresponding bias encodes the content-specific editing
signals. Based on this insight, we propose Group Relative Attention Guidance, a
simple yet effective method that reweights the delta values of different tokens
to modulate the focus of the model on the input image relative to the editing
instruction, enabling continuous and fine-grained control over editing
intensity without any tuning. Extensive experiments conducted on existing image
editing frameworks demonstrate that GRAG can be integrated with as few as four
lines of code, consistently enhancing editing quality. Moreover, compared to
the commonly used Classifier-Free Guidance, GRAG achieves smoother and more
precise control over the degree of editing. Our code will be released at
https://github.com/little-misfit/GRAG-Image-Editing.

</details>


### [53] [SAGE: Structure-Aware Generative Video Transitions between Diverse Clips](https://arxiv.org/abs/2510.24667)
*Mia Kan,Yilin Liu,Niloy Mitra*

Main category: cs.CV

TL;DR: 论文提出 SAGE，一个基于结构引导的生成式零样本视频过渡方法，在跨片段过渡中兼顾结构完整性与语义一致性，效果优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有的视频过渡方法（线性混合、交叉淡入淡出、变形、帧插值）在面对时序差距大或语义差异显著的片段时容易出现视觉不连贯或伪影，未能满足内容感知和结构保持的需求。

Method: 作者借鉴艺术创作流程中的对齐轮廓、插值显著特征等策略，提出了 SAGE（Structure-Aware Generative vidEo transitions）方法。该方法以线条图和运动流作为结构引导，结合生成式合成，实现无需微调的零样本视频过渡生成。

Result: 实验表明，SAGE 在定量指标和用户研究中均优于现有的经典和生成式方法（FILM, TVG, DiffMorpher, VACE, GI），能生成结构与语义一致的平滑过渡。

Conclusion: SAGE 提供了一种结构感知的生成式视频过渡新范式，能够在语义差异较大的片段间生成连贯自然的过渡效果，显著提升视频编辑的自动化与视觉质量。

Abstract: Video transitions aim to synthesize intermediate frames between two clips,
but naive approaches such as linear blending introduce artifacts that limit
professional use or break temporal coherence. Traditional techniques
(cross-fades, morphing, frame interpolation) and recent generative inbetweening
methods can produce high-quality plausible intermediates, but they struggle
with bridging diverse clips involving large temporal gaps or significant
semantic differences, leaving a gap for content-aware and visually coherent
transitions. We address this challenge by drawing on artistic workflows,
distilling strategies such as aligning silhouettes and interpolating salient
features to preserve structure and perceptual continuity. Building on this, we
propose SAGE (Structure-Aware Generative vidEo transitions) as a zeroshot
approach that combines structural guidance, provided via line maps and motion
flow, with generative synthesis, enabling smooth, semantically consistent
transitions without fine-tuning. Extensive experiments and comparison with
current alternatives, namely [FILM, TVG, DiffMorpher, VACE, GI], demonstrate
that SAGE outperforms both classical and generative baselines on quantitative
metrics and user studies for producing transitions between diverse clips. Code
to be released on acceptance.

</details>


### [54] [Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?](https://arxiv.org/abs/2510.24709)
*Yihao Li,Saeed Salehi,Lyle Ungar,Konrad P. Kording*

Main category: cs.CV

TL;DR: 自监督ViT中自然出现可解码的物体绑定能力，该能力有助于模型性能，并体现出注意力机制的符号化特征。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究ViT是否在无显式物体中心化注意机制的情况下，能自然实现人类认知中关键的“物体绑定”能力，从而理解Transformer模型中的符号化知识如何自发形成。

Method: 作者通过相似性探针（similarity probe）从ViT各层的patch嵌入中解码“是否为同一物体”（IsSameObject）属性，并进行准确率评估及消融实验，考察该信号的表现及对注意力和任务性能的影响。

Result: 相似性探针在ViT上解码同物体属性的准确率超过90%，且此能力在自监督模型中显著强于监督模型。IsSameObject信号存在于低维子空间并能引导注意力；移除该信号会降低下游任务性能。

Conclusion: 研究表明，视觉Transformer（ViT）在自监督训练（如DINO、MAE、CLIP）中会自然产生物体绑定能力，即能够识别“哪些图像块属于同一物体”，这一能力在ImageNet监督模型中较弱。该能力不是架构的偶然产物，而是由特定的预训练目标习得所得。

Abstract: Object binding, the brain's ability to bind the many features that
collectively represent an object into a coherent whole, is central to human
cognition. It groups low-level perceptual features into high-level object
representations, stores those objects efficiently and compositionally in
memory, and supports human reasoning about individual object instances. While
prior work often imposes object-centric attention (e.g., Slot Attention)
explicitly to probe these benefits, it remains unclear whether this ability
naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they
could: recognizing which patches belong to the same object should be useful for
downstream prediction and thus guide attention. Motivated by the quadratic
nature of self-attention, we hypothesize that ViTs represent whether two
patches belong to the same object, a property we term IsSameObject. We decode
IsSameObject from patch embeddings across ViT layers using a similarity probe,
which reaches over 90% accuracy. Crucially, this object-binding capability
emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker
in ImageNet-supervised models, suggesting that binding is not a trivial
architectural artifact, but an ability acquired through specific pretraining
objectives. We further discover that IsSameObject is encoded in a
low-dimensional subspace on top of object features, and that this signal
actively guides attention. Ablating IsSameObject from model activations
degrades downstream performance and works against the learning objective,
implying that emergent object binding naturally serves the pretraining
objective. Our findings challenge the view that ViTs lack object binding and
highlight how symbolic knowledge of "which parts belong together" emerges
naturally in a connectionist system.

</details>


### [55] [MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection](https://arxiv.org/abs/2510.24688)
*Yun Zhang,Zhaoliang Zheng,Johnson Liu,Zhiyu Huang,Zewei Zhou,Zonglin Meng,Tianhui Cai,Jiaqi Ma*

Main category: cs.CV

TL;DR: 本文提出Transformer架构的MIC-BEV框架与合成数据集M2I，在多摄像头基础设施场景下实现鲁棒的三维目标检测，性能领先且适用于现实部署。


<details>
  <summary>Details</summary>
Motivation: 现有的基于摄像头的检测模型在多视角基础设施环境中表现不佳，面临摄像头配置差异、视觉退化和复杂道路布局等挑战。

Method: 提出基于Transformer的鸟瞰图（BEV）感知框架MIC-BEV，用于基础设施中的多摄像头三维目标检测；并设计图增强融合模块，实现多视图特征与BEV空间的结合。另构建合成数据集M2I，用于训练和评估。

Result: MIC-BEV在合成数据集M2I和真实数据集RoScenes上均达到最新性能，并在恶劣天气和传感器退化情况下保持较强鲁棒性。

Conclusion: MIC-BEV为基础设施感知提供了高鲁棒性和高性能的解决方案，具备实际部署潜力。

Abstract: Infrastructure-based perception plays a crucial role in intelligent
transportation systems, offering global situational awareness and enabling
cooperative autonomy. However, existing camera-based detection models often
underperform in such scenarios due to challenges such as multi-view
infrastructure setup, diverse camera configurations, degraded visual inputs,
and various road layouts. We introduce MIC-BEV, a Transformer-based
bird's-eye-view (BEV) perception framework for infrastructure-based
multi-camera 3D object detection. MIC-BEV flexibly supports a variable number
of cameras with heterogeneous intrinsic and extrinsic parameters and
demonstrates strong robustness under sensor degradation. The proposed
graph-enhanced fusion module in MIC-BEV integrates multi-view image features
into the BEV space by exploiting geometric relationships between cameras and
BEV cells alongside latent visual cues. To support training and evaluation, we
introduce M2I, a synthetic dataset for infrastructure-based object detection,
featuring diverse camera configurations, road layouts, and environmental
conditions. Extensive experiments on both M2I and the real-world dataset
RoScenes demonstrate that MIC-BEV achieves state-of-the-art performance in 3D
object detection. It also remains robust under challenging conditions,
including extreme weather and sensor degradation. These results highlight the
potential of MIC-BEV for real-world deployment. The dataset and source code are
available at: https://github.com/HandsomeYun/MIC-BEV.

</details>


### [56] [Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance](https://arxiv.org/abs/2510.24711)
*Yujie Wei,Shiwei Zhang,Hangjie Yuan,Yujin Han,Zhekai Chen,Jiayu Wang,Difan Zou,Xihui Liu,Yingya Zhang,Yu Liu,Hongming Shan*

Main category: cs.CV

TL;DR: 本文提出ProMoE框架，通过两步路由与语义原型机制显著提升视觉扩散Transformer的MoE性能，在ImageNet上超越主流方法。


<details>
  <summary>Details</summary>
Motivation: 目前在大语言模型中Mixture-of-Experts（MoE）取得显著成功，但将其应用于图像扩散Transformer（DiT）时效果有限。作者认为这是由于语言与视觉token的本质差异造成的，视觉token存在空间冗余和功能异质性，阻碍了专家模型的有效分工。

Method: 提出ProMoE框架，设计了一个带有显式路由引导的两步路由器：首先通过条件路由将图像token划分为有条件和无条件集合；随后通过原型路由利用可学习原型进行语义驱动的专家分配。此外，引入基于路由对比损失的优化机制以增强专家间区分度与内部一致性。

Result: 在ImageNet基准上，ProMoE在Rectified Flow和DDPM两种训练目标下均优于现有最先进方法。

Conclusion: ProMoE通过显式语义指导的原型路由机制有效促进了视觉MoE的专家特化，大幅提升了扩散Transformer的性能。

Abstract: Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model
capacity while preserving computational efficiency. Despite its notable success
in large language models (LLMs), existing attempts to apply MoE to Diffusion
Transformers (DiTs) have yielded limited gains. We attribute this gap to
fundamental differences between language and visual tokens. Language tokens are
semantically dense with pronounced inter-token variation, while visual tokens
exhibit spatial redundancy and functional heterogeneity, hindering expert
specialization in vision MoE. To this end, we present ProMoE, an MoE framework
featuring a two-step router with explicit routing guidance that promotes expert
specialization. Specifically, this guidance encourages the router to partition
image tokens into conditional and unconditional sets via conditional routing
according to their functional roles, and refine the assignments of conditional
image tokens through prototypical routing with learnable prototypes based on
semantic content. Moreover, the similarity-based expert allocation in latent
space enabled by prototypical routing offers a natural mechanism for
incorporating explicit semantic guidance, and we validate that such guidance is
crucial for vision MoE. Building on this, we propose a routing contrastive loss
that explicitly enhances the prototypical routing process, promoting
intra-expert coherence and inter-expert diversity. Extensive experiments on
ImageNet benchmark demonstrate that ProMoE surpasses state-of-the-art methods
under both Rectified Flow and DDPM training objectives. Code and models will be
made publicly available.

</details>


### [57] [Uniform Discrete Diffusion with Metric Path for Video Generation](https://arxiv.org/abs/2510.24717)
*Haoge Deng,Ting Pan,Fan Zhang,Yang Liu,Zhuoyan Luo,Yufeng Cui,Wenxuan Wang,Chunhua Shen,Shiguang Shan,Zhaoxiang Zhang,Xinlong Wang*

Main category: cs.CV

TL;DR: URSA框架通过度量路径与时间步移设计改进离散视频生成，有效提升可扩展性和性能，达到了与主流连续扩散方法相媲美的效果。


<details>
  <summary>Details</summary>
Motivation: 现有离散视频生成方法因误差累积和长时上下文不一致性而落后于连续方法，因此需要一种可扩展且高效的离散生成框架来提高性能。

Method: 提出Uniform discRete diffuSion with metric pAth (URSA)框架，通过线性度量路径（Linearized Metric Path）与分辨率依赖时间步移机制（Resolution-dependent Timestep Shifting），实现高效的离散空间视频生成。

Result: URSA在视频与图像生成的多个挑战性基准上均优于现有离散方法，并达到与最先进连续扩散方法可比的水准，同时推理步骤更少。

Conclusion: URSA显著缩小了离散视频生成方法与连续扩散方法之间的性能差距，并在多个基准测试上取得了领先表现。

Abstract: Continuous-space video generation has advanced rapidly, while discrete
approaches lag behind due to error accumulation and long-context inconsistency.
In this work, we revisit discrete generative modeling and present Uniform
discRete diffuSion with metric pAth (URSA), a simple yet powerful framework
that bridges the gap with continuous approaches for the scalable video
generation. At its core, URSA formulates the video generation task as an
iterative global refinement of discrete spatiotemporal tokens. It integrates
two key designs: a Linearized Metric Path and a Resolution-dependent Timestep
Shifting mechanism. These designs enable URSA to scale efficiently to
high-resolution image synthesis and long-duration video generation, while
requiring significantly fewer inference steps. Additionally, we introduce an
asynchronous temporal fine-tuning strategy that unifies versatile tasks within
a single model, including interpolation and image-to-video generation.
Extensive experiments on challenging video and image generation benchmarks
demonstrate that URSA consistently outperforms existing discrete methods and
achieves performance comparable to state-of-the-art continuous diffusion
methods. Code and models are available at https://github.com/baaivision/URSA

</details>


### [58] [Generative View Stitching](https://arxiv.org/abs/2510.24718)
*Chonghyuk Song,Michal Stary,Boyuan Chen,George Kopanas,Vincent Sitzmann*

Main category: cs.CV

TL;DR: 本文提出GVS方法，用并行采样与双向引导实现稳定无碰撞的摄像机路径视频生成，提升了扩散模型在时序一致性上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归视频扩散模型在长时间生成上稳定并且与历史一致，但无法利用未来信息进行条件引导，这在预定义摄像机轨迹的视频生成中容易导致与场景碰撞和生成崩溃。

Method: 提出生成视图拼接（GVS）方法，通过并行采样整个视频序列，使生成场景与预定义摄像机轨迹的各部分一致。该方法扩展了用于机器人规划的扩散拼接采样算法，并引入了全向引导（Omni Guidance）技术，通过同时利用过去和未来的条件增强时间一致性，并实现闭环机制。

Result: GVS无需专门训练模型，兼容任何基于Diffusion Forcing框架训练的现成视频模型，成功实现了稳定的、无碰撞的、帧间一致且能闭环的摄像机引导视频生成。

Conclusion: GVS显著改进了摄像机引导视频生成的稳定性和一致性，为复杂轨迹（如“不可能的楼梯”）提供了无缝生成能力。

Abstract: Autoregressive video diffusion models are capable of long rollouts that are
stable and consistent with history, but they are unable to guide the current
generation with conditioning from the future. In camera-guided video generation
with a predefined camera trajectory, this limitation leads to collisions with
the generated scene, after which autoregression quickly collapses. To address
this, we propose Generative View Stitching (GVS), which samples the entire
sequence in parallel such that the generated scene is faithful to every part of
the predefined camera trajectory. Our main contribution is a sampling algorithm
that extends prior work on diffusion stitching for robot planning to video
generation. While such stitching methods usually require a specially trained
model, GVS is compatible with any off-the-shelf video model trained with
Diffusion Forcing, a prevalent sequence diffusion framework that we show
already provides the affordances necessary for stitching. We then introduce
Omni Guidance, a technique that enhances the temporal consistency in stitching
by conditioning on both the past and future, and that enables our proposed
loop-closing mechanism for delivering long-range coherence. Overall, GVS
achieves camera-guided video generation that is stable, collision-free,
frame-to-frame consistent, and closes loops for a variety of predefined camera
paths, including Oscar Reutersv\"ard's Impossible Staircase. Results are best
viewed as videos at https://andrewsonga.github.io/gvs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [59] [Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents](https://arxiv.org/abs/2510.23691)
*Zihao Wang,Xujing Li,Yining Ye,Junjie Fang,Haoming Wang,Longxiang Liu,Shihao Liang,Junting Lu,Zhiyong Wu,Jiazhan Feng,Wanjun Zhong,Zili Li,Yu Wang,Yu Miao,Bo Zhou,Yuanfan Li,Hao Wang,Zhongkai Zhao,Faming Wu,Zhengxuan Jiang,Weihao Tan,Heyuan Yao,Shi Yan,Xiangyang Li,Yitao Liang,Yujia Qin,Guang Shi*

Main category: cs.AI

TL;DR: Game-TARS通过统一人类原生操作接口的动作空间，实现跨平台游戏智能体的高效训练与强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于API或GUI的游戏智能体难以在多领域持续扩展，作者希望通过人类一致的操作接口实现更通用、更具可扩展性的智能体架构，从而推动具有广泛计算机使用能力的通用人工智能发展。

Method: 采用统一键鼠动作空间的多模态大规模预训练策略，引入衰减性持续损失机制以减少因果混淆，并使用稀疏思维（Sparse-Thinking）技术在推理深度与计算成本之间取得平衡。

Result: 本文提出了一个名为Game-TARS的通用游戏智能体，它通过统一且可扩展的动作空间进行大规模预训练，该动作空间基于人类常用的键盘和鼠标输入方式。该模型能够跨操作系统、网页和模拟游戏等异构领域进行持续预训练，并在超过5000亿个token的数据上学习多模态行为。

Conclusion: 实验表明，Game-TARS在Minecraft任务中成功率提升约两倍，在未见过的3D网页游戏中接近人类新手水平，并在FPS基准测试中超过多个顶级模型，验证了统一动作空间和大规模预训练在构建通用智能体方面的有效性。

Abstract: We present Game-TARS, a generalist game agent trained with a unified,
scalable action space anchored to human-aligned native keyboard-mouse inputs.
Unlike API- or GUI-based approaches, this paradigm enables large-scale
continual pre-training across heterogeneous domains, including OS, web, and
simulation games. Game-TARS is pre-trained on over 500B tokens with diverse
trajectories and multimodal data. Key techniques include a decaying continual
loss to reduce causal confusion and an efficient Sparse-Thinking strategy that
balances reasoning depth and inference cost. Experiments show that Game-TARS
achieves about 2 times the success rate over the previous sota model on
open-world Minecraft tasks, is close to the generality of fresh humans in
unseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet
in FPS benchmarks. Scaling results on training-time and test-time confirm that
the unified action space sustains improvements when scaled to cross-game and
multimodal data. Our results demonstrate that simple, scalable action
representations combined with large-scale pre-training provide a promising path
toward generalist agents with broad computer-use abilities.

</details>


### [60] [AI and the Decentering of Disciplinary Creativity](https://arxiv.org/abs/2510.23734)
*Eamon Duede*

Main category: cs.AI

TL;DR: 论文通过哲学框架与数学案例说明人工智能既能提升又可能削弱学科创造力，对科学研究的价值体系产生重要影响。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能在科学研究中对学科创造力的影响，理解其对科学追求价值的潜在改变。

Method: 通过哲学分析与两个数学领域的案例研究来探讨人工智能参与科学创造的方式。

Result: 计算手段可增强学科创造力，但某些人工智能方法可能使学科创造力被替代，从而影响科学活动的核心价值。

Conclusion: 人工智能在科学问题求解中既能扩展学科创造力，也可能取代或削弱其价值。

Abstract: This paper examines the role of artificial intelligence in scientific
problem-solving, with a focus on its implications for disciplinary creativity.
Drawing on recent work in the philosophy of creativity, I distinguish between
creative approaches and creative products, and introduce the concept of
disciplinary creativity -the creative application of discipline-specific
expertise to a valued problem within that field. Through two cases in
mathematics, I show that while computation can extend disciplinary creativity,
certain approaches involving AI can serve to displace it. This displacement has
the potential to alter (and, perhaps, diminish) the value of scientific
pursuit.

</details>


### [61] [Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability](https://arxiv.org/abs/2510.23744)
*Eline M. Bovy,Caleb Probine,Marnix Suilen,Ufuk Topcu,Nils Jansen*

Main category: cs.AI

TL;DR: 本文提出ME-POMDP和AB-POMDP模型，并开发精确和近似算法以计算鲁棒策略。


<details>
  <summary>Details</summary>
Motivation: 针对实际问题中多个专家模型不一致导致的模型不确定性，作者希望构造一种能在所有情境下保持性能稳定的策略模型。

Method: 提出了从ME-POMDP到AB-POMDP的推广与简化方法，并设计了精确及基于点的近似算法来计算鲁棒策略。

Result: 本文扩展了传统的POMDP概念，提出了多环境POMDP（ME-POMDP）模型，用来处理存在离散模型不确定性的情境，目标是找到一种在所有可能模型下都能实现最优最差表现的鲁棒策略。

Conclusion: 研究表明，ME-POMDP问题可以转化为仅在部分模型成分上变动的形式，并且通过所提出的算法能够有效求解鲁棒策略，适用于多环境扩展的标准POMDP基准问题。

Abstract: Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete
model uncertainty. ME-POMDPs represent a finite set of POMDPs that share the
same state, action, and observation spaces, but may arbitrarily vary in their
transition, observation, and reward models. Such models arise, for instance,
when multiple domain experts disagree on how to model a problem. The goal is to
find a single policy that is robust against any choice of POMDP within the set,
i.e., a policy that maximizes the worst-case reward across all POMDPs. We
generalize and expand on existing work in the following way. First, we show
that ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which
we call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any
arbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its
transition and reward functions or only in its observation and reward
functions, while preserving (optimal) policies. We then devise exact and
approximate (point-based) algorithms to compute robust policies for AB-POMDPs,
and thus ME-POMDPs. We demonstrate that we can compute policies for standard
POMDP benchmarks extended to the multi-environment setting.

</details>


### [62] [Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra](https://arxiv.org/abs/2510.23746)
*Laura Mismetti,Marvin Alberts,Andreas Krause,Mara Graziani*

Main category: cs.AI

TL;DR: 本文提出了一种基于测试时调优（test-time tuning）的Transformer模型，用于从质谱数据直接生成分子结构，突破了依赖数据库匹配的局限。


<details>
  <summary>Details</summary>
Motivation: 现有的质谱分析方法依赖数据库匹配或多步骤中间预测，难以识别数据库中不存在的未知化合物。

Method: 使用预训练Transformer与测试时调优机制，直接从串联质谱数据和分子式生成分子结构，避免人工注释和中间步骤。

Result: 在NPLIB1和MassSpecGym两个基准上分别比当前最优方法DiffMS提升100%和20%，并在MassSpecGym上比传统微调方式提升62%。

Conclusion: 该方法能显著提升未知化合物的识别精度，提高结构生成的可靠性，对人工分析具有重要辅助作用。

Abstract: Tandem Mass Spectrometry enables the identification of unknown compounds in
crucial fields such as metabolomics, natural product discovery and
environmental analysis. However, current methods rely on database matching from
previously observed molecules, or on multi-step pipelines that require
intermediate fragment or fingerprint prediction. This makes finding the correct
molecule highly challenging, particularly for compounds absent from reference
databases. We introduce a framework that, by leveraging test-time tuning,
enhances the learning of a pre-trained transformer model to address this gap,
enabling end-to-end de novo molecular structure generation directly from the
tandem mass spectra and molecular formulae, bypassing manual annotations and
intermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on
two popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.
Test-time tuning on experimental spectra allows the model to dynamically adapt
to novel spectra, and the relative performance gain over conventional
fine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground
truth, the generated molecular candidates remain structurally accurate,
providing valuable guidance for human interpretation and more reliable
identification.

</details>


### [63] [Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions](https://arxiv.org/abs/2510.23772)
*Vivek Veeriah,Federico Barbero,Marcus Chiam,Xidong Feng,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Johan Obando-Ceron,Jiaxin Shi,Shaobo Hou,Satinder Singh,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 该论文探讨了生成式AI在生成创意棋题方面的能力，并通过专家评审来验证其创造性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI快速发展，越来越多人关注其是否具有真正的创造力。作者希望通过象棋谜题这一可衡量且富艺术性的领域来探索AI的创意潜力。

Method: 作者开发了一个基于生成式AI的系统，用算法生成具有美感和创新性的象棋谜题，并由三位专家进行审美与创意评估，以定性分析AI创作的表现。

Result: 论文研究了生成式人工智能在创作和生成新颖内容方面的能力，具体选择国际象棋谜题作为测试领域，构建了一个能生成具有审美性、创新性、反直觉性和独特解法的棋题系统。研究中还邀请了三位国际知名棋艺专家对系统生成的谜题进行评估，从创意、挑战性及美学设计等方面发表意见。

Conclusion: 研究表明，生成式AI有潜力在象棋谜题领域展现出创造性和审美价值，专家的反馈支持AI在艺术性内容生产中的应用前景。

Abstract: The rapid advancement of Generative AI has raised significant questions
regarding its ability to produce creative and novel outputs. Our recent work
investigates this question within the domain of chess puzzles and presents an
AI system designed to generate puzzles characterized by aesthetic appeal,
novelty, counter-intuitive and unique solutions. We briefly discuss our method
below and refer the reader to the technical paper for more details. To assess
our system's creativity, we presented a curated booklet of AI-generated puzzles
to three world-renowned experts: International Master for chess compositions
Amatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All
three are noted authors on chess aesthetics and the evolving role of computers
in the game. They were asked to select their favorites and explain what made
them appealing, considering qualities such as their creativity, level of
challenge, or aesthetic design.

</details>


### [64] [Why Foundation Models in Pathology Are Failing](https://arxiv.org/abs/2510.23807)
*Hamid R. Tizhoosh*

Main category: cs.AI

TL;DR: 本文指出计算病理学的基础模型存在概念性错配，需重新思考其建模范式。


<details>
  <summary>Details</summary>
Motivation: 基础模型在非医学领域取得巨大成功，研究者希望其能同样推动计算病理学发展，但结果并未达到预期，因此需要探讨背后的根本原因。

Method: 系统性评估与概念分析方法

Result: 发现计算病理学中的基础模型存在诊断准确度低、鲁棒性差、几何不稳定、计算代价高以及安全隐患等问题，并揭示了七个相互关联的根本原因。

Conclusion: 现有病理领域基础模型与组织形态学的本质特征不匹配，应进行根本性范式重构以适应生物组织的复杂性。

Abstract: In non-medical domains, foundation models (FMs) have revolutionized computer
vision and language processing through large-scale self-supervised and
multimodal learning. Consequently, their rapid adoption in computational
pathology was expected to deliver comparable breakthroughs in cancer diagnosis,
prognostication, and multimodal retrieval. However, recent systematic
evaluations reveal fundamental weaknesses: low diagnostic accuracy, poor
robustness, geometric instability, heavy computational demands, and concerning
safety vulnerabilities. This short paper examines these shortcomings and argues
that they stem from deeper conceptual mismatches between the assumptions
underlying generic foundation modeling in mainstream AI and the intrinsic
complexity of human tissue. Seven interrelated causes are identified:
biological complexity, ineffective self-supervision, overgeneralization,
excessive architectural complexity, lack of domain-specific innovation,
insufficient data, and a fundamental design flaw related to tissue patch size.
These findings suggest that current pathology foundation models remain
conceptually misaligned with the nature of tissue morphology and call for a
fundamental rethinking of the paradigm itself.

</details>


### [65] [ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents](https://arxiv.org/abs/2510.23822)
*Zhenyu Zhang,Tianyi Chen,Weiran Xu,Alex Pentland,Jiaxin Pei*

Main category: cs.AI

TL;DR: 该论文提出ReCAP框架，用于提升LLM在长时间多步推理与动态规划任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在长时序任务中易出现上下文漂移和目标丢失，传统层次方法效率低下，因此亟需一种兼顾上下文共享与层次一致性的推理框架。

Method: ReCAP采用分层递归架构，包含三个机制：计划前瞻分解、父级计划重注入以及高效内存管理，使LLM在多层推理中保持上下文连续与成本可控。

Result: 在Robotouille等长时序推理基准上，ReCAP在严格pass@1协议下同步模式提升32%，异步模式提升29%。

Conclusion: 实验表明，ReCAP在长周期推理任务中显著提高了子目标对齐度与成功率，效果优于现有层次化或顺序提示方法。

Abstract: Long-horizon tasks requiring multi-step reasoning and dynamic re-planning
remain challenging for large language models (LLMs). Sequential prompting
methods are prone to context drift, loss of goal information, and recurrent
failure cycles, while hierarchical prompting methods often weaken cross-level
continuity or incur substantial runtime overhead. We introduce ReCAP (Recursive
Context-Aware Reasoning and Planning), a hierarchical framework with shared
context for reasoning and planning in LLMs. ReCAP combines three key
mechanisms: (i) plan-ahead decomposition, in which the model generates a full
subtask list, executes the first item, and refines the remainder; (ii)
structured re-injection of parent plans, maintaining consistent multi-level
context during recursive return; and (iii) memory-efficient execution, bounding
the active prompt so costs scale linearly with task depth. Together these
mechanisms align high-level goals with low-level actions, reduce redundant
prompting, and preserve coherent context updates across recursion. Experiments
demonstrate that ReCAP substantially improves subgoal alignment and success
rates on various long-horizon reasoning benchmarks, achieving a 32% gain on
synchronous Robotouille and a 29% improvement on asynchronous Robotouille under
the strict pass@1 protocol.

</details>


### [66] [Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models](https://arxiv.org/abs/2510.23824)
*Murad Ismayilov,Edwin Meriaux,Shuo Wen,Gregory Dudek*

Main category: cs.AI

TL;DR: 比较传统启发式、最优方法与LLM智能体的多智能体去中心化目标分配策略，结果显示LLM在合理提示下达到近乎最优性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中在共享环境下进行任务分配一直是机器人与人工智能领域的难题，尤其在缺乏集中协调的情况下。本文旨在探索利用语言模型改进去中心化目标分配以提升路径规划效率。

Method: 本文采用在完全可观测网格世界环境下对多智能体目标分配的去中心化方法，包括基于贪心启发式、最优分配算法以及基于大型语言模型（LLM）的智能体进行系统比较。智能体在环境中独立生成目标偏好排名，并通过确定性冲突解决规则（如智能体索引顺序）分配目标。

Result: 实验表明，当LLM智能体获得设计良好的提示与定量信息时，其完成任务的总耗时接近最优，并在性能上明显优于传统贪心启发式算法。

Conclusion: 研究表明语言模型在无集中协商的多智能体路径规划目标分配中具备显著潜力，合理设计的信息结构对系统性能至关重要。

Abstract: Coordinating multiple autonomous agents in shared environments under
decentralized conditions is a long-standing challenge in robotics and
artificial intelligence. This work addresses the problem of decentralized goal
assignment for multi-agent path planning, where agents independently generate
ranked preferences over goals based on structured representations of the
environment, including grid visualizations and scenario data. After this
reasoning phase, agents exchange their goal rankings, and assignments are
determined by a fixed, deterministic conflict-resolution rule (e.g., agent
index ordering), without negotiation or iterative coordination. We
systematically compare greedy heuristics, optimal assignment, and large
language model (LLM)-based agents in fully observable grid-world settings. Our
results show that LLM-based agents, when provided with well-designed prompts
and relevant quantitative information, can achieve near-optimal makespans and
consistently outperform traditional heuristics. These findings underscore the
potential of language models for decentralized goal assignment in multi-agent
path planning and highlight the importance of information structure in such
systems.

</details>


### [67] [Generating Creative Chess Puzzles](https://arxiv.org/abs/2510.23881)
*Xidong Feng,Vivek Veeriah,Marcus Chiam,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Federico Barbero,Johan Obando-Ceron,Jiaxin Shi,Satinder Singh,Shaobo Hou,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 通过强化学习改进生成式AI，使其能产生更具创造性和反直觉性的国际象棋谜题。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI在多个领域迅速发展，但在创意和美学生成方面仍有限；研究旨在解决生成国际象棋谜题时缺乏创造性与反直觉特征的问题。

Method: 论文结合生成式AI模型与强化学习（RL），设计基于棋力引擎搜索统计的奖励机制，用以度量谜题的独特性、反直觉性和真实性，并据此优化生成策略。

Result: 该论文提出一种基于强化学习的框架，用于在国际象棋谜题生成中提高创造性和反直觉性。研究通过与现有生成式AI模型对比，利用基于棋力引擎搜索数据的创新奖励函数，显著增强生成谜题的独特性、多样性与美感。

Conclusion: 实验显示，新方法使反直觉谜题生成率提高了约10倍，并在专家评审中表现出更高的创意和审美价值，其生成结果接近经典人类创作的谜题水平。

Abstract: While Generative AI rapidly advances in various domains, generating truly
creative, aesthetic, and counter-intuitive outputs remains a challenge. This
paper presents an approach to tackle these difficulties in the domain of chess
puzzles. We start by benchmarking Generative AI architectures, and then
introduce an RL framework with novel rewards based on chess engine search
statistics to overcome some of those shortcomings. The rewards are designed to
enhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.
Our RL approach dramatically increases counter-intuitive puzzle generation by
10x, from 0.22\% (supervised) to 2.5\%, surpassing existing dataset rates
(2.1\%) and the best Lichess-trained model (0.4\%). Our puzzles meet novelty
and diversity benchmarks, retain aesthetic themes, and are rated by human
experts as more creative, enjoyable, and counter-intuitive than composed book
puzzles, even approaching classic compositions. Our final outcome is a curated
booklet of these AI-generated puzzles, which is acknowledged for creativity by
three world-renowned experts.

</details>


### [68] [Latent Chain-of-Thought for Visual Reasoning](https://arxiv.org/abs/2510.23925)
*Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao*

Main category: cs.AI

TL;DR: 论文通过摊销变分推断与多样性强化学习改进LVLM的推理能力，在多个基准任务上实现泛化与解释性的提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模视觉语言模型在推理任务中的可解释性和泛化能力较弱，主要原因是当前的训练算法（如SFT、PPO、GRPO）依赖有偏的奖励模型并缺乏对未见推理任务的适应能力。

Method: 作者将LVLM的推理过程重新表述为后验推断，提出了一种基于摊销变分推断的可扩展训练算法，并结合多样性导向的强化学习方法，引入稀疏奖励函数和贝叶斯推断缩放策略，以提升模型对多样推理路径的学习能力。

Result: 该方法在七个推理基准测试中显著提升了最先进LVLM的有效性、泛化性和可解释性。

Conclusion: 通过将推理建模为后验推断并结合强化学习与贝叶斯方法，可有效提高LVLM在复杂推理任务中的表现与解释能力。

Abstract: Chain-of-thought (CoT) reasoning is critical for improving the
interpretability and reliability of Large Vision-Language Models (LVLMs).
However, existing training algorithms such as SFT, PPO, and GRPO may not
generalize well across unseen reasoning tasks and heavily rely on a biased
reward model. To address this challenge, we reformulate reasoning in LVLMs as
posterior inference and propose a scalable training algorithm based on
amortized variational inference. By leveraging diversity-seeking reinforcement
learning algorithms, we introduce a novel sparse reward function for
token-level learning signals that encourage diverse, high-likelihood latent
CoT, overcoming deterministic sampling limitations and avoiding reward hacking.
Additionally, we implement a Bayesian inference-scaling strategy that replaces
costly Best-of-N and Beam Search with a marginal likelihood to efficiently rank
optimal rationales and answers. We empirically demonstrate that the proposed
method enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in
terms of effectiveness, generalization, and interpretability.

</details>


### [69] [Decentralized Causal Discovery using Judo Calculus](https://arxiv.org/abs/2510.23942)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 本文提出一个基于拓扑斯理论的去中心化因果发现框架judo calculus，能形式化刻画上下文依赖性，实验显示其在效率与性能上均优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法通常假设因果关系在所有实验环境或制度下保持一致，但在现实应用中（如生物学、医学、社会科学），不同条件（年龄、国家、剂量、基因型等）会导致因果效应变化，因此需要一种能够形式化表示上下文依赖性和局部真理的因果推理框架。

Method: 提出一种基于拓扑斯层范畴的直觉主义去中心化因果发现框架——judo calculus。该方法利用Lawvere-Tierney模态算子j定义局部真理，通过j-do-calculus实现j稳定因果推断，并结合传统的得分法、约束法及梯度法进行算法化实现。

Result: 提出的judo calculus框架在多个合成和真实数据集（包括生物学和经济学）上进行了实验，结果显示：该方法不仅提高了计算效率，还在性能上优于传统因果发现方法。

Conclusion: judo calculus通过引入j稳定性和局部真理的概念，提供了一种构造性一致的因果推理新范式，为多领域上下文相关的因果发现提供理论与计算上的改进。

Abstract: We describe a theory and implementation of an intuitionistic decentralized
framework for causal discovery using judo calculus, which is formally defined
as j-stable causal inference using j-do-calculus in a topos of sheaves. In
real-world applications -- from biology to medicine and social science --
causal effects depend on regime (age, country, dose, genotype, or lab
protocol). Our proposed judo calculus formalizes this context dependence
formally as local truth: a causal claim is proven true on a cover of regimes,
not everywhere at once. The Lawvere-Tierney modal operator j chooses which
regimes are relevant; j-stability means the claim holds constructively and
consistently across that family. We describe an algorithmic and implementation
framework for judo calculus, combining it with standard score-based,
constraint-based, and gradient-based causal discovery methods. We describe
experimental results on a range of domains, from synthetic to real-world
datasets from biology and economics. Our experimental results show the
computational efficiency gained by the decentralized nature of sheaf-theoretic
causal discovery, as well as improved performance over classical causal
discovery methods.

</details>


### [70] [The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity](https://arxiv.org/abs/2510.23965)
*Aymane El Gadarri,Ali Aouad,Vivek F. Farias*

Main category: cs.AI

TL;DR: 本文提出一种名为 sign estimator 的新方法，用于改进大语言模型（LLM）在面对人类偏好异质性时的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 传统的 LLM 对齐方法在处理不同人类偏好时存在偏差，会导致整体社会效用估计不一致，因此需要一种既简单又鲁棒的新方法。

Method: 通过将配对比较数据的交叉熵损失替换为二元分类损失，从而获得一致且高效的社会福利估计；在有限样本下具备多项式误差界。

Result: 在数字孪生仿真实验中，sign estimator 将角度估计误差降低约 35%，总体偏好不一致率从 12% 降至 8%，效果超过标准 RLHF 和需跟踪个体偏好的复杂面板方法。

Conclusion: sign estimator 在保证方法简单性的同时，显著降低了偏好失真和估计误差，相比标准 RLHF 拥有更好的对齐性能。

Abstract: Traditional LLM alignment methods are vulnerable to heterogeneity in human
preferences. Fitting a na\"ive probabilistic model to pairwise comparison data
(say over prompt-completion pairs) yields an inconsistent estimate of the
population-average utility -a canonical measure of social welfare. We propose a
new method, dubbed the sign estimator, that provides a simple, provably
consistent, and efficient estimator by replacing cross-entropy with binary
classification loss in the aggregation step. This simple modification recovers
consistent ordinal alignment under mild assumptions and achieves the first
polynomial finite-sample error bounds in this setting. In realistic simulations
of LLM alignment using digital twins, the sign estimator substantially reduces
preference distortion over a panel of simulated personas, cutting (angular)
estimation error by nearly 35% and decreasing disagreement with true population
preferences from 12% to 8% compared to standard RLHF. Our method also compares
favorably to panel data heuristics that explicitly model user heterogeneity and
require tracking individual-level preference data-all while maintaining the
implementation simplicity of existing LLM alignment pipelines.

</details>


### [71] [Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance](https://arxiv.org/abs/2510.23989)
*Shangde Gao,Zelin Xu,Zhe Jiang*

Main category: cs.AI

TL;DR: 本文通过引入社会基础设施韧性（SIR）与空间环境信息的条件化深度学习模型，有效提升了破坏性事件后个体移动模式的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有预测模型缺乏对个体社会基础设施韧性的量化，且未充分捕捉移动模式与空间环境的复杂交互，使得在破坏性事件前预测个体行为变化极具挑战。

Method: 本文采用了一种条件化深度学习模型，结合个体的社会基础设施韧性指标与局部空间背景信息，对大规模且稀疏的个体移动数据进行建模与预测。

Result: 实验表明，该模型能够更准确地预测事件后的移动模式，尤其能区分在事件前行为相似但社会基础设施韧性不同的个体，其预测结果存在显著差异。

Conclusion: 研究得出结论：在模型中融入个体的社会基础设施韧性（SIR）和空间背景可以显著提升对事件后个体移动模式的预测能力。

Abstract: Shifts in individual movement patterns following disruptive events can reveal
changing demands for community resources. However, predicting such shifts
before disruptive events remains challenging for several reasons. First,
measures are lacking for individuals' heterogeneous social infrastructure
resilience (SIR), which directly influences their movement patterns, and
commonly used features are often limited or unavailable at scale, e.g.,
sociodemographic characteristics. Second, the complex interactions between
individual movement patterns and spatial contexts have not been sufficiently
captured. Third, individual-level movement may be spatially sparse and not
well-suited to traditional decision-making methods for movement predictions.
This study incorporates individuals' SIR into a conditioned deep learning model
to capture the complex relationships between individual movement patterns and
local spatial context using large-scale, sparse individual-level data. Our
experiments demonstrate that incorporating individuals' SIR and spatial context
can enhance the model's ability to predict post-event individual movement
patterns. The conditioned model can capture the divergent shifts in movement
patterns among individuals who exhibit similar pre-event patterns but differ in
SIR.

</details>


### [72] [OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting](https://arxiv.org/abs/2510.24028)
*Tingyue Pan,Mingyue Cheng,Shilong Zhang,Zhiding Liu,Xiaoyu Tao,Yucong Luo,Jintao Zhang,Qi Liu*

Main category: cs.AI

TL;DR: 该论文提出了用于跨领域时间序列预测的框架 OneCast，通过结构化分解提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在面对异构时间序列的趋势漂移与周期性不一致时泛化不足，主要因为未区分时间序列内部结构。作者希望通过明确分解结构提升跨域预测能力。

Method: 作者将时间序列分解为季节性与趋势两部分。季节性部分用轻量投影模块基于可解释基函数建模周期性模式；趋势部分通过语义感知分词器编码为离散标记，再采用掩蔽离散扩散机制进行推断，最后聚合两部分生成预测结果。

Result: 在八个不同数据域上测试显示，OneCast 在预测精度上多数情况下超越当前最佳基线方法。

Conclusion: OneCast 在八个不同领域的实验中显著优于现有最先进方法，验证了其在趋势与季节性建模上的有效性与鲁棒性。

Abstract: Cross-domain time series forecasting is a valuable task in various web
applications. Despite its rapid advancement, achieving effective generalization
across heterogeneous time series data remains a significant challenge. Existing
methods have made progress by extending single-domain models, yet often fall
short when facing domain-specific trend shifts and inconsistent periodic
patterns. We argue that a key limitation lies in treating temporal series as
undifferentiated sequence, without explicitly decoupling their inherent
structural components. To address this, we propose OneCast, a structured and
modular forecasting framework that decomposes time series into seasonal and
trend components, each modeled through tailored generative pathways.
Specifically, the seasonal component is captured by a lightweight projection
module that reconstructs periodic patterns via interpretable basis functions.
In parallel, the trend component is encoded into discrete tokens at segment
level via a semantic-aware tokenizer, and subsequently inferred through a
masked discrete diffusion mechanism. The outputs from both branches are
combined to produce a final forecast that captures seasonal patterns while
tracking domain-specific trends. Extensive experiments across eight domains
demonstrate that OneCast mostly outperforms state-of-the-art baselines.

</details>


### [73] [Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach](https://arxiv.org/abs/2510.24085)
*Md. Shihab Uddin,Md Nazmus Shakib,Rahul Bhadani*

Main category: cs.AI

TL;DR: 本文通过比较随机森林与传统车随模型发现，随机森林在电动车行为预测上精度显著更高。


<details>
  <summary>Details</summary>
Motivation: 随着电动车普及，需要准确的驾驶行为模型以提升交通安全及智能驾驶系统开发，因此展开对比研究以确定最佳建模方法。

Method: 以真实驾驶数据为基础，对经典模型进行参数校准并用随机森林回归预测加速度，通过RMSE评价模型性能。

Result: 本文比较了电动车跟车行为的经典物理模型与机器学习模型。经典模型包括IDM、OVM、OVRV以及简化的CACC模型，机器学习采用随机森林回归。实验数据来自现实中的电动车跟随内燃机汽车的行驶数据，通过最小化RMSE进行模型参数校准。结果显示随机森林模型在不同车距下具有更小的误差（最优RMSE分别为0.0046、0.0016和0.0025），显著优于物理模型，其中CACC表现最好，RMSE为2.67。

Conclusion: 机器学习模型特别是随机森林在预测电动车加速度和行为方面精度更高，可用于电动车交通仿真和混合自主系统分析。

Abstract: The increasing adoption of electric vehicles (EVs) necessitates an
understanding of their driving behavior to enhance traffic safety and develop
smart driving systems. This study compares classical and machine learning
models for EV car following behavior. Classical models include the Intelligent
Driver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative
Velocity (OVRV), and a simplified CACC model, while the machine learning
approach employs a Random Forest Regressor. Using a real world dataset of an EV
following an internal combustion engine (ICE) vehicle under varied driving
conditions, we calibrated classical model parameters by minimizing the RMSE
between predictions and real data. The Random Forest model predicts
acceleration using spacing, speed, and gap type as inputs. Results demonstrate
the Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),
0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,
CACC performed best, with an RMSE of 2.67 for long gaps. These findings
highlight the machine learning model's performance across all scenarios. Such
models are valuable for simulating EV behavior and analyzing mixed autonomy
traffic dynamics in EV integrated environments.

</details>


### [74] [HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology](https://arxiv.org/abs/2510.24115)
*Sandeep Vissapragada,Vikrant Sahu,Gagan Raj Gupta,Vandita Singh*

Main category: cs.AI

TL;DR: HistoLens 让医生能像与同事对话一样理解AI诊断结果，并提供可视化验证。


<details>
  <summary>Details</summary>
Motivation: 增强医生对人工智能诊断工具的信任感，避免传统AI模型的“黑箱”问题。

Method: 通过建立自然语言查询接口、AI视觉分析引擎以及基于热图的可解释性机制，实现了透明且交互式的病理图像分析系统。

Result: 开发了一个名为 HistoLens 的系统，使病理学家能以自然语言询问并获得结构化报告及对应的可视化证据。

Conclusion: HistoLens 实现了人机协作的透明诊断支持，使病理医生在保持主导权的同时获得AI的高效辅助。

Abstract: For doctors to truly trust artificial intelligence, it can't be a black box.
They need to understand its reasoning, almost as if they were consulting a
colleague. We created HistoLens1 to be that transparent, collaborative partner.
It allows a pathologist to simply ask a question in plain English about a
tissue slide--just as they would ask a trainee. Our system intelligently
translates this question into a precise query for its AI engine, which then
provides a clear, structured report. But it doesn't stop there. If a doctor
ever asks, "Why?", HistoLens can instantly provide a 'visual proof' for any
finding--a heatmap that points to the exact cells and regions the AI used for
its analysis. We've also ensured the AI focuses only on the patient's tissue,
just like a trained pathologist would, by teaching it to ignore distracting
background noise. The result is a workflow where the pathologist remains the
expert in charge, using a trustworthy AI assistant to verify their insights and
make faster, more confident diagnoses.

</details>


### [75] [From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems](https://arxiv.org/abs/2510.24145)
*Yu Luo,Jiamin Jiang,Jingfei Feng,Lei Tao,Qingliang Zhang,Xidao Wen,Yongqian Sun,Shenglin Zhang,Jielong Huang,Nan Qi,Dan Pei*

Main category: cs.AI

TL;DR: OpsAgent通过多智能体协作与自演化机制，实现高效、可解释且具有自我改进能力的云系统事件管理。


<details>
  <summary>Details</summary>
Motivation: 为解决大规模云系统中手工事件管理效率低、错误率高及现有自动化方法通用性差、解释性不足和部署成本高的问题。

Method: 采用多智能体系统架构，包括一个无训练数据处理器用于将异构观测数据转化为结构化文本描述，以及一个多智能体推理框架以支持透明的诊断与自演化机制。

Result: 本文提出了一个名为OpsAgent的系统，用于提升云系统的事件管理效率。通过训练无需模型的轻量数据处理器和多智能体协作框架，OpsAgent能够有效地将复杂的观测数据转化为可解释的诊断推理过程，实现透明和可审计的自动化事件管理。实验结果表明该系统在通用性、可解释性、成本效率和自演化能力方面均优于现有方法。

Conclusion: OpsAgent在开放事件管理基准测试中表现出色，具备可持续部署能力，是一个适合长期实际应用的事件管理解决方案。

Abstract: Incident management (IM) is central to the reliability of large-scale cloud
systems. Yet manual IM, where on-call engineers examine metrics, logs, and
traces is labor-intensive and error-prone in the face of massive and
heterogeneous observability data. Existing automated IM approaches often
struggle to generalize across systems, provide limited interpretability, and
incur high deployment costs, which hinders adoption in practice. In this paper,
we present OpsAgent, a lightweight, self-evolving multi-agent system for IM
that employs a training-free data processor to convert heterogeneous
observability data into structured textual descriptions, along with a
multi-agent collaboration framework that makes diagnostic inference transparent
and auditable. To support continual capability growth, OpsAgent also introduces
a dual self-evolution mechanism that integrates internal model updates with
external experience accumulation, thereby closing the deployment loop.
Comprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art
performance and show that OpsAgent is generalizable, interpretable,
cost-efficient, and self-evolving, making it a practically deployable and
sustainable solution for long-term operation in real-world cloud systems.

</details>


### [76] [BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data](https://arxiv.org/abs/2510.24151)
*Bingsen Qiu,Zijian Liu,Xiao Liu,Haoshen Yang,Zeren Gao,Bingjie Wang,Feier Zhang,Yixuan Qin,Chunyan Li*

Main category: cs.AI

TL;DR: 该论文提出一种自动化框架，用于生成高难度、多跳问答训练数据，以解决数据稀缺和人工构建成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多跳问答数据集多用于评估而非训练，且难以规模化构建，限制了模型在复杂检索与推理任务中的提升。

Method: 作者设计了一个自动生成系统：（i）通过基于自然语言推理的关系标注和多样性扩展生成证据簇；（ii）利用反向问题构建生成包含间接线索的问题；（iii）用双阶段评估机制（模型共识过滤与结构化约束分解）进行质量控制。

Result: 生成的问题具备高复杂度、可验证且难以直接检索，显著减少了人工工作量，同时保留了现有评测数据集的难度特征。

Conclusion: 该方法实现了多跳问答数据的高质量自动化生成，为模型的SFT与RL训练提供了可扩展的数据来源。

Abstract: Building training-ready multi-hop question answering (QA) datasets that truly
stress a model's retrieval and reasoning abilities remains highly challenging
recently. While there have been a few recent evaluation datasets that capture
the characteristics of hard-to-search but easy-to-verify problems -- requiring
the integration of ambiguous, indirect, and cross-domain cues -- these data
resources remain scarce and are mostly designed for evaluation, making them
unsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL).
Meanwhile, manually curating non-trivially retrievable questions -- where
answers cannot be found through a single direct query but instead require
multi-hop reasoning over oblique and loosely connected evidence -- incurs
prohibitive human costs and fails to scale, creating a critical data bottleneck
for training high-capability retrieval-and-reasoning agents.
  To address this, we present an automated framework for generating
high-difficulty, training-ready multi-hop questions from semi-structured
knowledge sources. The system (i) grows diverse, logically labeled evidence
clusters through Natural Language Inference (NLI)-based relation typing and
diversity-aware expansion; (ii) applies reverse question construction to
compose oblique cues so that isolated signals are underinformative but their
combination uniquely identifies the target entity; and (iii) enforces quality
with a two-step evaluation pipeline that combines multi-model consensus
filtering with structured constraint decomposition and evidence-based matching.
The result is a scalable process that yields complex, retrieval-resistant yet
verifiable questions suitable for SFT/RL training as well as challenging
evaluation, substantially reducing human curation effort while preserving the
difficulty profile of strong evaluation benchmarks.

</details>


### [77] [BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning](https://arxiv.org/abs/2510.24161)
*Wentao Tan,Bowen Wang,Heng Zhi,Chenyu Liu,Zhe Li,Jian Liu,Zengrong Lin,Yukun Dai,Yipeng Chen,Wenjie Yang,Enci Xie,Hao Xue,Baixu Ji,Chen Xu,Zhibin Wang,Tianshi Wang,Lei Zhu,Heng Tao Shen*

Main category: cs.AI

TL;DR: 本文提出BLM₁模型，通过两阶段训练实现跨空间、任务与体现的统一，在数字与物理场景均超越现有多模态模型。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在数字与物理空间间泛化能力差，缺乏稳健的高层具身推理以及跨体现的一致性，需要一种统一模型同时具备跨空间、跨任务及跨体现能力。

Method: 提出两阶段训练方法：第一阶段通过精心筛选的数字语料向MLLM注入具身知识，保持语言能力；第二阶段利用意图桥接接口训练策略模块，从MLLM提取高层语义指导控制，不需微调主干模型。

Result: BLM₁在数字任务中提升约6%，在物理任务中提升约3%，表现优于MLLMs、ELLMs、VLAs和GMLMs四类模型。

Conclusion: BLM₁模型成功实现了跨数字与物理空间的统一，多模态空间推理表现优于现有模型，并在多种任务和体现上都有显著提升。

Abstract: Multimodal large language models (MLLMs) have advanced vision-language
reasoning and are increasingly deployed in embodied agents. However,
significant limitations remain: MLLMs generalize poorly across digital-physical
spaces and embodiments; vision-language-action models (VLAs) produce low-level
actions yet lack robust high-level embodied reasoning; and most embodied large
language models (ELLMs) are constrained to digital-space with poor
generalization to the physical world. Thus, unified models that operate
seamlessly across digital and physical spaces while generalizing across
embodiments and tasks remain absent. We introduce the \textbf{Boundless Large
Model (BLM$_1$)}, a multimodal spatial foundation model that preserves
instruction following and reasoning, incorporates embodied knowledge, and
supports robust cross-embodiment control. BLM$_1$ integrates three key
capabilities -- \textit{cross-space transfer, cross-task learning, and
cross-embodiment generalization} -- via a two-stage training paradigm. Stage I
injects embodied knowledge into the MLLM through curated digital corpora while
maintaining language competence. Stage II trains a policy module through an
intent-bridging interface that extracts high-level semantics from the MLLM to
guide control, without fine-tuning the MLLM backbone. This process is supported
by a self-collected cross-embodiment demonstration suite spanning four robot
embodiments and six progressively challenging tasks. Evaluations across digital
and physical benchmarks show that a single BLM$_1$ instance outperforms four
model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving
$\sim\!\textbf{6%}$ gains in digital tasks and $\sim\!\textbf{3%}$ in physical
tasks.

</details>


### [78] [MGA: Memory-Driven GUI Agent for Observation-Centric Interaction](https://arxiv.org/abs/2510.24168)
*Weihua Cheng,Ersheng Ni,Wenlong Wang,Yifei Sun,Junming Liu,Wangyu Shen,Yirong Chen,Botian Shi,Ding Wang*

Main category: cs.AI

TL;DR: 本文提出记忆驱动GUI智能体（MGA），通过“先观察、后决策”的机制与结构化记忆增强鲁棒性与泛化性，在多项测试中超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图形用户界面（GUI）智能体在处理复杂桌面与网页任务时存在鲁棒性与泛化能力不足的问题，主要由于过度依赖历史轨迹和局部探索偏差造成决策失误。

Method: 提出Memory-Driven GUI Agent（MGA）框架，遵循“先观察，后决策”的原则。每一步操作视为独立的、具有上下文的状态，由当前截图、任务无关的空间信息以及动态更新的结构化记忆三部分构成，以减少错误传播和忽略界面关键线索的风险。

Result: 在OSworld基准测试、真实桌面应用（Chrome、VSCode、VLC）以及跨任务迁移实验中，MGA在鲁棒性、泛化性和效率方面均显著优于现有方法。

Conclusion: MGA通过引入记忆驱动机制与独立状态建模，成功提升GUI智能体的稳定性与泛化能力，是实现更通用桌面和网页操作智能体的重要一步。

Abstract: The rapid progress of Large Language Models (LLMs) and their multimodal
extensions (MLLMs) has enabled agentic systems capable of perceiving and acting
across diverse environments. A challenging yet impactful frontier is the
development of GUI agents, which must navigate complex desktop and web
interfaces while maintaining robustness and generalization. Existing paradigms
typically model tasks as long-chain executions, concatenating historical
trajectories into the context. While approaches such as Mirage and GTA1 refine
planning or introduce multi-branch action selection, they remain constrained by
two persistent issues: Dependence on historical trajectories, which amplifies
error propagation. And Local exploration bias, where "decision-first,
observation-later" mechanisms overlook critical interface cues. We introduce
the Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the
principle of observe first, then decide. MGA models each step as an
independent, context-rich environment state represented by a triad: current
screenshot, task-agnostic spatial information, and a dynamically updated
structured memory. Experiments on OSworld benchmarks, real desktop applications
(Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves
substantial gains in robustness, generalization, and efficiency compared to
state-of-the-art baselines. The code is publicly available at:
{https://anonymous.4open.science/r/MGA-3571}.

</details>


### [79] [Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms](https://arxiv.org/abs/2510.24297)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 论文改进了MCTS抽象处理的内部决策规则，用多种新策略替代随机决策，实验表明多数情况下性能更佳。


<details>
  <summary>Details</summary>
Motivation: 现有MCTS结合抽象的方法在遇到同一父节点下多个动作属于同一抽象节点时，会导致相同的UCB值并需随机决策，这可能降低算法效果。

Method: 通过在现有抽象算法（如pruned OGA）基础上设计并实证评估多种不同的抽象内策略，比较它们与随机策略在不同实验环境中的表现。

Result: 实证结果显示新设计的抽象内策略在多数实验环境和参数设置下，显著优于随机策略。

Conclusion: 提出了多种新的抽象内策略来改进MCTS中的抽象使用方式，相比随机策略在多数环境和参数设置下取得了更优性能。

Abstract: One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which
can be addressed by building and using state and/or action abstractions in
parallel to the tree search such that information can be shared among nodes of
the same layer. The primary usage of abstractions for MCTS is to enhance the
Upper Confidence Bound (UCB) value during the tree policy by aggregating visits
and returns of an abstract node. However, this direct usage of abstractions
does not take the case into account where multiple actions with the same parent
might be in the same abstract node, as these would then all have the same UCB
value, thus requiring a tiebreak rule. In state-of-the-art abstraction
algorithms such as pruned On the Go Abstractions (pruned OGA), this case has
not been noticed, and a random tiebreak rule was implicitly chosen. In this
paper, we propose and empirically evaluate several alternative
intra-abstraction policies, several of which outperform the random policy
across a majority of environments and parameter settings.

</details>


### [80] [Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank](https://arxiv.org/abs/2510.24299)
*Jiayu Liu,Wei Dai,Zhenya Huang,Ning Miao,Enhong Chen*

Main category: cs.AI

TL;DR: 使用LLM自身的相关矩阵秩作为正确性指标，可有效区分正确与错误推理路径。


<details>
  <summary>Details</summary>
Motivation: 现有LLM输出校验方法依赖外部资源且计算开销大，作者希望找到一种利用模型内部行为即可实现有效验证的简便方法。

Method: 通过计算输入问题与推理输出之间的相关矩阵秩来衡量推理可靠性，并据此对候选推理路径进行重新加权。

Result: 本文提出了一种名为“Self-Indicator”的自检方法，用于评估大语言模型（LLM）推理路径的可靠性。研究发现输入问题与输出推理路径之间相关矩阵的秩能够稳健地反映推理正确性。该方法无需外部训练模型或复杂提示，具有通用性和高效性。

Conclusion: Self-Indicator方法显著改进了推理准确率，在多个基准测试上提升超过8%，且计算成本低。

Abstract: Despite the strong reasoning ability of large language models~(LLMs), they
are prone to errors and hallucinations. As a result, how to check their outputs
effectively and efficiently has become a critical problem in their
applications. Existing checking methods heavily rely on external resources,
such as trained verifiers (e.g., process/outcome reward models) or elaborate
prompts, which lead to high computational overhead and are only applicable to
specific domains. In this paper, we investigate whether the internal behaviors
of LLMs have already implied the credibility of their reasoning paths.
Specifically, we find that the rank of the correlation matrix between the input
problem and the output reasoning path is a robust indicator of reasoning
correctness. Different from other correctness indicators for LLMs, the
calculation of the correlation matrix only relies on the LLM itself, which
avoids the hassle of training a separate model or designing complicated
prompts. Based on it, we design a simple, plug-and-play Self-Indicator method
to reweight candidate reasoning paths, which achieves significant performance
improvements than other voting and verification methods with very few
computational overhead. Our experiments across multiple LLMs of varying scales
and model families have further shown the effectiveness of Self-Indicator. It
achieves over 75% accuracy in distinguishing correct reasoning paths from
incorrect ones, and, in turn, improves the accuracies on three reasoning
benchmarks by more than 8%.

</details>


### [81] [Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting](https://arxiv.org/abs/2510.24303)
*Deniz Gorur,Antoni Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 多智能体框架结合多个LLM，通过论证组合提升未来事件预测精度并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于单一判断或模型的预测缺乏多方证据汇聚与可解释性，作者希望通过多智能体机制提升预测的可信度和透明度。

Method: 基于定量双极论证框架（QBAF）设计三类LLM智能体，分别通过现有论证生成、关系论证挖掘与检索增强生成进行声明验证实验。

Result: 本文提出一种多智能体框架，用于基于人类判断的未来事件预测，即“判断性预测”。该框架将这一任务视为声明验证问题，不同智能体可对声明真伪产生分歧并提供支持或反对证据。证据以定量双极论证框架（QBAF）的形式表示。作者通过三类LLM智能体实现该框架：ArgLLM、RbAM智能体与RAG-ArgLLM智能体，并在两个标准预测数据集上进行实验，结果表明多智能体的证据组合可提高预测准确率及解释性。

Conclusion: 多智能体协同验证和整合证据能够改善判断性预测的准确性与解释效果，尤其在三智能体设置下表现最佳。

Abstract: Judgmental forecasting is the task of making predictions about future events
based on human judgment. This task can be seen as a form of claim verification,
where the claim corresponds to a future event and the task is to assess the
plausibility of that event. In this paper, we propose a novel multi-agent
framework for claim verification, whereby different agents may disagree on
claim veracity and bring specific evidence for and against the claims,
represented as quantitative bipolar argumentation frameworks (QBAFs). We then
instantiate the framework for supporting claim verification, with a variety of
agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an
existing approach for claim verification that generates and evaluates QBAFs;
(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)
from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,
extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of
arguments from external sources. Finally, we conduct experiments with two
standard judgmental forecasting datasets, with instances of our framework with
two or three agents, empowered by six different base LLMs. We observe that
combining evidence from agents can improve forecasting accuracy, especially in
the case of three agents, while providing an explainable combination of
evidence for claim verification.

</details>


### [82] [Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research](https://arxiv.org/abs/2510.24337)
*Daria Kravets-Meinke,Hannah Schmid-Petri,Sonja Niemann,Ute Schmid*

Main category: cs.AI

TL;DR: 本文分析了生成式大语言模型在传播学内容分析中的应用潜力与挑战，提出标准化的操作指南以提升研究质量。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等生成式语言模型在传播学中的广泛应用，研究者亟需理解并规范它们在内容分析中的使用，以提升效率并确保方法学质量。

Method: 本文采用文献综述与实证研究结合的方法，对基于生成式大语言模型（gLLMs）的定量内容分析进行系统归纳与方法论探讨。

Result: 研究总结了gLLM在传播学内容编码任务中相较人工编码和众包工作者的优势，同时提出七项关键挑战及对应的最佳实践指南，以指导可靠的模型使用流程。

Conclusion: 研究指出gLLM正在引发自动化内容分析的范式转变，只要科学应对方法学挑战并遵守学科规范，就能在传播研究中形成更高效、可靠和伦理的研究模式。

Abstract: Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly
being used in communication research for content analysis. Studies show that
gLLMs can outperform both crowd workers and trained coders, such as research
assistants, on various coding tasks relevant to communication science, often at
a fraction of the time and cost. Additionally, gLLMs can decode implicit
meanings and contextual information, be instructed using natural language,
deployed with only basic programming skills, and require little to no annotated
data beyond a validation dataset - constituting a paradigm shift in automated
content analysis. Despite their potential, the integration of gLLMs into the
methodological toolkit of communication research remains underdeveloped. In
gLLM-assisted quantitative content analysis, researchers must address at least
seven critical challenges that impact result quality: (1) codebook development,
(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)
iterative refinement, (6) validation of the model's reliability, and
optionally, (7) performance enhancement. This paper synthesizes emerging
research on gLLM-assisted quantitative content analysis and proposes a
comprehensive best-practice guide to navigate these challenges. Our goal is to
make gLLM-based content analysis more accessible to a broader range of
communication researchers and ensure adherence to established disciplinary
quality standards of validity, reliability, reproducibility, and research
ethics.

</details>


### [83] [VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation](https://arxiv.org/abs/2510.24339)
*Yunxuan Jiang,Silan Hu,Xiaoning Wang,Yuanyuan Zhang,Xiangyu Chang*

Main category: cs.AI

TL;DR: 本文提出VDSAgents系统，将VDS框架的PCS原理融入LLM驱动的数据科学自动化流程，在多数据集测试中表现优于主流系统，显著增强可信度与稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的数据科学系统过分依赖模型内部推理，缺乏科学原理指导，导致在处理复杂和噪声数据时可信度和稳健性不足，因此引入VDS框架中的PCS原理以提高系统可靠性。

Method: 论文设计了一个基于多智能体的系统，每个智能体负责数据清理、特征工程、建模和评估等模块，并利用扰动分析、单元测试和模型验证实现科学可审计的自动化工作流。

Result: VDSAgents在包含九个不同特性的公开数据集上进行实证评估，结合DeepSeek-V3和GPT-4o后端，性能均超过AutoKaggle与DataInterpreter。

Conclusion: VDSAgents通过在LLM驱动的数据科学系统中嵌入PCS原理，有效提升了系统的可信度和鲁棒性，并在多个真实数据集上优于现有的自动化系统。

Abstract: Large language models (LLMs) become increasingly integrated into data science
workflows for automated system design. However, these LLM-driven data science
systems rely solely on the internal reasoning of LLMs, lacking guidance from
scientific and theoretical principles. This limits their trustworthiness and
robustness, especially when dealing with noisy and complex real-world datasets.
This paper provides VDSAgents, a multi-agent system grounded in the
Predictability-Computability-Stability (PCS) principles proposed in the
Veridical Data Science (VDS) framework. Guided by PCS principles, the system
implements a modular workflow for data cleaning, feature engineering, modeling,
and evaluation. Each phase is handled by an elegant agent, incorporating
perturbation analysis, unit testing, and model validation to ensure both
functionality and scientific auditability. We evaluate VDSAgents on nine
datasets with diverse characteristics, comparing it with state-of-the-art
end-to-end data science systems, such as AutoKaggle and DataInterpreter, using
DeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the
results of AutoKaggle and DataInterpreter, which validates the feasibility of
embedding PCS principles into LLM-driven data science automation.

</details>


### [84] [An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine](https://arxiv.org/abs/2510.24359)
*Pedram Fard,Alaleh Azhir,Neguine Rezaii,Jiazi Tian,Hossein Estiri*

Main category: cs.AI

TL;DR: 本文主张用多智能体协调系统取代单一模型，以提高AI在个体化医疗决策中的公平性与透明度。


<details>
  <summary>Details</summary>
Motivation: 现有医学AI倾向于优化平均表现，忽视罕见病人和数据稀疏群体，导致公平性与信任问题，因此需要针对个体而非总体的AI决策支持体系。

Method: 设计一个多智能体架构，智能体共享模型与证据库，并通过协调层综合分析可靠性、不确定性与数据密度，再向临床医生输出包含风险估计与置信区间的决策信息。

Result: 本文提出建立一个面向个体医疗决策支持的多智能体生态系统，而非仅聚焦平均病人的AI模型。该系统通过按器官系统、病患人群、分析方式等聚类的多个智能体协同工作，以提升AI在罕见病例及边缘人群中的决策可靠性。

Conclusion: 作者认为，多智能体协作能减轻“平均病人谬误”，改善个体层面的AI决策支持，使医疗AI更符合以患者为中心的原则。

Abstract: Artificial intelligence in medicine is built to serve the average patient. By
minimizing error across large datasets, most systems deliver strong aggregate
accuracy yet falter at the margins: patients with rare variants,
multimorbidity, or underrepresented demographics. This average patient fallacy
erodes both equity and trust. We propose a different design: a multi-agent
ecosystem for N-of-1 decision support. In this environment, agents clustered by
organ systems, patient populations, and analytic modalities draw on a shared
library of models and evidence synthesis tools. Their results converge in a
coordination layer that weighs reliability, uncertainty, and data density
before presenting the clinician with a decision-support packet: risk estimates
bounded by confidence ranges, outlier flags, and linked evidence. Validation
shifts from population averages to individual reliability, measured by error in
low-density regions, calibration in the small, and risk--coverage trade-offs.
Anticipated challenges include computational demands, automation bias, and
regulatory fit, addressed through caching strategies, consensus checks, and
adaptive trial frameworks. By moving from monolithic models to orchestrated
intelligence, this approach seeks to align medical AI with the first principle
of medicine: care that is transparent, equitable, and centered on the
individual.

</details>


### [85] [Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion](https://arxiv.org/abs/2510.24390)
*Xianjun Gao,Jianchun Liu,Hongli Xu,Liusheng Huang*

Main category: cs.AI

TL;DR: Orion通过依赖感知的并行推理机制显著提升了Web应用中LLM的速度与质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在实时Web应用中面临质量与效率难以兼顾的问题，现有方法无法同时满足低延迟与高吞吐的要求。

Method: 提出名为Orion的高效推理框架，通过依赖感知的查询分解与逻辑并行内容扩展实现高效推理。Orion包含两个阶段：关键点生成（通过检索增强的少样本提示提取结构化要点）与内容并行扩展（基于依赖图并发展开内容），并设计了跨查询的管线调度机制以充分利用计算资源。

Result: 在多个基准测试上，Orion实现了最高4.33倍的生成速度提升、3.42倍的延迟降低，并在推理质量上提升了18.75%。

Conclusion: Orion框架成功在推理效率和质量之间建立平衡，为Web端大模型推理提供了可扩展的解决方案。

Abstract: The integration of Large Language Models (LLMs) into real-time Web
applications, such as AI-powered search and conversational agents, presents a
fundamental Web infrastructure challenge: reconciling the demand for
high-quality, complex reasoning with the stringent low-latency and
high-throughput requirements of interactive services. Current LLM reasoning,
hindered by computationally inefficient sequential generation and rigid
reasoning strategies, creates a critical bottleneck for the Web services.
Existing approaches typically optimize the LLM reasoning for either efficiency
or quality but struggle to achieve both, and thus fail to meet the dual
requirements of modern Web platforms. To overcome these limitations, we propose
Orion, a novel and efficient reasoning framework that enables dependency-aware
query decomposition and logic-parallel content expansion. Concretely, Orion
decomposes a single query reasoning process into two synergistic phases: (1)
\textit{key point generation}, which distills logically structured key points
through retrieval-augmented few-shot prompting, and (2) \textit{content
parallel expansion}, which concurrently elaborates on these points based on a
dependency graph to ensure logical consistency. Furthermore, Orion introduces a
pipeline scheduling mechanism that exploits the complementary computational
characteristics of the two phases (generation imposes pressure on GPU computing
and expansion stresses on GPU memory) across multiple queries, enabling
cross-query parallelism and dramatically improving reasoning performance (\ie,
efficiency and quality). Experiments on diverse benchmarks show that Orion not
only delivers up to 4.33x higher token generation speed and 3.42x lower answer
latency over the baselines but also improves reasoning quality by up to 18.75%
through explicitly modeling inter-point dependencies.

</details>


### [86] [Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning](https://arxiv.org/abs/2510.24435)
*Benjamin Grando Moreira*

Main category: cs.AI

TL;DR: 论文评估了多款LLM的推理能力，发现它们在逻辑推断任务上与人类存在明显差距。


<details>
  <summary>Details</summary>
Motivation: 研究者希望评估大型语言模型（LLM）的推理能力，而不仅仅是语言任务表现，以了解它们是否真正具备理解与逻辑推断能力。

Method: 设计了八道推理题，对多个LLM（包括GPT、Claude、DeepSeek、Gemini等）的逻辑与抽象推理能力进行测试，并将结果与人类表现进行对比。

Result: 实验发现LLM在推理任务上与人类表现存在显著差异，显示模型在演绎推理方面仍有不足。

Conclusion: 当前LLM在逻辑与抽象推理上的表现仍不及人类，需进一步提升模型的推理机制。

Abstract: Evaluating reasoning ability in Large Language Models (LLMs) is important for
advancing artificial intelligence, as it transcends mere linguistic task
performance. It involves understanding whether these models truly understand
information, perform inferences, and are able to draw conclusions in a logical
and valid way. This study compare logical and abstract reasoning skills of
several LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,
Perplexity, and Sabi\'a - using a set of eight custom-designed reasoning
questions. The LLM results are benchmarked against human performance on the
same tasks, revealing significant differences and indicating areas where LLMs
struggle with deduction.

</details>


### [87] [Law in Silico: Simulating Legal Society with LLM-Based Agents](https://arxiv.org/abs/2510.24442)
*Yiding Wang,Yuxuan Chen,Fanxu Meng,Xifan Chen,Xiaolei Yang,Muhan Zhang*

Main category: cs.AI

TL;DR: 论文提出Law in Silico框架，用LLM模拟法律社会，实验显示该系统能重现真实犯罪趋势并揭示法律制度对弱势群体保护的作用。


<details>
  <summary>Details</summary>
Motivation: 由于现实中的法律实验通常成本高昂或难以实施，作者希望通过人工智能系统构建虚拟法律社会，从而验证和发展法律理论，并支持法律行政。

Method: 作者提出了一个名为Law in Silico的LLM智能体框架，通过模拟个人决策与立法、裁决、执法等制度机制，开展实验并将模拟的犯罪率与现实数据进行对比分析。

Result: 实验结果表明，LLM智能体不仅能够重现宏观层面的犯罪趋势，还能在微观层面揭示法律系统特性对个体权利保护的影响。

Conclusion: 论文得出结论：基于LLM的智能体可以有效模拟法律社会，在宏观层面再现真实世界的犯罪趋势，并在微观层面展现出透明、适应性良好的法律系统更能保护弱势群体的权利。

Abstract: Since real-world legal experiments are often costly or infeasible, simulating
legal societies with Artificial Intelligence (AI) systems provides an effective
alternative for verifying and developing legal theory, as well as supporting
legal administration. Large Language Models (LLMs), with their world knowledge
and role-playing capabilities, are strong candidates to serve as the foundation
for legal society simulation. However, the application of LLMs to simulate
legal systems remains underexplored. In this work, we introduce Law in Silico,
an LLM-based agent framework for simulating legal scenarios with individual
decision-making and institutional mechanisms of legislation, adjudication, and
enforcement. Our experiments, which compare simulated crime rates with
real-world data, demonstrate that LLM-based agents can largely reproduce
macro-level crime trends and provide insights that align with real-world
observations. At the same time, micro-level simulations reveal that a
well-functioning, transparent, and adaptive legal system offers better
protection of the rights of vulnerable individuals.

</details>


### [88] [From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning](https://arxiv.org/abs/2510.24528)
*Zihan Chen,Song Wang,Xingbo Fu,Chengshuai Shi,Zhenyu Lei,Cong Shen,Jundong Li*

Main category: cs.AI

TL;DR: 提出一个结合跨任务示例提示与基于图的标签传播的两阶段方法，用于低成本构建上下文学习示例，在五个任务上验证了性能与降本效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型具备上下文学习能力，可以在无需参数更新的情况下完成新任务，但为新任务收集高质量示例的成本较高且费时。

Method: 提出一个成本高效的两阶段流程：第一阶段利用跨任务示例提示LLM为少量目标任务样本生成伪标签；第二阶段通过基于图的标签传播方法，将标签信息传递到剩余的目标样本，无需额外的LLM调用。

Result: 在五个任务上的实验表明，该方法在降低标注成本的同时，依然能够取得优异的性能。

Conclusion: 结合跨任务监督的灵活性与不依赖LLM的传播方法的可扩展性，可以有效支持高效的上下文学习示例构建，显著减少标注成本。

Abstract: The capability of in-context learning (ICL) enables large language models
(LLMs) to perform novel tasks without parameter updates by conditioning on a
few input-output examples. However, collecting high-quality examples for new or
challenging tasks can be costly and labor-intensive. In this work, we propose a
cost-efficient two-stage pipeline that reduces reliance on LLMs for data
labeling. Our approach first leverages readily available cross-task examples to
prompt an LLM and pseudo-label a small set of target task instances. We then
introduce a graph-based label propagation method that spreads label information
to the remaining target examples without additional LLM queries. The resulting
fully pseudo-labeled dataset is used to construct in-task demonstrations for
ICL. This pipeline combines the flexibility of cross-task supervision with the
scalability of LLM-free propagation. Experiments across five tasks demonstrate
that our method achieves strong performance while lowering labeling costs.

</details>


### [89] [Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives](https://arxiv.org/abs/2510.24551)
*Gang Chen,Changshuo Liu,Gene Anne Ooi,Marcus Tan,Zhongle Xie,Jianwei Yin,James Wei Luen Yip,Wenqiao Zhang,Jiaqi Zhu,Beng Chin Ooi*

Main category: cs.AI

TL;DR: 论文提出一种以数据为中心的生成式人工智能医疗系统设计理念，通过构建医疗数据生态以支持模型训练与临床推理，从而提高医疗服务质量。


<details>
  <summary>Details</summary>
Motivation: 为了应对GenAI在医疗领域的潜力与挑战，提升诊断、个性化治疗及减轻医务人员认知负担，需要重新思考GenAI系统的设计和数据使用方式，以充分发挥其效能。

Method: 作者提出一种以数据生命周期为中心的范式，将医疗数据的整合、表示与检索作为生成式医疗系统的基础，通过语义向量搜索、上下文查询等数据处理管线来支持模型训练和推理。

Result: 该生态系统能够向生成模型提供高质量的多模态数据用于预训练与微调，同时作为知识检索后端支持具体临床任务推理，促进高效的医疗服务交付。

Conclusion: 本文提出在医疗领域部署生成式人工智能（GenAI）时，应以数据为核心，通过构建可持续的医疗数据生态系统来支撑模型预训练、微调和临床应用，从而实现高质量的医疗服务。

Abstract: Generative Artificial Intelligence (GenAI) is taking the world by storm. It
promises transformative opportunities for advancing and disrupting existing
practices, including healthcare. From large language models (LLMs) for clinical
note synthesis and conversational assistance to multimodal systems that
integrate medical imaging, electronic health records, and genomic data for
decision support, GenAI is transforming the practice of medicine and the
delivery of healthcare, such as diagnosis and personalized treatments, with
great potential in reducing the cognitive burden on clinicians, thereby
improving overall healthcare delivery. However, GenAI deployment in healthcare
requires an in-depth understanding of healthcare tasks and what can and cannot
be achieved. In this paper, we propose a data-centric paradigm in the design
and deployment of GenAI systems for healthcare. Specifically, we reposition the
data life cycle by making the medical data ecosystem as the foundational
substrate for generative healthcare systems. This ecosystem is designed to
sustainably support the integration, representation, and retrieval of diverse
medical data and knowledge. With effective and efficient data processing
pipelines, such as semantic vector search and contextual querying, it enables
GenAI-powered operations for upstream model components and downstream clinical
applications. Ultimately, it not only supplies foundation models with
high-quality, multimodal data for large-scale pretraining and domain-specific
fine-tuning, but also serves as a knowledge retrieval backend to support
task-specific inference via the agentic layer. The ecosystem enables the
deployment of GenAI for high-quality and effective healthcare delivery.

</details>


### [90] [Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning](https://arxiv.org/abs/2510.24650)
*Nitin Rai,Daeun,Choi,Nathan S. Boyd,Arnold W. Schumann*

Main category: cs.AI

TL;DR: 综述分析了基础模型在作物病害管理中的应用现状，发现视觉语言模型增长迅速，但人机协同和真实场景应用仍存在瓶颈。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和深度学习在农作物病害视觉识别领域快速发展，基础模型正改变传统数据处理方式，研究希望了解这些模型在融合视觉与文本、实现人机协同和精准喷洒等方面的潜力与挑战。

Method: 该研究通过系统综述约40篇关于FMs在SSDM中的应用文献，重点分析了大型语言模型（LLMs）、视觉语言模型（VLMs）以及相关自适应学习（AL）、强化学习（RL）和数字孪生框架的研究进展。

Result: FMs相关文献在2023-24年显著增长；VLMs研究数量比LLMs高出5到10倍；RL和AL在智能喷洒领域仍处于早期阶段；数字孪生结合RL可虚拟模拟喷洒过程；现实部署需解决仿真到现实的差距；人机协作尤其在人机交互环节仍有限。

Conclusion: 基础模型（FMs）在作物病害现场管理（SSDM）中发挥着越来越关键的作用，尤其是视觉语言模型（VLMs），预计多模态FMs与实时反馈结合将引领下一代精准病害治理。

Abstract: Site-specific disease management (SSDM) in crops has advanced rapidly through
machine and deep learning (ML and DL) for real-time computer vision. Research
evolved from handcrafted feature extraction to large-scale automated feature
learning. With foundation models (FMs), crop disease datasets are now processed
in fundamentally new ways. Unlike traditional neural networks, FMs integrate
visual and textual data, interpret symptoms in text, reason about
symptom-management relationships, and support interactive QA for growers and
educators. Adaptive and imitation learning in robotics further enables
field-based disease management. This review screened approx. 40 articles on FM
applications for SSDM, focusing on large-language models (LLMs) and
vision-language models (VLMs), and discussing their role in adaptive learning
(AL), reinforcement learning (RL), and digital twin frameworks for targeted
spraying. Key findings: (a) FMs are gaining traction with surging literature in
2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL
and AL are still nascent for smart spraying; (d) digital twins with RL can
simulate targeted spraying virtually; (e) addressing the sim-to-real gap is
critical for real-world deployment; (f) human-robot collaboration remains
limited, especially in human-in-the-loop approaches where robots detect early
symptoms and humans validate uncertain cases; (g) multi-modal FMs with
real-time feedback will drive next-gen SSDM. For updates, resources, and
contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to
submit papers, code, or datasets.

</details>


### [91] [OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs](https://arxiv.org/abs/2510.24663)
*Yifu Lu,Shengjie Liu,Li Dong*

Main category: cs.AI

TL;DR: 作者提出OrchDAG框架生成DAG结构任务数据并设计图奖励机制，实验验证其在多轮工具调用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有关于智能体调用工具的研究多集中于单轮交互，忽略了多轮工具交互的复杂性。

Method: 提出OrchDAG数据生成管线，将工具执行过程建模为可控复杂度的有向无环图（DAG），并引入图结构奖励机制优化RLVR训练。

Result: 实验表明OrchDAG数据集具有挑战性但可解，且所设计的图结构奖励在结合GRPO算法时取得良好效果。

Conclusion: 通过利用拓扑结构和数据复杂度，可以显著提升多轮工具使用任务中智能体的表现。

Abstract: Agentic tool use has gained traction with the rise of agentic tool calling,
yet most existing work overlooks the complexity of multi-turn tool
interactions. We introduce OrchDAG, a synthetic data generation pipeline that
models tool execution as directed acyclic graphs (DAGs) with controllable
complexity. Using this dataset, we benchmark model performance and propose a
graph-based reward to enhance RLVR training. Experiments show that the dataset
presents a challenging but solvable benchmark, and the proposed reward is
effective when combined with GRPO-style algorithms, highlighting the importance
of leveraging topological structure and data complexity in multi-turn tool use.

</details>


### [92] [Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning](https://arxiv.org/abs/2510.24690)
*Shengjie Liu,Li Dong,Zhenyu Zhang*

Main category: cs.AI

TL;DR: 通过构建并融合工具知识图谱与领域文档知识图谱，并采用深度稀疏整合策略对齐两者，显著提升了示例计划生成效果和工具交互建模能力。


<details>
  <summary>Details</summary>
Motivation: 当前工具与文档之间的依赖关系在构建示例工件时往往缺乏系统化挖掘与利用，导致生成计划的质量和工具增强推理能力受限，因此作者希望通过一个统一框架将工具知识与领域文档紧密结合，提高生成效果。

Method: 首先从工具的模式信息（描述、参数、输出等）中构建工具知识图谱，采用类似DeepResearch的分析方法；同时从内部文档与SOP中构建领域知识图谱，并与工具图谱融合；在生成示例计划时，使用一种深度稀疏整合策略，将结构化的工具依赖关系与流程知识对齐。

Result: 实验结果表明，该框架能够有效建模工具之间的交互，并提升计划生成的质量，证明了工具知识图谱与领域知识图谱融合对工具增强推理与规划的价值。

Conclusion: 融合工具知识与领域知识的统一框架能显著改善工具依赖建模与示例计划生成质量，为工具辅助推理和规划提供了有效途径。

Abstract: We present a framework for uncovering and exploiting dependencies among tools
and documents to enhance exemplar artifact generation. Our method begins by
constructing a tool knowledge graph from tool schemas,including descriptions,
arguments, and output payloads, using a DeepResearch-inspired analysis. In
parallel, we derive a complementary knowledge graph from internal documents and
SOPs, which is then fused with the tool graph. To generate exemplar plans, we
adopt a deep-sparse integration strategy that aligns structural tool
dependencies with procedural knowledge. Experiments demonstrate that this
unified framework effectively models tool interactions and improves plan
generation, underscoring the benefits of linking tool graphs with domain
knowledge graphs for tool-augmented reasoning and planning.

</details>
